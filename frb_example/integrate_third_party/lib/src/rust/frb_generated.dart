// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: unused_import, unused_element, unnecessary_import, duplicate_ignore, invalid_use_of_internal_member, annotate_overrides, non_constant_identifier_names, curly_braces_in_flow_control_structures, prefer_const_literals_to_create_immutables, unused_field
// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'api/media_element.dart';
import 'api/override_web_audio_api.dart';
import 'api/simple.dart';
import 'dart:async';
import 'dart:convert';
import 'frb_generated.dart';
import 'frb_generated.io.dart'
    if (dart.library.js_interop) 'frb_generated.web.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
import 'third_party/web_audio_api.dart';
import 'third_party/web_audio_api/context.dart';
import 'third_party/web_audio_api/media_devices.dart';
import 'third_party/web_audio_api/media_recorder.dart';
import 'third_party/web_audio_api/media_streams.dart';
import 'third_party/web_audio_api/node.dart';
import 'third_party/web_audio_api/worklet.dart';
part 'frb_generated.freezed.dart';

/// Main entrypoint of the Rust API
class RustLib extends BaseEntrypoint<RustLibApi, RustLibApiImpl, RustLibWire> {
  @internal
  static final instance = RustLib._();

  RustLib._();

  /// Initialize flutter_rust_bridge
  static Future<void> init({
    RustLibApi? api,
    BaseHandler? handler,
    ExternalLibrary? externalLibrary,
    bool forceSameCodegenVersion = true,
  }) async {
    await instance.initImpl(
      api: api,
      handler: handler,
      externalLibrary: externalLibrary,
      forceSameCodegenVersion: forceSameCodegenVersion,
    );
  }

  /// Initialize flutter_rust_bridge in mock mode.
  /// No libraries for FFI are loaded.
  static void initMock({
    required RustLibApi api,
  }) {
    instance.initMockImpl(
      api: api,
    );
  }

  /// Dispose flutter_rust_bridge
  ///
  /// The call to this function is optional, since flutter_rust_bridge (and everything else)
  /// is automatically disposed when the app stops.
  static void dispose() => instance.disposeImpl();

  @override
  ApiImplConstructor<RustLibApiImpl, RustLibWire> get apiImplConstructor =>
      RustLibApiImpl.new;

  @override
  WireConstructor<RustLibWire> get wireConstructor =>
      RustLibWire.fromExternalLibrary;

  @override
  Future<void> executeRustInitializers() async {
    await api.crateApiSimpleInitApp();
  }

  @override
  ExternalLibraryLoaderConfig get defaultExternalLibraryLoaderConfig =>
      kDefaultExternalLibraryLoaderConfig;

  @override
  String get codegenVersion => '2.10.0';

  @override
  int get rustContentHash => -385663864;

  static const kDefaultExternalLibraryLoaderConfig =
      ExternalLibraryLoaderConfig(
    stem: 'rust_lib_frb_example_integrate_third_party',
    ioDirectory: 'rust/target/release/',
    webPrefix: 'pkg/',
  );
}

abstract class RustLibApi extends BaseApi {
  Future<void> webAudioApiNodeAnalyserNodeChannelConfig(
      {required AnalyserNode that});

  Future<int> webAudioApiNodeAnalyserNodeChannelCount(
      {required AnalyserNode that});

  Future<ChannelCountMode> webAudioApiNodeAnalyserNodeChannelCountMode(
      {required AnalyserNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeAnalyserNodeChannelInterpretation(
          {required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeClearOnprocessorerror(
      {required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeDisconnect(
      {required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeDisconnectOutput(
      {required AnalyserNode that, required int output});

  Future<int> webAudioApiNodeAnalyserNodeFftSize({required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeFrbOverrideConnect(
      {required AnalyserNode that, required AudioNode dest});

  Future<Uint8List> webAudioApiNodeAnalyserNodeFrbOverrideGetByteTimeDomainData(
      {required AnalyserNode that, required int len});

  Future<Float32List>
      webAudioApiNodeAnalyserNodeFrbOverrideGetFloatTimeDomainData(
          {required AnalyserNode that, required int len});

  Future<int> webAudioApiNodeAnalyserNodeFrequencyBinCount(
      {required AnalyserNode that});

  Future<double> webAudioApiNodeAnalyserNodeMaxDecibels(
      {required AnalyserNode that});

  Future<double> webAudioApiNodeAnalyserNodeMinDecibels(
      {required AnalyserNode that});

  Future<int> webAudioApiNodeAnalyserNodeNumberOfInputs(
      {required AnalyserNode that});

  Future<int> webAudioApiNodeAnalyserNodeNumberOfOutputs(
      {required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeRegistration(
      {required AnalyserNode that});

  Future<void> webAudioApiNodeAnalyserNodeSetFftSize(
      {required AnalyserNode that, required int fftSize});

  Future<void> webAudioApiNodeAnalyserNodeSetMaxDecibels(
      {required AnalyserNode that, required double value});

  Future<void> webAudioApiNodeAnalyserNodeSetMinDecibels(
      {required AnalyserNode that, required double value});

  Future<void> webAudioApiNodeAnalyserNodeSetOnProcessorError(
      {required AnalyserNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeAnalyserNodeSetSmoothingTimeConstant(
      {required AnalyserNode that, required double value});

  Future<double> webAudioApiNodeAnalyserNodeSmoothingTimeConstant(
      {required AnalyserNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeChannelConfig(
      {required AudioBufferSourceNode that});

  Future<int> webAudioApiNodeAudioBufferSourceNodeChannelCount(
      {required AudioBufferSourceNode that});

  Future<ChannelCountMode> webAudioApiNodeAudioBufferSourceNodeChannelCountMode(
      {required AudioBufferSourceNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeAudioBufferSourceNodeChannelInterpretation(
          {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeClearOnended(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeClearOnprocessorerror(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeDisconnect(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeDisconnectOutput(
      {required AudioBufferSourceNode that, required int output});

  Future<void> webAudioApiNodeAudioBufferSourceNodeFrbOverrideConnect(
      {required AudioBufferSourceNode that, required AudioNode dest});

  Future<void> webAudioApiNodeAudioBufferSourceNodeFrbOverrideSetBuffer(
      {required AudioBufferSourceNode that, required AudioBuffer audioBuffer});

  Future<bool> webAudioApiNodeAudioBufferSourceNodeLoop(
      {required AudioBufferSourceNode that});

  Future<double> webAudioApiNodeAudioBufferSourceNodeLoopEnd(
      {required AudioBufferSourceNode that});

  Future<double> webAudioApiNodeAudioBufferSourceNodeLoopStart(
      {required AudioBufferSourceNode that});

  Future<int> webAudioApiNodeAudioBufferSourceNodeNumberOfInputs(
      {required AudioBufferSourceNode that});

  Future<int> webAudioApiNodeAudioBufferSourceNodeNumberOfOutputs(
      {required AudioBufferSourceNode that});

  Future<double> webAudioApiNodeAudioBufferSourceNodePosition(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeRegistration(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoop(
      {required AudioBufferSourceNode that, required bool value});

  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoopEnd(
      {required AudioBufferSourceNode that, required double value});

  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoopStart(
      {required AudioBufferSourceNode that, required double value});

  Future<void> webAudioApiNodeAudioBufferSourceNodeSetOnEnded(
      {required AudioBufferSourceNode that,
      required FutureOr<void> Function(Event) callback});

  Future<void> webAudioApiNodeAudioBufferSourceNodeSetOnProcessorError(
      {required AudioBufferSourceNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStart(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAt(
      {required AudioBufferSourceNode that, required double when});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAtWithOffset(
      {required AudioBufferSourceNode that,
      required double start,
      required double offset});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDuration(
      {required AudioBufferSourceNode that,
      required double start,
      required double offset,
      required double duration});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStop(
      {required AudioBufferSourceNode that});

  Future<void> webAudioApiNodeAudioBufferSourceNodeStopAt(
      {required AudioBufferSourceNode that, required double when});

  Future<double> webAudioApiAudioBufferDuration({required AudioBuffer that});

  Future<AudioBuffer> webAudioApiAudioBufferFrom(
      {required List<Float32List> samples, required double sampleRate});

  Future<void> webAudioApiAudioBufferGetChannelData(
      {required AudioBuffer that, required int channelNumber});

  Future<void> webAudioApiAudioBufferGetChannelDataMut(
      {required AudioBuffer that, required int channelNumber});

  Future<int> webAudioApiAudioBufferLength({required AudioBuffer that});

  Future<AudioBuffer> webAudioApiAudioBufferNew(
      {required AudioBufferOptions options});

  Future<int> webAudioApiAudioBufferNumberOfChannels(
      {required AudioBuffer that});

  Future<double> webAudioApiAudioBufferSampleRate({required AudioBuffer that});

  Future<double> webAudioApiContextAudioContextBaseLatency(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextClearOnsinkchange(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextClearOnstatechange(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextClose(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextCloseSync(
      {required AudioContext that});

  Future<AnalyserNode> webAudioApiContextAudioContextCreateAnalyser(
      {required AudioContext that});

  Future<(AudioParam, AudioParamId)>
      webAudioApiContextAudioContextCreateAudioParam(
          {required AudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest});

  Future<BiquadFilterNode> webAudioApiContextAudioContextCreateBiquadFilter(
      {required AudioContext that});

  Future<AudioBuffer> webAudioApiContextAudioContextCreateBuffer(
      {required AudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate});

  Future<AudioBufferSourceNode>
      webAudioApiContextAudioContextCreateBufferSource(
          {required AudioContext that});

  Future<ChannelMergerNode> webAudioApiContextAudioContextCreateChannelMerger(
      {required AudioContext that, required int numberOfInputs});

  Future<ChannelSplitterNode>
      webAudioApiContextAudioContextCreateChannelSplitter(
          {required AudioContext that, required int numberOfOutputs});

  Future<ConstantSourceNode> webAudioApiContextAudioContextCreateConstantSource(
      {required AudioContext that});

  Future<ConvolverNode> webAudioApiContextAudioContextCreateConvolver(
      {required AudioContext that});

  Future<DelayNode> webAudioApiContextAudioContextCreateDelay(
      {required AudioContext that, required double maxDelayTime});

  Future<DynamicsCompressorNode>
      webAudioApiContextAudioContextCreateDynamicsCompressor(
          {required AudioContext that});

  Future<GainNode> webAudioApiContextAudioContextCreateGain(
      {required AudioContext that});

  Future<IirFilterNode> webAudioApiContextAudioContextCreateIirFilter(
      {required AudioContext that,
      required List<double> feedforward,
      required List<double> feedback});

  Future<MediaStreamAudioDestinationNode>
      webAudioApiContextAudioContextCreateMediaStreamDestination(
          {required AudioContext that});

  Future<MediaStreamAudioSourceNode>
      webAudioApiContextAudioContextCreateMediaStreamSource(
          {required AudioContext that, required MediaStream media});

  Future<MediaStreamTrackAudioSourceNode>
      webAudioApiContextAudioContextCreateMediaStreamTrackSource(
          {required AudioContext that, required MediaStreamTrack media});

  Future<OscillatorNode> webAudioApiContextAudioContextCreateOscillator(
      {required AudioContext that});

  Future<PannerNode> webAudioApiContextAudioContextCreatePanner(
      {required AudioContext that});

  Future<PeriodicWave> webAudioApiContextAudioContextCreatePeriodicWave(
      {required AudioContext that, required PeriodicWaveOptions options});

  Future<ScriptProcessorNode>
      webAudioApiContextAudioContextCreateScriptProcessor(
          {required AudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels});

  Future<StereoPannerNode> webAudioApiContextAudioContextCreateStereoPanner(
      {required AudioContext that});

  Future<WaveShaperNode> webAudioApiContextAudioContextCreateWaveShaper(
      {required AudioContext that});

  Future<double> webAudioApiContextAudioContextCurrentTime(
      {required AudioContext that});

  Future<AudioContext> webAudioApiContextAudioContextDefault();

  Future<AudioDestinationNode> webAudioApiContextAudioContextDestination(
      {required AudioContext that});

  Future<MediaElementAudioSourceNode>
      webAudioApiContextAudioContextFrbOverrideCreateMediaElementSource(
          {required AudioContext that, required MediaElement mediaElement});

  Future<AudioBuffer>
      webAudioApiContextAudioContextFrbOverrideDecodeAudioDataSync(
          {required AudioContext that, required String inputPath});

  Future<AudioListener> webAudioApiContextAudioContextListener(
      {required AudioContext that});

  AudioContext webAudioApiContextAudioContextNew(
      {required AudioContextOptions options});

  Future<double> webAudioApiContextAudioContextOutputLatency(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextRenderCapacity(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextResumeSync(
      {required AudioContext that});

  Future<double> webAudioApiContextAudioContextSampleRate(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextSetOnStateChange(
      {required AudioContext that,
      required FutureOr<void> Function(Event) callback});

  Future<void> webAudioApiContextAudioContextSetSinkId(
      {required AudioContext that, required String sinkId});

  Future<String> webAudioApiContextAudioContextSinkId(
      {required AudioContext that});

  Future<AudioContextState> webAudioApiContextAudioContextState(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextSuspend(
      {required AudioContext that});

  Future<void> webAudioApiContextAudioContextSuspendSync(
      {required AudioContext that});

  Future<void> webAudioApiNodeAudioDestinationNodeChannelConfig(
      {required AudioDestinationNode that});

  Future<int> webAudioApiNodeAudioDestinationNodeChannelCount(
      {required AudioDestinationNode that});

  Future<ChannelCountMode> webAudioApiNodeAudioDestinationNodeChannelCountMode(
      {required AudioDestinationNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeAudioDestinationNodeChannelInterpretation(
          {required AudioDestinationNode that});

  Future<void> webAudioApiNodeAudioDestinationNodeClearOnprocessorerror(
      {required AudioDestinationNode that});

  Future<void> webAudioApiNodeAudioDestinationNodeDisconnect(
      {required AudioDestinationNode that});

  Future<void> webAudioApiNodeAudioDestinationNodeDisconnectOutput(
      {required AudioDestinationNode that, required int output});

  Future<void> webAudioApiNodeAudioDestinationNodeFrbOverrideConnect(
      {required AudioDestinationNode that, required AudioNode dest});

  Future<int> webAudioApiNodeAudioDestinationNodeMaxChannelCount(
      {required AudioDestinationNode that});

  Future<int> webAudioApiNodeAudioDestinationNodeNumberOfInputs(
      {required AudioDestinationNode that});

  Future<int> webAudioApiNodeAudioDestinationNodeNumberOfOutputs(
      {required AudioDestinationNode that});

  Future<void> webAudioApiNodeAudioDestinationNodeRegistration(
      {required AudioDestinationNode that});

  Future<void> webAudioApiNodeAudioDestinationNodeSetOnProcessorError(
      {required AudioDestinationNode that,
      required FutureOr<void> Function(String) callback});

  Future<AutomationRate> webAudioApiAudioParamAutomationRate(
      {required AudioParam that});

  Future<void> webAudioApiAudioParamCancelAndHoldAtTime(
      {required AudioParam that, required double cancelTime});

  Future<void> webAudioApiAudioParamCancelScheduledValues(
      {required AudioParam that, required double cancelTime});

  Future<void> webAudioApiAudioParamChannelConfig({required AudioParam that});

  Future<int> webAudioApiAudioParamChannelCount({required AudioParam that});

  Future<ChannelCountMode> webAudioApiAudioParamChannelCountMode(
      {required AudioParam that});

  Future<ChannelInterpretation> webAudioApiAudioParamChannelInterpretation(
      {required AudioParam that});

  Future<void> webAudioApiAudioParamClearOnprocessorerror(
      {required AudioParam that});

  Future<double> webAudioApiAudioParamDefaultValue({required AudioParam that});

  Future<void> webAudioApiAudioParamDisconnect({required AudioParam that});

  Future<void> webAudioApiAudioParamDisconnectOutput(
      {required AudioParam that, required int output});

  Future<void> webAudioApiAudioParamExponentialRampToValueAtTime(
      {required AudioParam that,
      required double value,
      required double endTime});

  Future<void> webAudioApiAudioParamFrbOverrideConnect(
      {required AudioParam that, required AudioNode dest});

  Future<void> webAudioApiAudioParamLinearRampToValueAtTime(
      {required AudioParam that,
      required double value,
      required double endTime});

  Future<double> webAudioApiAudioParamMaxValue({required AudioParam that});

  Future<double> webAudioApiAudioParamMinValue({required AudioParam that});

  Future<int> webAudioApiAudioParamNumberOfInputs({required AudioParam that});

  Future<int> webAudioApiAudioParamNumberOfOutputs({required AudioParam that});

  Future<void> webAudioApiAudioParamRegistration({required AudioParam that});

  Future<void> webAudioApiAudioParamSetAutomationRate(
      {required AudioParam that, required AutomationRate value});

  Future<void> webAudioApiAudioParamSetOnProcessorError(
      {required AudioParam that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiAudioParamSetTargetAtTime(
      {required AudioParam that,
      required double value,
      required double startTime,
      required double timeConstant});

  void webAudioApiAudioParamSetValue(
      {required AudioParam that, required double value});

  Future<void> webAudioApiAudioParamSetValueAtTime(
      {required AudioParam that,
      required double value,
      required double startTime});

  Future<void> webAudioApiAudioParamSetValueCurveAtTime(
      {required AudioParam that,
      required List<double> values,
      required double startTime,
      required double duration});

  double webAudioApiAudioParamValue({required AudioParam that});

  AudioBuffer webAudioApiAudioProcessingEventAutoAccessorGetInputBuffer(
      {required AudioProcessingEvent that});

  AudioBuffer webAudioApiAudioProcessingEventAutoAccessorGetOutputBuffer(
      {required AudioProcessingEvent that});

  double webAudioApiAudioProcessingEventAutoAccessorGetPlaybackTime(
      {required AudioProcessingEvent that});

  void webAudioApiAudioProcessingEventAutoAccessorSetInputBuffer(
      {required AudioProcessingEvent that, required AudioBuffer inputBuffer});

  void webAudioApiAudioProcessingEventAutoAccessorSetOutputBuffer(
      {required AudioProcessingEvent that, required AudioBuffer outputBuffer});

  void webAudioApiAudioProcessingEventAutoAccessorSetPlaybackTime(
      {required AudioProcessingEvent that, required double playbackTime});

  double webAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoad(
      {required AudioRenderCapacityEvent that});

  Event webAudioApiAudioRenderCapacityEventAutoAccessorGetEvent(
      {required AudioRenderCapacityEvent that});

  double webAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoad(
      {required AudioRenderCapacityEvent that});

  double webAudioApiAudioRenderCapacityEventAutoAccessorGetTimestamp(
      {required AudioRenderCapacityEvent that});

  double webAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatio(
      {required AudioRenderCapacityEvent that});

  void webAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoad(
      {required AudioRenderCapacityEvent that, required double averageLoad});

  void webAudioApiAudioRenderCapacityEventAutoAccessorSetEvent(
      {required AudioRenderCapacityEvent that, required Event event});

  void webAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoad(
      {required AudioRenderCapacityEvent that, required double peakLoad});

  void webAudioApiAudioRenderCapacityEventAutoAccessorSetTimestamp(
      {required AudioRenderCapacityEvent that, required double timestamp});

  void webAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatio(
      {required AudioRenderCapacityEvent that, required double underrunRatio});

  Future<void> webAudioApiAudioRenderCapacityClearOnupdate(
      {required AudioRenderCapacity that});

  Future<void> webAudioApiAudioRenderCapacityStart(
      {required AudioRenderCapacity that,
      required AudioRenderCapacityOptions options});

  Future<void> webAudioApiAudioRenderCapacityStop(
      {required AudioRenderCapacity that});

  Future<void> webAudioApiWorkletAudioWorkletNodeChannelConfig(
      {required AudioWorkletNode that});

  Future<int> webAudioApiWorkletAudioWorkletNodeChannelCount(
      {required AudioWorkletNode that});

  Future<ChannelCountMode> webAudioApiWorkletAudioWorkletNodeChannelCountMode(
      {required AudioWorkletNode that});

  Future<ChannelInterpretation>
      webAudioApiWorkletAudioWorkletNodeChannelInterpretation(
          {required AudioWorkletNode that});

  Future<void> webAudioApiWorkletAudioWorkletNodeClearOnprocessorerror(
      {required AudioWorkletNode that});

  Future<void> webAudioApiWorkletAudioWorkletNodeDisconnect(
      {required AudioWorkletNode that});

  Future<void> webAudioApiWorkletAudioWorkletNodeDisconnectOutput(
      {required AudioWorkletNode that, required int output});

  Future<int> webAudioApiWorkletAudioWorkletNodeNumberOfInputs(
      {required AudioWorkletNode that});

  Future<int> webAudioApiWorkletAudioWorkletNodeNumberOfOutputs(
      {required AudioWorkletNode that});

  Future<void> webAudioApiWorkletAudioWorkletNodeParameters(
      {required AudioWorkletNode that});

  Future<void> webAudioApiWorkletAudioWorkletNodeRegistration(
      {required AudioWorkletNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeChannelConfig(
      {required BiquadFilterNode that});

  Future<int> webAudioApiNodeBiquadFilterNodeChannelCount(
      {required BiquadFilterNode that});

  Future<ChannelCountMode> webAudioApiNodeBiquadFilterNodeChannelCountMode(
      {required BiquadFilterNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeBiquadFilterNodeChannelInterpretation(
          {required BiquadFilterNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeClearOnprocessorerror(
      {required BiquadFilterNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeDisconnect(
      {required BiquadFilterNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeDisconnectOutput(
      {required BiquadFilterNode that, required int output});

  Future<void> webAudioApiNodeBiquadFilterNodeFrbOverrideConnect(
      {required BiquadFilterNode that, required AudioNode dest});

  Future<int> webAudioApiNodeBiquadFilterNodeNumberOfInputs(
      {required BiquadFilterNode that});

  Future<int> webAudioApiNodeBiquadFilterNodeNumberOfOutputs(
      {required BiquadFilterNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeRegistration(
      {required BiquadFilterNode that});

  Future<void> webAudioApiNodeBiquadFilterNodeSetOnProcessorError(
      {required BiquadFilterNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeBiquadFilterNodeSetType(
      {required BiquadFilterNode that, required BiquadFilterType type});

  Future<BiquadFilterType> webAudioApiNodeBiquadFilterNodeType(
      {required BiquadFilterNode that});

  Uint8List webAudioApiMediaRecorderBlobEventAutoAccessorGetBlob(
      {required BlobEvent that});

  Event webAudioApiMediaRecorderBlobEventAutoAccessorGetEvent(
      {required BlobEvent that});

  double webAudioApiMediaRecorderBlobEventAutoAccessorGetTimecode(
      {required BlobEvent that});

  void webAudioApiMediaRecorderBlobEventAutoAccessorSetBlob(
      {required BlobEvent that, required Uint8List blob});

  void webAudioApiMediaRecorderBlobEventAutoAccessorSetEvent(
      {required BlobEvent that, required Event event});

  void webAudioApiMediaRecorderBlobEventAutoAccessorSetTimecode(
      {required BlobEvent that, required double timecode});

  Future<ChannelConfig> webAudioApiNodeChannelConfigDefault();

  Future<void> webAudioApiNodeChannelMergerNodeChannelConfig(
      {required ChannelMergerNode that});

  Future<int> webAudioApiNodeChannelMergerNodeChannelCount(
      {required ChannelMergerNode that});

  Future<ChannelCountMode> webAudioApiNodeChannelMergerNodeChannelCountMode(
      {required ChannelMergerNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeChannelMergerNodeChannelInterpretation(
          {required ChannelMergerNode that});

  Future<void> webAudioApiNodeChannelMergerNodeClearOnprocessorerror(
      {required ChannelMergerNode that});

  Future<void> webAudioApiNodeChannelMergerNodeDisconnect(
      {required ChannelMergerNode that});

  Future<void> webAudioApiNodeChannelMergerNodeDisconnectOutput(
      {required ChannelMergerNode that, required int output});

  Future<void> webAudioApiNodeChannelMergerNodeFrbOverrideConnect(
      {required ChannelMergerNode that, required AudioNode dest});

  Future<int> webAudioApiNodeChannelMergerNodeNumberOfInputs(
      {required ChannelMergerNode that});

  Future<int> webAudioApiNodeChannelMergerNodeNumberOfOutputs(
      {required ChannelMergerNode that});

  Future<void> webAudioApiNodeChannelMergerNodeRegistration(
      {required ChannelMergerNode that});

  Future<void> webAudioApiNodeChannelMergerNodeSetOnProcessorError(
      {required ChannelMergerNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeChannelSplitterNodeChannelConfig(
      {required ChannelSplitterNode that});

  Future<int> webAudioApiNodeChannelSplitterNodeChannelCount(
      {required ChannelSplitterNode that});

  Future<ChannelCountMode> webAudioApiNodeChannelSplitterNodeChannelCountMode(
      {required ChannelSplitterNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeChannelSplitterNodeChannelInterpretation(
          {required ChannelSplitterNode that});

  Future<void> webAudioApiNodeChannelSplitterNodeClearOnprocessorerror(
      {required ChannelSplitterNode that});

  Future<void> webAudioApiNodeChannelSplitterNodeDisconnect(
      {required ChannelSplitterNode that});

  Future<void> webAudioApiNodeChannelSplitterNodeDisconnectOutput(
      {required ChannelSplitterNode that, required int output});

  Future<void> webAudioApiNodeChannelSplitterNodeFrbOverrideConnect(
      {required ChannelSplitterNode that, required AudioNode dest});

  Future<int> webAudioApiNodeChannelSplitterNodeNumberOfInputs(
      {required ChannelSplitterNode that});

  Future<int> webAudioApiNodeChannelSplitterNodeNumberOfOutputs(
      {required ChannelSplitterNode that});

  Future<void> webAudioApiNodeChannelSplitterNodeRegistration(
      {required ChannelSplitterNode that});

  Future<void> webAudioApiNodeChannelSplitterNodeSetOnProcessorError(
      {required ChannelSplitterNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiContextConcreteBaseAudioContextClearOnstatechange(
      {required ConcreteBaseAudioContext that});

  Future<AnalyserNode> webAudioApiContextConcreteBaseAudioContextCreateAnalyser(
      {required ConcreteBaseAudioContext that});

  Future<(AudioParam, AudioParamId)>
      webAudioApiContextConcreteBaseAudioContextCreateAudioParam(
          {required ConcreteBaseAudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest});

  Future<BiquadFilterNode>
      webAudioApiContextConcreteBaseAudioContextCreateBiquadFilter(
          {required ConcreteBaseAudioContext that});

  Future<AudioBuffer> webAudioApiContextConcreteBaseAudioContextCreateBuffer(
      {required ConcreteBaseAudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate});

  Future<AudioBufferSourceNode>
      webAudioApiContextConcreteBaseAudioContextCreateBufferSource(
          {required ConcreteBaseAudioContext that});

  Future<ChannelMergerNode>
      webAudioApiContextConcreteBaseAudioContextCreateChannelMerger(
          {required ConcreteBaseAudioContext that,
          required int numberOfInputs});

  Future<ChannelSplitterNode>
      webAudioApiContextConcreteBaseAudioContextCreateChannelSplitter(
          {required ConcreteBaseAudioContext that,
          required int numberOfOutputs});

  Future<ConstantSourceNode>
      webAudioApiContextConcreteBaseAudioContextCreateConstantSource(
          {required ConcreteBaseAudioContext that});

  Future<ConvolverNode>
      webAudioApiContextConcreteBaseAudioContextCreateConvolver(
          {required ConcreteBaseAudioContext that});

  Future<DelayNode> webAudioApiContextConcreteBaseAudioContextCreateDelay(
      {required ConcreteBaseAudioContext that, required double maxDelayTime});

  Future<DynamicsCompressorNode>
      webAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressor(
          {required ConcreteBaseAudioContext that});

  Future<GainNode> webAudioApiContextConcreteBaseAudioContextCreateGain(
      {required ConcreteBaseAudioContext that});

  Future<IirFilterNode>
      webAudioApiContextConcreteBaseAudioContextCreateIirFilter(
          {required ConcreteBaseAudioContext that,
          required List<double> feedforward,
          required List<double> feedback});

  Future<OscillatorNode>
      webAudioApiContextConcreteBaseAudioContextCreateOscillator(
          {required ConcreteBaseAudioContext that});

  Future<PannerNode> webAudioApiContextConcreteBaseAudioContextCreatePanner(
      {required ConcreteBaseAudioContext that});

  Future<PeriodicWave>
      webAudioApiContextConcreteBaseAudioContextCreatePeriodicWave(
          {required ConcreteBaseAudioContext that,
          required PeriodicWaveOptions options});

  Future<ScriptProcessorNode>
      webAudioApiContextConcreteBaseAudioContextCreateScriptProcessor(
          {required ConcreteBaseAudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels});

  Future<StereoPannerNode>
      webAudioApiContextConcreteBaseAudioContextCreateStereoPanner(
          {required ConcreteBaseAudioContext that});

  Future<WaveShaperNode>
      webAudioApiContextConcreteBaseAudioContextCreateWaveShaper(
          {required ConcreteBaseAudioContext that});

  Future<double> webAudioApiContextConcreteBaseAudioContextCurrentTime(
      {required ConcreteBaseAudioContext that});

  Future<AudioDestinationNode>
      webAudioApiContextConcreteBaseAudioContextDestination(
          {required ConcreteBaseAudioContext that});

  Future<AudioListener> webAudioApiContextConcreteBaseAudioContextListener(
      {required ConcreteBaseAudioContext that});

  Future<void> webAudioApiContextConcreteBaseAudioContextMarkCycleBreaker(
      {required ConcreteBaseAudioContext that,
      required AudioContextRegistration reg});

  Future<double> webAudioApiContextConcreteBaseAudioContextSampleRate(
      {required ConcreteBaseAudioContext that});

  Future<AudioContextState> webAudioApiContextConcreteBaseAudioContextState(
      {required ConcreteBaseAudioContext that});

  Future<void> webAudioApiNodeConstantSourceNodeChannelConfig(
      {required ConstantSourceNode that});

  Future<int> webAudioApiNodeConstantSourceNodeChannelCount(
      {required ConstantSourceNode that});

  Future<ChannelCountMode> webAudioApiNodeConstantSourceNodeChannelCountMode(
      {required ConstantSourceNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeConstantSourceNodeChannelInterpretation(
          {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeClearOnended(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeClearOnprocessorerror(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeDisconnect(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeDisconnectOutput(
      {required ConstantSourceNode that, required int output});

  Future<void> webAudioApiNodeConstantSourceNodeFrbOverrideConnect(
      {required ConstantSourceNode that, required AudioNode dest});

  Future<int> webAudioApiNodeConstantSourceNodeNumberOfInputs(
      {required ConstantSourceNode that});

  Future<int> webAudioApiNodeConstantSourceNodeNumberOfOutputs(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeRegistration(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeSetOnEnded(
      {required ConstantSourceNode that,
      required FutureOr<void> Function(Event) callback});

  Future<void> webAudioApiNodeConstantSourceNodeSetOnProcessorError(
      {required ConstantSourceNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeConstantSourceNodeStart(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeStartAt(
      {required ConstantSourceNode that, required double when});

  Future<void> webAudioApiNodeConstantSourceNodeStop(
      {required ConstantSourceNode that});

  Future<void> webAudioApiNodeConstantSourceNodeStopAt(
      {required ConstantSourceNode that, required double when});

  Future<void> webAudioApiNodeConvolverNodeChannelConfig(
      {required ConvolverNode that});

  Future<int> webAudioApiNodeConvolverNodeChannelCount(
      {required ConvolverNode that});

  Future<ChannelCountMode> webAudioApiNodeConvolverNodeChannelCountMode(
      {required ConvolverNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeConvolverNodeChannelInterpretation(
          {required ConvolverNode that});

  Future<void> webAudioApiNodeConvolverNodeClearOnprocessorerror(
      {required ConvolverNode that});

  Future<void> webAudioApiNodeConvolverNodeDisconnect(
      {required ConvolverNode that});

  Future<void> webAudioApiNodeConvolverNodeDisconnectOutput(
      {required ConvolverNode that, required int output});

  Future<void> webAudioApiNodeConvolverNodeFrbOverrideConnect(
      {required ConvolverNode that, required AudioNode dest});

  Future<bool> webAudioApiNodeConvolverNodeNormalize(
      {required ConvolverNode that});

  Future<int> webAudioApiNodeConvolverNodeNumberOfInputs(
      {required ConvolverNode that});

  Future<int> webAudioApiNodeConvolverNodeNumberOfOutputs(
      {required ConvolverNode that});

  Future<void> webAudioApiNodeConvolverNodeRegistration(
      {required ConvolverNode that});

  Future<void> webAudioApiNodeConvolverNodeSetBuffer(
      {required ConvolverNode that, required AudioBuffer buffer});

  Future<void> webAudioApiNodeConvolverNodeSetNormalize(
      {required ConvolverNode that, required bool value});

  Future<void> webAudioApiNodeConvolverNodeSetOnProcessorError(
      {required ConvolverNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeDelayNodeChannelConfig({required DelayNode that});

  Future<int> webAudioApiNodeDelayNodeChannelCount({required DelayNode that});

  Future<ChannelCountMode> webAudioApiNodeDelayNodeChannelCountMode(
      {required DelayNode that});

  Future<ChannelInterpretation> webAudioApiNodeDelayNodeChannelInterpretation(
      {required DelayNode that});

  Future<void> webAudioApiNodeDelayNodeClearOnprocessorerror(
      {required DelayNode that});

  Future<void> webAudioApiNodeDelayNodeDisconnect({required DelayNode that});

  Future<void> webAudioApiNodeDelayNodeDisconnectOutput(
      {required DelayNode that, required int output});

  Future<void> webAudioApiNodeDelayNodeFrbOverrideConnect(
      {required DelayNode that, required AudioNode dest});

  Future<int> webAudioApiNodeDelayNodeNumberOfInputs({required DelayNode that});

  Future<int> webAudioApiNodeDelayNodeNumberOfOutputs(
      {required DelayNode that});

  Future<void> webAudioApiNodeDelayNodeRegistration({required DelayNode that});

  Future<void> webAudioApiNodeDelayNodeSetOnProcessorError(
      {required DelayNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeDynamicsCompressorNodeChannelConfig(
      {required DynamicsCompressorNode that});

  Future<int> webAudioApiNodeDynamicsCompressorNodeChannelCount(
      {required DynamicsCompressorNode that});

  Future<ChannelCountMode>
      webAudioApiNodeDynamicsCompressorNodeChannelCountMode(
          {required DynamicsCompressorNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeDynamicsCompressorNodeChannelInterpretation(
          {required DynamicsCompressorNode that});

  Future<void> webAudioApiNodeDynamicsCompressorNodeClearOnprocessorerror(
      {required DynamicsCompressorNode that});

  Future<void> webAudioApiNodeDynamicsCompressorNodeDisconnect(
      {required DynamicsCompressorNode that});

  Future<void> webAudioApiNodeDynamicsCompressorNodeDisconnectOutput(
      {required DynamicsCompressorNode that, required int output});

  Future<void> webAudioApiNodeDynamicsCompressorNodeFrbOverrideConnect(
      {required DynamicsCompressorNode that, required AudioNode dest});

  Future<int> webAudioApiNodeDynamicsCompressorNodeNumberOfInputs(
      {required DynamicsCompressorNode that});

  Future<int> webAudioApiNodeDynamicsCompressorNodeNumberOfOutputs(
      {required DynamicsCompressorNode that});

  Future<double> webAudioApiNodeDynamicsCompressorNodeReduction(
      {required DynamicsCompressorNode that});

  Future<void> webAudioApiNodeDynamicsCompressorNodeRegistration(
      {required DynamicsCompressorNode that});

  Future<void> webAudioApiNodeDynamicsCompressorNodeSetOnProcessorError(
      {required DynamicsCompressorNode that,
      required FutureOr<void> Function(String) callback});

  String webAudioApiEventType({required Event that});

  Future<void> webAudioApiNodeGainNodeChannelConfig({required GainNode that});

  Future<int> webAudioApiNodeGainNodeChannelCount({required GainNode that});

  Future<ChannelCountMode> webAudioApiNodeGainNodeChannelCountMode(
      {required GainNode that});

  Future<ChannelInterpretation> webAudioApiNodeGainNodeChannelInterpretation(
      {required GainNode that});

  Future<void> webAudioApiNodeGainNodeClearOnprocessorerror(
      {required GainNode that});

  Future<void> webAudioApiNodeGainNodeDisconnect({required GainNode that});

  Future<void> webAudioApiNodeGainNodeDisconnectOutput(
      {required GainNode that, required int output});

  Future<void> webAudioApiNodeGainNodeFrbOverrideConnect(
      {required GainNode that, required AudioNode dest});

  Future<int> webAudioApiNodeGainNodeNumberOfInputs({required GainNode that});

  Future<int> webAudioApiNodeGainNodeNumberOfOutputs({required GainNode that});

  Future<void> webAudioApiNodeGainNodeRegistration({required GainNode that});

  Future<void> webAudioApiNodeGainNodeSetOnProcessorError(
      {required GainNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeIirFilterNodeChannelConfig(
      {required IirFilterNode that});

  Future<int> webAudioApiNodeIirFilterNodeChannelCount(
      {required IirFilterNode that});

  Future<ChannelCountMode> webAudioApiNodeIirFilterNodeChannelCountMode(
      {required IirFilterNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeIirFilterNodeChannelInterpretation(
          {required IirFilterNode that});

  Future<void> webAudioApiNodeIirFilterNodeClearOnprocessorerror(
      {required IirFilterNode that});

  Future<void> webAudioApiNodeIirFilterNodeDisconnect(
      {required IirFilterNode that});

  Future<void> webAudioApiNodeIirFilterNodeDisconnectOutput(
      {required IirFilterNode that, required int output});

  Future<void> webAudioApiNodeIirFilterNodeFrbOverrideConnect(
      {required IirFilterNode that, required AudioNode dest});

  Future<int> webAudioApiNodeIirFilterNodeNumberOfInputs(
      {required IirFilterNode that});

  Future<int> webAudioApiNodeIirFilterNodeNumberOfOutputs(
      {required IirFilterNode that});

  Future<void> webAudioApiNodeIirFilterNodeRegistration(
      {required IirFilterNode that});

  Future<void> webAudioApiNodeIirFilterNodeSetOnProcessorError(
      {required IirFilterNode that,
      required FutureOr<void> Function(String) callback});

  int webAudioApiMaxChannels();

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeChannelConfig(
      {required MediaElementAudioSourceNode that});

  Future<int> webAudioApiNodeMediaElementAudioSourceNodeChannelCount(
      {required MediaElementAudioSourceNode that});

  Future<ChannelCountMode>
      webAudioApiNodeMediaElementAudioSourceNodeChannelCountMode(
          {required MediaElementAudioSourceNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeMediaElementAudioSourceNodeChannelInterpretation(
          {required MediaElementAudioSourceNode that});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerror(
      {required MediaElementAudioSourceNode that});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeDisconnect(
      {required MediaElementAudioSourceNode that});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeDisconnectOutput(
      {required MediaElementAudioSourceNode that, required int output});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnect(
      {required MediaElementAudioSourceNode that, required AudioNode dest});

  Future<int> webAudioApiNodeMediaElementAudioSourceNodeNumberOfInputs(
      {required MediaElementAudioSourceNode that});

  Future<int> webAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputs(
      {required MediaElementAudioSourceNode that});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeRegistration(
      {required MediaElementAudioSourceNode that});

  Future<void> webAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorError(
      {required MediaElementAudioSourceNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiMediaRecorderMediaRecorderClearOndataavailable(
      {required MediaRecorder that});

  Future<void> webAudioApiMediaRecorderMediaRecorderClearOnerror(
      {required MediaRecorder that});

  Future<void> webAudioApiMediaRecorderMediaRecorderClearOnstop(
      {required MediaRecorder that});

  Future<MediaRecorder> webAudioApiMediaRecorderMediaRecorderNew(
      {required MediaStream stream});

  Future<void> webAudioApiMediaRecorderMediaRecorderStart(
      {required MediaRecorder that});

  Future<void> webAudioApiMediaRecorderMediaRecorderStop(
      {required MediaRecorder that});

  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeChannelConfig(
      {required MediaStreamAudioDestinationNode that});

  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeChannelCount(
      {required MediaStreamAudioDestinationNode that});

  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamAudioDestinationNodeChannelCountMode(
          {required MediaStreamAudioDestinationNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretation(
          {required MediaStreamAudioDestinationNode that});

  Future<void>
      webAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerror(
          {required MediaStreamAudioDestinationNode that});

  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeDisconnect(
      {required MediaStreamAudioDestinationNode that});

  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutput(
      {required MediaStreamAudioDestinationNode that, required int output});

  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnect(
      {required MediaStreamAudioDestinationNode that, required AudioNode dest});

  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputs(
      {required MediaStreamAudioDestinationNode that});

  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputs(
      {required MediaStreamAudioDestinationNode that});

  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeRegistration(
      {required MediaStreamAudioDestinationNode that});

  Future<void>
      webAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorError(
          {required MediaStreamAudioDestinationNode that,
          required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeChannelConfig(
      {required MediaStreamAudioSourceNode that});

  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeChannelCount(
      {required MediaStreamAudioSourceNode that});

  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamAudioSourceNodeChannelCountMode(
          {required MediaStreamAudioSourceNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretation(
          {required MediaStreamAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerror(
      {required MediaStreamAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeDisconnect(
      {required MediaStreamAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutput(
      {required MediaStreamAudioSourceNode that, required int output});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnect(
      {required MediaStreamAudioSourceNode that, required AudioNode dest});

  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputs(
      {required MediaStreamAudioSourceNode that});

  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputs(
      {required MediaStreamAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeRegistration(
      {required MediaStreamAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorError(
      {required MediaStreamAudioSourceNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfig(
      {required MediaStreamTrackAudioSourceNode that});

  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCount(
      {required MediaStreamTrackAudioSourceNode that});

  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountMode(
          {required MediaStreamTrackAudioSourceNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretation(
          {required MediaStreamTrackAudioSourceNode that});

  Future<void>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerror(
          {required MediaStreamTrackAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnect(
      {required MediaStreamTrackAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutput(
      {required MediaStreamTrackAudioSourceNode that, required int output});

  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnect(
      {required MediaStreamTrackAudioSourceNode that, required AudioNode dest});

  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputs(
      {required MediaStreamTrackAudioSourceNode that});

  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputs(
      {required MediaStreamTrackAudioSourceNode that});

  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeRegistration(
      {required MediaStreamTrackAudioSourceNode that});

  Future<void>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorError(
          {required MediaStreamTrackAudioSourceNode that,
          required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiMediaStreamsMediaStreamTrackClose(
      {required MediaStreamTrack that});

  Future<MediaStreamTrackState>
      webAudioApiMediaStreamsMediaStreamTrackReadyState(
          {required MediaStreamTrack that});

  Future<List<MediaStreamTrack>>
      webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(
          {required MediaStream that});

  Future<MediaStream> webAudioApiMediaStreamsMediaStreamFromTracks(
      {required List<MediaStreamTrack> tracks});

  Future<double> crateApiMediaElementMyMediaElementCurrentTime(
      {required MediaElement that});

  Future<bool> crateApiMediaElementMyMediaElementLoop(
      {required MediaElement that});

  MediaElement crateApiMediaElementMyMediaElementNew({required String file});

  Future<void> crateApiMediaElementMyMediaElementPause(
      {required MediaElement that});

  Future<bool> crateApiMediaElementMyMediaElementPaused(
      {required MediaElement that});

  Future<void> crateApiMediaElementMyMediaElementPlay(
      {required MediaElement that});

  Future<double> crateApiMediaElementMyMediaElementPlaybackRate(
      {required MediaElement that});

  Future<void> crateApiMediaElementMyMediaElementSetCurrentTime(
      {required MediaElement that, required double value});

  Future<void> crateApiMediaElementMyMediaElementSetLoop(
      {required MediaElement that, required bool value});

  Future<void> crateApiMediaElementMyMediaElementSetPlaybackRate(
      {required MediaElement that, required double value});

  Event webAudioApiOfflineAudioCompletionEventAutoAccessorGetEvent(
      {required OfflineAudioCompletionEvent that});

  AudioBuffer
      webAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBuffer(
          {required OfflineAudioCompletionEvent that});

  void webAudioApiOfflineAudioCompletionEventAutoAccessorSetEvent(
      {required OfflineAudioCompletionEvent that, required Event event});

  void webAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBuffer(
      {required OfflineAudioCompletionEvent that,
      required AudioBuffer renderedBuffer});

  Future<void> webAudioApiContextOfflineAudioContextClearOncomplete(
      {required OfflineAudioContext that});

  Future<void> webAudioApiContextOfflineAudioContextClearOnstatechange(
      {required OfflineAudioContext that});

  Future<AnalyserNode> webAudioApiContextOfflineAudioContextCreateAnalyser(
      {required OfflineAudioContext that});

  Future<(AudioParam, AudioParamId)>
      webAudioApiContextOfflineAudioContextCreateAudioParam(
          {required OfflineAudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest});

  Future<BiquadFilterNode>
      webAudioApiContextOfflineAudioContextCreateBiquadFilter(
          {required OfflineAudioContext that});

  Future<AudioBuffer> webAudioApiContextOfflineAudioContextCreateBuffer(
      {required OfflineAudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate});

  Future<AudioBufferSourceNode>
      webAudioApiContextOfflineAudioContextCreateBufferSource(
          {required OfflineAudioContext that});

  Future<ChannelMergerNode>
      webAudioApiContextOfflineAudioContextCreateChannelMerger(
          {required OfflineAudioContext that, required int numberOfInputs});

  Future<ChannelSplitterNode>
      webAudioApiContextOfflineAudioContextCreateChannelSplitter(
          {required OfflineAudioContext that, required int numberOfOutputs});

  Future<ConstantSourceNode>
      webAudioApiContextOfflineAudioContextCreateConstantSource(
          {required OfflineAudioContext that});

  Future<ConvolverNode> webAudioApiContextOfflineAudioContextCreateConvolver(
      {required OfflineAudioContext that});

  Future<DelayNode> webAudioApiContextOfflineAudioContextCreateDelay(
      {required OfflineAudioContext that, required double maxDelayTime});

  Future<DynamicsCompressorNode>
      webAudioApiContextOfflineAudioContextCreateDynamicsCompressor(
          {required OfflineAudioContext that});

  Future<GainNode> webAudioApiContextOfflineAudioContextCreateGain(
      {required OfflineAudioContext that});

  Future<IirFilterNode> webAudioApiContextOfflineAudioContextCreateIirFilter(
      {required OfflineAudioContext that,
      required List<double> feedforward,
      required List<double> feedback});

  Future<OscillatorNode> webAudioApiContextOfflineAudioContextCreateOscillator(
      {required OfflineAudioContext that});

  Future<PannerNode> webAudioApiContextOfflineAudioContextCreatePanner(
      {required OfflineAudioContext that});

  Future<PeriodicWave> webAudioApiContextOfflineAudioContextCreatePeriodicWave(
      {required OfflineAudioContext that,
      required PeriodicWaveOptions options});

  Future<ScriptProcessorNode>
      webAudioApiContextOfflineAudioContextCreateScriptProcessor(
          {required OfflineAudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels});

  Future<StereoPannerNode>
      webAudioApiContextOfflineAudioContextCreateStereoPanner(
          {required OfflineAudioContext that});

  Future<WaveShaperNode> webAudioApiContextOfflineAudioContextCreateWaveShaper(
      {required OfflineAudioContext that});

  Future<double> webAudioApiContextOfflineAudioContextCurrentTime(
      {required OfflineAudioContext that});

  Future<AudioDestinationNode> webAudioApiContextOfflineAudioContextDestination(
      {required OfflineAudioContext that});

  Future<int> webAudioApiContextOfflineAudioContextLength(
      {required OfflineAudioContext that});

  Future<AudioListener> webAudioApiContextOfflineAudioContextListener(
      {required OfflineAudioContext that});

  Future<OfflineAudioContext> webAudioApiContextOfflineAudioContextNew(
      {required int numberOfChannels,
      required int length,
      required double sampleRate});

  Future<void> webAudioApiContextOfflineAudioContextResume(
      {required OfflineAudioContext that});

  Future<double> webAudioApiContextOfflineAudioContextSampleRate(
      {required OfflineAudioContext that});

  Future<void> webAudioApiContextOfflineAudioContextSetOnComplete(
      {required OfflineAudioContext that,
      required FutureOr<void> Function(OfflineAudioCompletionEvent) callback});

  Future<AudioBuffer> webAudioApiContextOfflineAudioContextStartRendering(
      {required OfflineAudioContext that});

  Future<AudioBuffer> webAudioApiContextOfflineAudioContextStartRenderingSync(
      {required OfflineAudioContext that});

  Future<AudioContextState> webAudioApiContextOfflineAudioContextState(
      {required OfflineAudioContext that});

  Future<void> webAudioApiContextOfflineAudioContextSuspend(
      {required OfflineAudioContext that, required double suspendTime});

  Future<void> webAudioApiNodeOscillatorNodeChannelConfig(
      {required OscillatorNode that});

  Future<int> webAudioApiNodeOscillatorNodeChannelCount(
      {required OscillatorNode that});

  Future<ChannelCountMode> webAudioApiNodeOscillatorNodeChannelCountMode(
      {required OscillatorNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeOscillatorNodeChannelInterpretation(
          {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeClearOnended(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeClearOnprocessorerror(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeDisconnect(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeDisconnectOutput(
      {required OscillatorNode that, required int output});

  Future<void> webAudioApiNodeOscillatorNodeFrbOverrideConnect(
      {required OscillatorNode that, required AudioNode dest});

  Future<int> webAudioApiNodeOscillatorNodeNumberOfInputs(
      {required OscillatorNode that});

  Future<int> webAudioApiNodeOscillatorNodeNumberOfOutputs(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeRegistration(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeSetOnEnded(
      {required OscillatorNode that,
      required FutureOr<void> Function(Event) callback});

  Future<void> webAudioApiNodeOscillatorNodeSetOnProcessorError(
      {required OscillatorNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeOscillatorNodeSetPeriodicWave(
      {required OscillatorNode that, required PeriodicWave periodicWave});

  Future<void> webAudioApiNodeOscillatorNodeSetType(
      {required OscillatorNode that, required OscillatorType type});

  Future<void> webAudioApiNodeOscillatorNodeStart(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeStartAt(
      {required OscillatorNode that, required double when});

  Future<void> webAudioApiNodeOscillatorNodeStop(
      {required OscillatorNode that});

  Future<void> webAudioApiNodeOscillatorNodeStopAt(
      {required OscillatorNode that, required double when});

  Future<OscillatorType> webAudioApiNodeOscillatorNodeType(
      {required OscillatorNode that});

  Future<void> webAudioApiNodePannerNodeChannelConfig(
      {required PannerNode that});

  Future<int> webAudioApiNodePannerNodeChannelCount({required PannerNode that});

  Future<ChannelCountMode> webAudioApiNodePannerNodeChannelCountMode(
      {required PannerNode that});

  Future<ChannelInterpretation> webAudioApiNodePannerNodeChannelInterpretation(
      {required PannerNode that});

  Future<void> webAudioApiNodePannerNodeClearOnprocessorerror(
      {required PannerNode that});

  Future<double> webAudioApiNodePannerNodeConeInnerAngle(
      {required PannerNode that});

  Future<double> webAudioApiNodePannerNodeConeOuterAngle(
      {required PannerNode that});

  Future<double> webAudioApiNodePannerNodeConeOuterGain(
      {required PannerNode that});

  Future<void> webAudioApiNodePannerNodeDisconnect({required PannerNode that});

  Future<void> webAudioApiNodePannerNodeDisconnectOutput(
      {required PannerNode that, required int output});

  Future<DistanceModelType> webAudioApiNodePannerNodeDistanceModel(
      {required PannerNode that});

  Future<void> webAudioApiNodePannerNodeFrbOverrideConnect(
      {required PannerNode that, required AudioNode dest});

  Future<double> webAudioApiNodePannerNodeMaxDistance(
      {required PannerNode that});

  Future<int> webAudioApiNodePannerNodeNumberOfInputs(
      {required PannerNode that});

  Future<int> webAudioApiNodePannerNodeNumberOfOutputs(
      {required PannerNode that});

  Future<PanningModelType> webAudioApiNodePannerNodePanningModel(
      {required PannerNode that});

  Future<double> webAudioApiNodePannerNodeRefDistance(
      {required PannerNode that});

  Future<void> webAudioApiNodePannerNodeRegistration(
      {required PannerNode that});

  Future<double> webAudioApiNodePannerNodeRolloffFactor(
      {required PannerNode that});

  Future<void> webAudioApiNodePannerNodeSetConeInnerAngle(
      {required PannerNode that, required double value});

  Future<void> webAudioApiNodePannerNodeSetConeOuterAngle(
      {required PannerNode that, required double value});

  Future<void> webAudioApiNodePannerNodeSetConeOuterGain(
      {required PannerNode that, required double value});

  Future<void> webAudioApiNodePannerNodeSetDistanceModel(
      {required PannerNode that, required DistanceModelType value});

  Future<void> webAudioApiNodePannerNodeSetMaxDistance(
      {required PannerNode that, required double value});

  Future<void> webAudioApiNodePannerNodeSetOnProcessorError(
      {required PannerNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodePannerNodeSetOrientation(
      {required PannerNode that,
      required double x,
      required double y,
      required double z});

  Future<void> webAudioApiNodePannerNodeSetPanningModel(
      {required PannerNode that, required PanningModelType value});

  Future<void> webAudioApiNodePannerNodeSetPosition(
      {required PannerNode that,
      required double x,
      required double y,
      required double z});

  Future<void> webAudioApiNodePannerNodeSetRefDistance(
      {required PannerNode that, required double value});

  Future<void> webAudioApiNodePannerNodeSetRolloffFactor(
      {required PannerNode that, required double value});

  Future<PeriodicWave> webAudioApiPeriodicWaveDefault();

  Future<int> webAudioApiNodeScriptProcessorNodeBufferSize(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeChannelConfig(
      {required ScriptProcessorNode that});

  Future<int> webAudioApiNodeScriptProcessorNodeChannelCount(
      {required ScriptProcessorNode that});

  Future<ChannelCountMode> webAudioApiNodeScriptProcessorNodeChannelCountMode(
      {required ScriptProcessorNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeScriptProcessorNodeChannelInterpretation(
          {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeClearOnaudioprocess(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeClearOnprocessorerror(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeDisconnect(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeDisconnectOutput(
      {required ScriptProcessorNode that, required int output});

  Future<void> webAudioApiNodeScriptProcessorNodeFrbOverrideConnect(
      {required ScriptProcessorNode that, required AudioNode dest});

  Future<void> webAudioApiNodeScriptProcessorNodeFrbOverrideSetOnaudioprocess(
      {required ScriptProcessorNode that,
      required FutureOr<void> Function(AudioProcessingEvent) callback});

  Future<int> webAudioApiNodeScriptProcessorNodeNumberOfInputs(
      {required ScriptProcessorNode that});

  Future<int> webAudioApiNodeScriptProcessorNodeNumberOfOutputs(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeRegistration(
      {required ScriptProcessorNode that});

  Future<void> webAudioApiNodeScriptProcessorNodeSetOnProcessorError(
      {required ScriptProcessorNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeStereoPannerNodeChannelConfig(
      {required StereoPannerNode that});

  Future<int> webAudioApiNodeStereoPannerNodeChannelCount(
      {required StereoPannerNode that});

  Future<ChannelCountMode> webAudioApiNodeStereoPannerNodeChannelCountMode(
      {required StereoPannerNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeStereoPannerNodeChannelInterpretation(
          {required StereoPannerNode that});

  Future<void> webAudioApiNodeStereoPannerNodeClearOnprocessorerror(
      {required StereoPannerNode that});

  Future<void> webAudioApiNodeStereoPannerNodeDisconnect(
      {required StereoPannerNode that});

  Future<void> webAudioApiNodeStereoPannerNodeDisconnectOutput(
      {required StereoPannerNode that, required int output});

  Future<void> webAudioApiNodeStereoPannerNodeFrbOverrideConnect(
      {required StereoPannerNode that, required AudioNode dest});

  Future<int> webAudioApiNodeStereoPannerNodeNumberOfInputs(
      {required StereoPannerNode that});

  Future<int> webAudioApiNodeStereoPannerNodeNumberOfOutputs(
      {required StereoPannerNode that});

  Future<void> webAudioApiNodeStereoPannerNodeRegistration(
      {required StereoPannerNode that});

  Future<void> webAudioApiNodeStereoPannerNodeSetOnProcessorError(
      {required StereoPannerNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeWaveShaperNodeChannelConfig(
      {required WaveShaperNode that});

  Future<int> webAudioApiNodeWaveShaperNodeChannelCount(
      {required WaveShaperNode that});

  Future<ChannelCountMode> webAudioApiNodeWaveShaperNodeChannelCountMode(
      {required WaveShaperNode that});

  Future<ChannelInterpretation>
      webAudioApiNodeWaveShaperNodeChannelInterpretation(
          {required WaveShaperNode that});

  Future<void> webAudioApiNodeWaveShaperNodeClearOnprocessorerror(
      {required WaveShaperNode that});

  Future<void> webAudioApiNodeWaveShaperNodeDisconnect(
      {required WaveShaperNode that});

  Future<void> webAudioApiNodeWaveShaperNodeDisconnectOutput(
      {required WaveShaperNode that, required int output});

  Future<void> webAudioApiNodeWaveShaperNodeFrbOverrideConnect(
      {required WaveShaperNode that, required AudioNode dest});

  Future<Float32List?> webAudioApiNodeWaveShaperNodeFrbOverrideCurve(
      {required WaveShaperNode that});

  Future<int> webAudioApiNodeWaveShaperNodeNumberOfInputs(
      {required WaveShaperNode that});

  Future<int> webAudioApiNodeWaveShaperNodeNumberOfOutputs(
      {required WaveShaperNode that});

  Future<OverSampleType> webAudioApiNodeWaveShaperNodeOversample(
      {required WaveShaperNode that});

  Future<void> webAudioApiNodeWaveShaperNodeRegistration(
      {required WaveShaperNode that});

  Future<void> webAudioApiNodeWaveShaperNodeSetCurve(
      {required WaveShaperNode that, required List<double> curve});

  Future<void> webAudioApiNodeWaveShaperNodeSetOnProcessorError(
      {required WaveShaperNode that,
      required FutureOr<void> Function(String) callback});

  Future<void> webAudioApiNodeWaveShaperNodeSetOversample(
      {required WaveShaperNode that, required OverSampleType oversample});

  Future<AnalyserOptions> webAudioApiNodeAnalyserOptionsDefault();

  Future<AudioBufferSourceOptions>
      webAudioApiNodeAudioBufferSourceOptionsDefault();

  Future<AudioContextLatencyCategory>
      webAudioApiContextAudioContextLatencyCategoryDefault();

  Future<AudioContextOptions> webAudioApiContextAudioContextOptionsDefault();

  Future<AudioNodeOptions> webAudioApiNodeAudioNodeOptionsDefault();

  Future<AudioRenderCapacityOptions>
      webAudioApiAudioRenderCapacityOptionsDefault();

  Future<BiquadFilterOptions> webAudioApiNodeBiquadFilterOptionsDefault();

  Future<BiquadFilterType> webAudioApiNodeBiquadFilterTypeDefault();

  Future<ChannelMergerOptions> webAudioApiNodeChannelMergerOptionsDefault();

  Future<ChannelSplitterOptions> webAudioApiNodeChannelSplitterOptionsDefault();

  Future<ConstantSourceOptions> webAudioApiNodeConstantSourceOptionsDefault();

  Future<ConvolverOptions> webAudioApiNodeConvolverOptionsDefault();

  Future<DelayOptions> webAudioApiNodeDelayOptionsDefault();

  Future<DistanceModelType> webAudioApiNodeDistanceModelTypeDefault();

  Future<DynamicsCompressorOptions>
      webAudioApiNodeDynamicsCompressorOptionsDefault();

  Future<void> crateApiSimpleF({required DummyStruct a});

  Future<GainOptions> webAudioApiNodeGainOptionsDefault();

  Future<MediaStream> webAudioApiMediaDevicesGetUserMediaSync(
      {required MediaStreamConstraints constraints});

  Future<void> crateApiSimpleInitApp();

  Future<OscillatorOptions> webAudioApiNodeOscillatorOptionsDefault();

  Future<OscillatorType> webAudioApiNodeOscillatorTypeDefault();

  Future<OverSampleType> webAudioApiNodeOverSampleTypeDefault();

  Future<PannerOptions> webAudioApiNodePannerOptionsDefault();

  Future<PanningModelType> webAudioApiNodePanningModelTypeDefault();

  Future<PeriodicWaveOptions> webAudioApiPeriodicWaveOptionsDefault();

  Future<StereoPannerOptions> webAudioApiNodeStereoPannerOptionsDefault();

  Future<WaveShaperOptions> webAudioApiNodeWaveShaperOptionsDefault();

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AnalyserNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AnalyserNode;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_AnalyserNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioBuffer;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioBuffer;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_AudioBufferPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioBufferSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioBufferSourceNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioBufferSourceNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioContext;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_AudioContextPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioContextRegistration;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioContextRegistration;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioContextRegistrationPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioDestinationNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioDestinationNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioDestinationNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioListener;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioListener;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioListenerPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioParam;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioParam;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_AudioParamPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioParamId;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioParamId;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_AudioParamIdPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioProcessingEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioProcessingEvent;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioProcessingEventPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioRenderCapacity;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioRenderCapacity;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioRenderCapacityPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioRenderCapacityEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioRenderCapacityEvent;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioRenderCapacityEventPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioWorkletNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioWorkletNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_AudioWorkletNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_BiquadFilterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_BiquadFilterNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_BiquadFilterNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_BlobEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_BlobEvent;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_BlobEventPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelConfig;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelConfig;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ChannelConfigPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelMergerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelMergerNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ChannelMergerNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelSplitterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelSplitterNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ChannelSplitterNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConcreteBaseAudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConcreteBaseAudioContext;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ConcreteBaseAudioContextPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConstantSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConstantSourceNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ConstantSourceNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConvolverNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConvolverNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ConvolverNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DelayNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DelayNode;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_DelayNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DummyStruct;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DummyStruct;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_DummyStructPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DynamicsCompressorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DynamicsCompressorNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_DynamicsCompressorNodePtr;

  RustArcIncrementStrongCountFnType get rust_arc_increment_strong_count_Event;

  RustArcDecrementStrongCountFnType get rust_arc_decrement_strong_count_Event;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_EventPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_GainNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_GainNode;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_GainNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_IirFilterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_IirFilterNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_IirFilterNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaElementAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaElementAudioSourceNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaElementAudioSourceNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaRecorder;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaRecorder;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaRecorderPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStream;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStream;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_MediaStreamPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamAudioDestinationNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamAudioDestinationNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaStreamAudioDestinationNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamAudioSourceNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaStreamAudioSourceNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamConstraints;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamConstraints;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaStreamConstraintsPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamTrack;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamTrack;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaStreamTrackPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamTrackAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaElement;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaElement;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_MediaElementPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OfflineAudioCompletionEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OfflineAudioCompletionEvent;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_OfflineAudioCompletionEventPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OfflineAudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OfflineAudioContext;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_OfflineAudioContextPtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OscillatorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OscillatorNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_OscillatorNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_PannerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_PannerNode;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_PannerNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_PeriodicWave;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_PeriodicWave;

  CrossPlatformFinalizerArg get rust_arc_decrement_strong_count_PeriodicWavePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ScriptProcessorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ScriptProcessorNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_ScriptProcessorNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_StereoPannerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_StereoPannerNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_StereoPannerNodePtr;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_WaveShaperNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_WaveShaperNode;

  CrossPlatformFinalizerArg
      get rust_arc_decrement_strong_count_WaveShaperNodePtr;
}

class RustLibApiImpl extends RustLibApiImplPlatform implements RustLibApi {
  RustLibApiImpl({
    required super.handler,
    required super.wire,
    required super.generalizedFrbRustBinding,
    required super.portManager,
  });

  @override
  Future<void> webAudioApiNodeAnalyserNodeChannelConfig(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 1, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeAnalyserNodeChannelCount(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 2, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeAnalyserNodeChannelCountMode(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 3, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeAnalyserNodeChannelInterpretation(
          {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 4, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "AnalyserNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAnalyserNodeClearOnprocessorerror(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 5, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "AnalyserNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAnalyserNodeDisconnect(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 6, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeDisconnectOutput(
      {required AnalyserNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 7, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<int> webAudioApiNodeAnalyserNodeFftSize({required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 8, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeFftSizeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeFftSizeConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_fft_size",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeFrbOverrideConnect(
      {required AnalyserNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 9, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<Uint8List> webAudioApiNodeAnalyserNodeFrbOverrideGetByteTimeDomainData(
      {required AnalyserNode that, required int len}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(len, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 10, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_list_prim_u_8_strict,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAnalyserNodeFrbOverrideGetByteTimeDomainDataConstMeta,
      argValues: [that, len],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeFrbOverrideGetByteTimeDomainDataConstMeta =>
          const TaskConstMeta(
            debugName:
                "AnalyserNode_frb_override_get_byte_time_domain_data(dart_style=get_byte_time_domain_data)",
            argNames: ["that", "len"],
          );

  @override
  Future<Float32List>
      webAudioApiNodeAnalyserNodeFrbOverrideGetFloatTimeDomainData(
          {required AnalyserNode that, required int len}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(len, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 11, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_list_prim_f_32_strict,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAnalyserNodeFrbOverrideGetFloatTimeDomainDataConstMeta,
      argValues: [that, len],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeFrbOverrideGetFloatTimeDomainDataConstMeta =>
          const TaskConstMeta(
            debugName:
                "AnalyserNode_frb_override_get_float_time_domain_data(dart_style=get_float_time_domain_data)",
            argNames: ["that", "len"],
          );

  @override
  Future<int> webAudioApiNodeAnalyserNodeFrequencyBinCount(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 12, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeFrequencyBinCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeFrequencyBinCountConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_frequency_bin_count",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodeAnalyserNodeMaxDecibels(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 13, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeMaxDecibelsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeMaxDecibelsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_max_decibels",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodeAnalyserNodeMinDecibels(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 14, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeMinDecibelsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeMinDecibelsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_min_decibels",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeAnalyserNodeNumberOfInputs(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 15, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeAnalyserNodeNumberOfOutputs(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 16, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeRegistration(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 17, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeSetFftSize(
      {required AnalyserNode that, required int fftSize}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(fftSize, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 18, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSetFftSizeConstMeta,
      argValues: [that, fftSize],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeSetFftSizeConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_set_fft_size",
        argNames: ["that", "fftSize"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeSetMaxDecibels(
      {required AnalyserNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 19, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSetMaxDecibelsConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeSetMaxDecibelsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_set_max_decibels",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeSetMinDecibels(
      {required AnalyserNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 20, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSetMinDecibelsConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeSetMinDecibelsConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_set_min_decibels",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeSetOnProcessorError(
      {required AnalyserNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 21, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "AnalyserNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeAnalyserNodeSetSmoothingTimeConstant(
      {required AnalyserNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 22, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSetSmoothingTimeConstantConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeSetSmoothingTimeConstantConstMeta =>
          const TaskConstMeta(
            debugName: "AnalyserNode_set_smoothing_time_constant",
            argNames: ["that", "value"],
          );

  @override
  Future<double> webAudioApiNodeAnalyserNodeSmoothingTimeConstant(
      {required AnalyserNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 23, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserNodeSmoothingTimeConstantConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAnalyserNodeSmoothingTimeConstantConstMeta =>
          const TaskConstMeta(
            debugName: "AnalyserNode_smoothing_time_constant",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeChannelConfig(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 24, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeAudioBufferSourceNodeChannelCount(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 25, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode> webAudioApiNodeAudioBufferSourceNodeChannelCountMode(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 26, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeAudioBufferSourceNodeChannelInterpretation(
          {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 27, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeClearOnended(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 28, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeClearOnendedConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeClearOnendedConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_clear_onended",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeClearOnprocessorerror(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 29, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeDisconnect(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 31, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeDisconnectOutput(
      {required AudioBufferSourceNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 32, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeFrbOverrideConnect(
      {required AudioBufferSourceNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 33, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioBufferSourceNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeFrbOverrideSetBuffer(
      {required AudioBufferSourceNode that, required AudioBuffer audioBuffer}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            audioBuffer, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 34, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeFrbOverrideSetBufferConstMeta,
      argValues: [that, audioBuffer],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeFrbOverrideSetBufferConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioBufferSourceNode_frb_override_set_buffer(dart_style=set_buffer)",
            argNames: ["that", "audioBuffer"],
          );

  @override
  Future<bool> webAudioApiNodeAudioBufferSourceNodeLoop(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 35, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_bool,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeLoopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeLoopConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_loop_",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodeAudioBufferSourceNodeLoopEnd(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 36, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeLoopEndConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeLoopEndConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_loop_end",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodeAudioBufferSourceNodeLoopStart(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 37, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeLoopStartConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeLoopStartConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_loop_start",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeAudioBufferSourceNodeNumberOfInputs(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 38, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeAudioBufferSourceNodeNumberOfOutputs(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 39, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<double> webAudioApiNodeAudioBufferSourceNodePosition(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 41, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodePositionConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodePositionConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_position",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeRegistration(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 42, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoop(
      {required AudioBufferSourceNode that, required bool value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_bool(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 43, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeSetLoopConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeSetLoopConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_set_loop",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoopEnd(
      {required AudioBufferSourceNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 44, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeSetLoopEndConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeSetLoopEndConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_set_loop_end",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeSetLoopStart(
      {required AudioBufferSourceNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 45, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeSetLoopStartConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeSetLoopStartConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_set_loop_start",
            argNames: ["that", "value"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeSetOnEnded(
      {required AudioBufferSourceNode that,
      required FutureOr<void> Function(Event) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 46, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeSetOnEndedConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeSetOnEndedConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_set_on_ended",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeSetOnProcessorError(
      {required AudioBufferSourceNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 47, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStart(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 48, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeStartConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeStartConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_start",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAt(
      {required AudioBufferSourceNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 49, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeStartAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeStartAtConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_start_at",
        argNames: ["that", "when"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAtWithOffset(
      {required AudioBufferSourceNode that,
      required double start,
      required double offset}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(start, serializer);
        sse_encode_f_64(offset, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 50, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetConstMeta,
      argValues: [that, start, offset],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetConstMeta =>
          const TaskConstMeta(
            debugName: "AudioBufferSourceNode_start_at_with_offset",
            argNames: ["that", "start", "offset"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDuration(
      {required AudioBufferSourceNode that,
      required double start,
      required double offset,
      required double duration}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(start, serializer);
        sse_encode_f_64(offset, serializer);
        sse_encode_f_64(duration, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 51, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDurationConstMeta,
      argValues: [that, start, offset, duration],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDurationConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioBufferSourceNode_start_at_with_offset_and_duration",
            argNames: ["that", "start", "offset", "duration"],
          );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStop(
      {required AudioBufferSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 52, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeStopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeStopConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_stop",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioBufferSourceNodeStopAt(
      {required AudioBufferSourceNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 53, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceNodeStopAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceNodeStopAtConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBufferSourceNode_stop_at",
        argNames: ["that", "when"],
      );

  @override
  Future<double> webAudioApiAudioBufferDuration({required AudioBuffer that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 54, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferDurationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferDurationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_duration",
        argNames: ["that"],
      );

  @override
  Future<AudioBuffer> webAudioApiAudioBufferFrom(
      {required List<Float32List> samples, required double sampleRate}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_list_list_prim_f_32_strict(samples, serializer);
        sse_encode_f_32(sampleRate, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 55, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferFromConstMeta,
      argValues: [samples, sampleRate],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferFromConstMeta => const TaskConstMeta(
        debugName: "AudioBuffer_from",
        argNames: ["samples", "sampleRate"],
      );

  @override
  Future<void> webAudioApiAudioBufferGetChannelData(
      {required AudioBuffer that, required int channelNumber}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        sse_encode_CastedPrimitive_usize(channelNumber, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 56, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferGetChannelDataConstMeta,
      argValues: [that, channelNumber],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferGetChannelDataConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_get_channel_data",
        argNames: ["that", "channelNumber"],
      );

  @override
  Future<void> webAudioApiAudioBufferGetChannelDataMut(
      {required AudioBuffer that, required int channelNumber}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        sse_encode_CastedPrimitive_usize(channelNumber, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 57, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferGetChannelDataMutConstMeta,
      argValues: [that, channelNumber],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferGetChannelDataMutConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_get_channel_data_mut",
        argNames: ["that", "channelNumber"],
      );

  @override
  Future<int> webAudioApiAudioBufferLength({required AudioBuffer that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 58, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferLengthConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferLengthConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_length",
        argNames: ["that"],
      );

  @override
  Future<AudioBuffer> webAudioApiAudioBufferNew(
      {required AudioBufferOptions options}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_box_autoadd_audio_buffer_options(options, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 59, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferNewConstMeta,
      argValues: [options],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferNewConstMeta => const TaskConstMeta(
        debugName: "AudioBuffer_new",
        argNames: ["options"],
      );

  @override
  Future<int> webAudioApiAudioBufferNumberOfChannels(
      {required AudioBuffer that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 60, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferNumberOfChannelsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferNumberOfChannelsConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_number_of_channels",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiAudioBufferSampleRate({required AudioBuffer that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 61, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioBufferSampleRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioBufferSampleRateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioBuffer_sample_rate",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiContextAudioContextBaseLatency(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 62, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextBaseLatencyConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextBaseLatencyConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_base_latency",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextClearOnsinkchange(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 63, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextClearOnsinkchangeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextClearOnsinkchangeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_clear_onsinkchange",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextClearOnstatechange(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 64, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextClearOnstatechangeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextClearOnstatechangeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_clear_onstatechange",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiContextAudioContextClose(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 65, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCloseConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCloseConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_close",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextCloseSync(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 66, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCloseSyncConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCloseSyncConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_close_sync",
        argNames: ["that"],
      );

  @override
  Future<AnalyserNode> webAudioApiContextAudioContextCreateAnalyser(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 67, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateAnalyserConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateAnalyserConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_analyser",
        argNames: ["that"],
      );

  @override
  Future<(AudioParam, AudioParamId)>
      webAudioApiContextAudioContextCreateAudioParam(
          {required AudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_box_autoadd_audio_param_descriptor(opts, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
            dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 68, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateAudioParamConstMeta,
      argValues: [that, opts, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateAudioParamConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_audio_param",
        argNames: ["that", "opts", "dest"],
      );

  @override
  Future<BiquadFilterNode> webAudioApiContextAudioContextCreateBiquadFilter(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 69, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateBiquadFilterConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateBiquadFilterConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_biquad_filter",
            argNames: ["that"],
          );

  @override
  Future<AudioBuffer> webAudioApiContextAudioContextCreateBuffer(
      {required AudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfChannels, serializer);
        sse_encode_CastedPrimitive_usize(length, serializer);
        sse_encode_f_32(sampleRate, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 70, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateBufferConstMeta,
      argValues: [that, numberOfChannels, length, sampleRate],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateBufferConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_buffer",
        argNames: ["that", "numberOfChannels", "length", "sampleRate"],
      );

  @override
  Future<AudioBufferSourceNode>
      webAudioApiContextAudioContextCreateBufferSource(
          {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 71, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateBufferSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateBufferSourceConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_buffer_source",
            argNames: ["that"],
          );

  @override
  Future<ChannelMergerNode> webAudioApiContextAudioContextCreateChannelMerger(
      {required AudioContext that, required int numberOfInputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 72, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateChannelMergerConstMeta,
      argValues: [that, numberOfInputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateChannelMergerConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_channel_merger",
            argNames: ["that", "numberOfInputs"],
          );

  @override
  Future<ChannelSplitterNode>
      webAudioApiContextAudioContextCreateChannelSplitter(
          {required AudioContext that, required int numberOfOutputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 73, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateChannelSplitterConstMeta,
      argValues: [that, numberOfOutputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateChannelSplitterConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_channel_splitter",
            argNames: ["that", "numberOfOutputs"],
          );

  @override
  Future<ConstantSourceNode> webAudioApiContextAudioContextCreateConstantSource(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 74, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateConstantSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateConstantSourceConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_constant_source",
            argNames: ["that"],
          );

  @override
  Future<ConvolverNode> webAudioApiContextAudioContextCreateConvolver(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 75, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateConvolverConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateConvolverConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_convolver",
        argNames: ["that"],
      );

  @override
  Future<DelayNode> webAudioApiContextAudioContextCreateDelay(
      {required AudioContext that, required double maxDelayTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_f_64(maxDelayTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 76, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateDelayConstMeta,
      argValues: [that, maxDelayTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateDelayConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_delay",
        argNames: ["that", "maxDelayTime"],
      );

  @override
  Future<DynamicsCompressorNode>
      webAudioApiContextAudioContextCreateDynamicsCompressor(
          {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 77, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextAudioContextCreateDynamicsCompressorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateDynamicsCompressorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_dynamics_compressor",
            argNames: ["that"],
          );

  @override
  Future<GainNode> webAudioApiContextAudioContextCreateGain(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 78, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateGainConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateGainConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_gain",
        argNames: ["that"],
      );

  @override
  Future<IirFilterNode> webAudioApiContextAudioContextCreateIirFilter(
      {required AudioContext that,
      required List<double> feedforward,
      required List<double> feedback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_list_prim_f_64_loose(feedforward, serializer);
        sse_encode_list_prim_f_64_loose(feedback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 79, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateIirFilterConstMeta,
      argValues: [that, feedforward, feedback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateIirFilterConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_iir_filter",
        argNames: ["that", "feedforward", "feedback"],
      );

  @override
  Future<MediaStreamAudioDestinationNode>
      webAudioApiContextAudioContextCreateMediaStreamDestination(
          {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 80, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextAudioContextCreateMediaStreamDestinationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateMediaStreamDestinationConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_media_stream_destination",
            argNames: ["that"],
          );

  @override
  Future<MediaStreamAudioSourceNode>
      webAudioApiContextAudioContextCreateMediaStreamSource(
          {required AudioContext that, required MediaStream media}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
            media, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 81, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextAudioContextCreateMediaStreamSourceConstMeta,
      argValues: [that, media],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateMediaStreamSourceConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_media_stream_source",
            argNames: ["that", "media"],
          );

  @override
  Future<MediaStreamTrackAudioSourceNode>
      webAudioApiContextAudioContextCreateMediaStreamTrackSource(
          {required AudioContext that, required MediaStreamTrack media}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
            media, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 82, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextAudioContextCreateMediaStreamTrackSourceConstMeta,
      argValues: [that, media],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateMediaStreamTrackSourceConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_media_stream_track_source",
            argNames: ["that", "media"],
          );

  @override
  Future<OscillatorNode> webAudioApiContextAudioContextCreateOscillator(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 83, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateOscillatorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateOscillatorConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_oscillator",
        argNames: ["that"],
      );

  @override
  Future<PannerNode> webAudioApiContextAudioContextCreatePanner(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 84, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreatePannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreatePannerConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_panner",
        argNames: ["that"],
      );

  @override
  Future<PeriodicWave> webAudioApiContextAudioContextCreatePeriodicWave(
      {required AudioContext that, required PeriodicWaveOptions options}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_box_autoadd_periodic_wave_options(options, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 85, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreatePeriodicWaveConstMeta,
      argValues: [that, options],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreatePeriodicWaveConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_periodic_wave",
            argNames: ["that", "options"],
          );

  @override
  Future<ScriptProcessorNode>
      webAudioApiContextAudioContextCreateScriptProcessor(
          {required AudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(bufferSize, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputChannels, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputChannels, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 86, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateScriptProcessorConstMeta,
      argValues: [
        that,
        bufferSize,
        numberOfInputChannels,
        numberOfOutputChannels
      ],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateScriptProcessorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_script_processor",
            argNames: [
              "that",
              "bufferSize",
              "numberOfInputChannels",
              "numberOfOutputChannels"
            ],
          );

  @override
  Future<StereoPannerNode> webAudioApiContextAudioContextCreateStereoPanner(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 87, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateStereoPannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextCreateStereoPannerConstMeta =>
          const TaskConstMeta(
            debugName: "AudioContext_create_stereo_panner",
            argNames: ["that"],
          );

  @override
  Future<WaveShaperNode> webAudioApiContextAudioContextCreateWaveShaper(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 88, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCreateWaveShaperConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCreateWaveShaperConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_create_wave_shaper",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiContextAudioContextCurrentTime(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 89, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextCurrentTimeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextCurrentTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_current_time",
        argNames: ["that"],
      );

  @override
  Future<AudioContext> webAudioApiContextAudioContextDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 90, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_default",
        argNames: [],
      );

  @override
  Future<AudioDestinationNode> webAudioApiContextAudioContextDestination(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 91, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextDestinationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextDestinationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_destination",
        argNames: ["that"],
      );

  @override
  Future<MediaElementAudioSourceNode>
      webAudioApiContextAudioContextFrbOverrideCreateMediaElementSource(
          {required AudioContext that, required MediaElement mediaElement}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            mediaElement, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 92, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextAudioContextFrbOverrideCreateMediaElementSourceConstMeta,
      argValues: [that, mediaElement],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextFrbOverrideCreateMediaElementSourceConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioContext_frb_override_create_media_element_source(dart_style=create_media_element_source)",
            argNames: ["that", "mediaElement"],
          );

  @override
  Future<AudioBuffer>
      webAudioApiContextAudioContextFrbOverrideDecodeAudioDataSync(
          {required AudioContext that, required String inputPath}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_String(inputPath, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 93, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: sse_decode_AnyhowException,
      ),
      constMeta:
          kWebAudioApiContextAudioContextFrbOverrideDecodeAudioDataSyncConstMeta,
      argValues: [that, inputPath],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextFrbOverrideDecodeAudioDataSyncConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioContext_frb_override_decode_audio_data_sync(dart_style=decode_audio_data_sync)",
            argNames: ["that", "inputPath"],
          );

  @override
  Future<AudioListener> webAudioApiContextAudioContextListener(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 94, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextListenerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextListenerConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_listener",
        argNames: ["that"],
      );

  @override
  AudioContext webAudioApiContextAudioContextNew(
      {required AudioContextOptions options}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_box_autoadd_audio_context_options(options, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 95)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextNewConstMeta,
      argValues: [options],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextNewConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_new",
        argNames: ["options"],
      );

  @override
  Future<double> webAudioApiContextAudioContextOutputLatency(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 96, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextOutputLatencyConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextOutputLatencyConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_output_latency",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextRenderCapacity(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 97, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextRenderCapacityConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextRenderCapacityConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_render_capacity",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextResumeSync(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 98, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextResumeSyncConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextResumeSyncConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_resume_sync",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiContextAudioContextSampleRate(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 99, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextSampleRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSampleRateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_sample_rate",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextSetOnStateChange(
      {required AudioContext that,
      required FutureOr<void> Function(Event) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 100, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextSetOnStateChangeConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSetOnStateChangeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_set_on_state_change",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiContextAudioContextSetSinkId(
      {required AudioContext that, required String sinkId}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        sse_encode_String(sinkId, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 101, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: sse_decode_AnyhowException,
      ),
      constMeta: kWebAudioApiContextAudioContextSetSinkIdConstMeta,
      argValues: [that, sinkId],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSetSinkIdConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_set_sink_id",
        argNames: ["that", "sinkId"],
      );

  @override
  Future<String> webAudioApiContextAudioContextSinkId(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 102, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_String,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextSinkIdConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSinkIdConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_sink_id",
        argNames: ["that"],
      );

  @override
  Future<AudioContextState> webAudioApiContextAudioContextState(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 103, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_context_state,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextStateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextStateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_state",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextSuspend(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 104, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextSuspendConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSuspendConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_suspend",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextAudioContextSuspendSync(
      {required AudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 105, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextSuspendSyncConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextSuspendSyncConstMeta =>
      const TaskConstMeta(
        debugName: "AudioContext_suspend_sync",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeChannelConfig(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 106, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeAudioDestinationNodeChannelCount(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 107, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioDestinationNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "AudioDestinationNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeAudioDestinationNodeChannelCountMode(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 108, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeAudioDestinationNodeChannelInterpretation(
          {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 109, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioDestinationNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeClearOnprocessorerror(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 110, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioDestinationNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeDisconnect(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 111, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioDestinationNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "AudioDestinationNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeDisconnectOutput(
      {required AudioDestinationNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 112, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeFrbOverrideConnect(
      {required AudioDestinationNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 113, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioDestinationNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioDestinationNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeAudioDestinationNodeMaxChannelCount(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 114, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeMaxChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeMaxChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_max_channel_count",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeAudioDestinationNodeNumberOfInputs(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 115, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeAudioDestinationNodeNumberOfOutputs(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 116, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeRegistration(
      {required AudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 117, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioDestinationNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioDestinationNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioDestinationNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeAudioDestinationNodeSetOnProcessorError(
      {required AudioDestinationNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 118, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeAudioDestinationNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeAudioDestinationNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioDestinationNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<AutomationRate> webAudioApiAudioParamAutomationRate(
      {required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 128, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_automation_rate,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamAutomationRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamAutomationRateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_automation_rate",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamCancelAndHoldAtTime(
      {required AudioParam that, required double cancelTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_64(cancelTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 129, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamCancelAndHoldAtTimeConstMeta,
      argValues: [that, cancelTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamCancelAndHoldAtTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_cancel_and_hold_at_time",
        argNames: ["that", "cancelTime"],
      );

  @override
  Future<void> webAudioApiAudioParamCancelScheduledValues(
      {required AudioParam that, required double cancelTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_64(cancelTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 130, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamCancelScheduledValuesConstMeta,
      argValues: [that, cancelTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamCancelScheduledValuesConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_cancel_scheduled_values",
        argNames: ["that", "cancelTime"],
      );

  @override
  Future<void> webAudioApiAudioParamChannelConfig({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 131, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiAudioParamChannelCount({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 132, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiAudioParamChannelCountMode(
      {required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 133, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation> webAudioApiAudioParamChannelInterpretation(
      {required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 134, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamChannelInterpretationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_channel_interpretation",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamClearOnprocessorerror(
      {required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 135, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamClearOnprocessorerrorConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_clear_onprocessorerror",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiAudioParamDefaultValue({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 136, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamDefaultValueConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamDefaultValueConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_default_value",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamDisconnect({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 137, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamDisconnectOutput(
      {required AudioParam that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 138, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiAudioParamExponentialRampToValueAtTime(
      {required AudioParam that,
      required double value,
      required double endTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_32(value, serializer);
        sse_encode_f_64(endTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 139, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamExponentialRampToValueAtTimeConstMeta,
      argValues: [that, value, endTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioParamExponentialRampToValueAtTimeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioParam_exponential_ramp_to_value_at_time",
            argNames: ["that", "value", "endTime"],
          );

  @override
  Future<void> webAudioApiAudioParamFrbOverrideConnect(
      {required AudioParam that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 140, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<void> webAudioApiAudioParamLinearRampToValueAtTime(
      {required AudioParam that,
      required double value,
      required double endTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_32(value, serializer);
        sse_encode_f_64(endTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 141, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamLinearRampToValueAtTimeConstMeta,
      argValues: [that, value, endTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamLinearRampToValueAtTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_linear_ramp_to_value_at_time",
        argNames: ["that", "value", "endTime"],
      );

  @override
  Future<double> webAudioApiAudioParamMaxValue({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 142, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamMaxValueConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamMaxValueConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_max_value",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiAudioParamMinValue({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 143, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamMinValueConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamMinValueConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_min_value",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiAudioParamNumberOfInputs({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 144, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiAudioParamNumberOfOutputs({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 145, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamRegistration({required AudioParam that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 146, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioParamSetAutomationRate(
      {required AudioParam that, required AutomationRate value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_automation_rate(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 147, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetAutomationRateConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetAutomationRateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_automation_rate",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiAudioParamSetOnProcessorError(
      {required AudioParam that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 148, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiAudioParamSetTargetAtTime(
      {required AudioParam that,
      required double value,
      required double startTime,
      required double timeConstant}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_32(value, serializer);
        sse_encode_f_64(startTime, serializer);
        sse_encode_f_64(timeConstant, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 149, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetTargetAtTimeConstMeta,
      argValues: [that, value, startTime, timeConstant],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetTargetAtTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_target_at_time",
        argNames: ["that", "value", "startTime", "timeConstant"],
      );

  @override
  void webAudioApiAudioParamSetValue(
      {required AudioParam that, required double value}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_32(value, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 150)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetValueConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetValueConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_value(dart_style=value)",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiAudioParamSetValueAtTime(
      {required AudioParam that,
      required double value,
      required double startTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_f_32(value, serializer);
        sse_encode_f_64(startTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 151, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetValueAtTimeConstMeta,
      argValues: [that, value, startTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetValueAtTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_value_at_time",
        argNames: ["that", "value", "startTime"],
      );

  @override
  Future<void> webAudioApiAudioParamSetValueCurveAtTime(
      {required AudioParam that,
      required List<double> values,
      required double startTime,
      required double duration}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        sse_encode_list_prim_f_32_loose(values, serializer);
        sse_encode_f_64(startTime, serializer);
        sse_encode_f_64(duration, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 152, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamSetValueCurveAtTimeConstMeta,
      argValues: [that, values, startTime, duration],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamSetValueCurveAtTimeConstMeta =>
      const TaskConstMeta(
        debugName: "AudioParam_set_value_curve_at_time",
        argNames: ["that", "values", "startTime", "duration"],
      );

  @override
  double webAudioApiAudioParamValue({required AudioParam that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 153)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioParamValueConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioParamValueConstMeta => const TaskConstMeta(
        debugName: "AudioParam_value",
        argNames: ["that"],
      );

  @override
  AudioBuffer webAudioApiAudioProcessingEventAutoAccessorGetInputBuffer(
      {required AudioProcessingEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 154)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorGetInputBufferConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorGetInputBufferConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_get_input_buffer",
            argNames: ["that"],
          );

  @override
  AudioBuffer webAudioApiAudioProcessingEventAutoAccessorGetOutputBuffer(
      {required AudioProcessingEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 155)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorGetOutputBufferConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorGetOutputBufferConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_get_output_buffer",
            argNames: ["that"],
          );

  @override
  double webAudioApiAudioProcessingEventAutoAccessorGetPlaybackTime(
      {required AudioProcessingEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 156)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorGetPlaybackTimeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorGetPlaybackTimeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_get_playback_time",
            argNames: ["that"],
          );

  @override
  void webAudioApiAudioProcessingEventAutoAccessorSetInputBuffer(
      {required AudioProcessingEvent that, required AudioBuffer inputBuffer}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            inputBuffer, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 157)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorSetInputBufferConstMeta,
      argValues: [that, inputBuffer],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorSetInputBufferConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_set_input_buffer",
            argNames: ["that", "inputBuffer"],
          );

  @override
  void webAudioApiAudioProcessingEventAutoAccessorSetOutputBuffer(
      {required AudioProcessingEvent that, required AudioBuffer outputBuffer}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            outputBuffer, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 158)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorSetOutputBufferConstMeta,
      argValues: [that, outputBuffer],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorSetOutputBufferConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_set_output_buffer",
            argNames: ["that", "outputBuffer"],
          );

  @override
  void webAudioApiAudioProcessingEventAutoAccessorSetPlaybackTime(
      {required AudioProcessingEvent that, required double playbackTime}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
            that, serializer);
        sse_encode_f_64(playbackTime, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 159)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioProcessingEventAutoAccessorSetPlaybackTimeConstMeta,
      argValues: [that, playbackTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioProcessingEventAutoAccessorSetPlaybackTimeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioProcessingEvent_auto_accessor_set_playback_time",
            argNames: ["that", "playbackTime"],
          );

  @override
  double webAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoad(
      {required AudioRenderCapacityEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 160)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoadConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoadConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioRenderCapacityEvent_auto_accessor_get_average_load",
            argNames: ["that"],
          );

  @override
  Event webAudioApiAudioRenderCapacityEventAutoAccessorGetEvent(
      {required AudioRenderCapacityEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 161)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorGetEventConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorGetEventConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_get_event",
            argNames: ["that"],
          );

  @override
  double webAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoad(
      {required AudioRenderCapacityEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 162)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoadConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoadConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_get_peak_load",
            argNames: ["that"],
          );

  @override
  double webAudioApiAudioRenderCapacityEventAutoAccessorGetTimestamp(
      {required AudioRenderCapacityEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 163)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorGetTimestampConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorGetTimestampConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_get_timestamp",
            argNames: ["that"],
          );

  @override
  double webAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatio(
      {required AudioRenderCapacityEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 164)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatioConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatioConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioRenderCapacityEvent_auto_accessor_get_underrun_ratio",
            argNames: ["that"],
          );

  @override
  void webAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoad(
      {required AudioRenderCapacityEvent that, required double averageLoad}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        sse_encode_f_64(averageLoad, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 165)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoadConstMeta,
      argValues: [that, averageLoad],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoadConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioRenderCapacityEvent_auto_accessor_set_average_load",
            argNames: ["that", "averageLoad"],
          );

  @override
  void webAudioApiAudioRenderCapacityEventAutoAccessorSetEvent(
      {required AudioRenderCapacityEvent that, required Event event}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
            event, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 166)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorSetEventConstMeta,
      argValues: [that, event],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorSetEventConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_set_event",
            argNames: ["that", "event"],
          );

  @override
  void webAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoad(
      {required AudioRenderCapacityEvent that, required double peakLoad}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        sse_encode_f_64(peakLoad, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 167)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoadConstMeta,
      argValues: [that, peakLoad],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoadConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_set_peak_load",
            argNames: ["that", "peakLoad"],
          );

  @override
  void webAudioApiAudioRenderCapacityEventAutoAccessorSetTimestamp(
      {required AudioRenderCapacityEvent that, required double timestamp}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        sse_encode_f_64(timestamp, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 168)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorSetTimestampConstMeta,
      argValues: [that, timestamp],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorSetTimestampConstMeta =>
          const TaskConstMeta(
            debugName: "AudioRenderCapacityEvent_auto_accessor_set_timestamp",
            argNames: ["that", "timestamp"],
          );

  @override
  void webAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatio(
      {required AudioRenderCapacityEvent that, required double underrunRatio}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
            that, serializer);
        sse_encode_f_64(underrunRatio, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 169)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatioConstMeta,
      argValues: [that, underrunRatio],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatioConstMeta =>
          const TaskConstMeta(
            debugName:
                "AudioRenderCapacityEvent_auto_accessor_set_underrun_ratio",
            argNames: ["that", "underrunRatio"],
          );

  @override
  Future<void> webAudioApiAudioRenderCapacityClearOnupdate(
      {required AudioRenderCapacity that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 170, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioRenderCapacityClearOnupdateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioRenderCapacityClearOnupdateConstMeta =>
      const TaskConstMeta(
        debugName: "AudioRenderCapacity_clear_onupdate",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiAudioRenderCapacityStart(
      {required AudioRenderCapacity that,
      required AudioRenderCapacityOptions options}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
            that, serializer);
        sse_encode_box_autoadd_audio_render_capacity_options(
            options, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 171, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioRenderCapacityStartConstMeta,
      argValues: [that, options],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioRenderCapacityStartConstMeta =>
      const TaskConstMeta(
        debugName: "AudioRenderCapacity_start",
        argNames: ["that", "options"],
      );

  @override
  Future<void> webAudioApiAudioRenderCapacityStop(
      {required AudioRenderCapacity that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 172, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioRenderCapacityStopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioRenderCapacityStopConstMeta =>
      const TaskConstMeta(
        debugName: "AudioRenderCapacity_stop",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeChannelConfig(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 173, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiWorkletAudioWorkletNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "AudioWorkletNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiWorkletAudioWorkletNodeChannelCount(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 174, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiWorkletAudioWorkletNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "AudioWorkletNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiWorkletAudioWorkletNodeChannelCountMode(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 175, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiWorkletAudioWorkletNodeChannelInterpretation(
          {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 176, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiWorkletAudioWorkletNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeClearOnprocessorerror(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 177, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiWorkletAudioWorkletNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeDisconnect(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 178, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiWorkletAudioWorkletNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "AudioWorkletNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeDisconnectOutput(
      {required AudioWorkletNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 179, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<int> webAudioApiWorkletAudioWorkletNodeNumberOfInputs(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 180, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiWorkletAudioWorkletNodeNumberOfOutputs(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 181, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiWorkletAudioWorkletNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "AudioWorkletNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeParameters(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 182, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeParametersConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiWorkletAudioWorkletNodeParametersConstMeta =>
      const TaskConstMeta(
        debugName: "AudioWorkletNode_parameters",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiWorkletAudioWorkletNodeRegistration(
      {required AudioWorkletNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 183, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiWorkletAudioWorkletNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiWorkletAudioWorkletNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "AudioWorkletNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeChannelConfig(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 184, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeBiquadFilterNodeChannelCount(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 185, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeBiquadFilterNodeChannelCountMode(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 186, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeBiquadFilterNodeChannelInterpretation(
          {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 187, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeBiquadFilterNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "BiquadFilterNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeClearOnprocessorerror(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 188, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeBiquadFilterNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "BiquadFilterNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeDisconnect(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 190, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeDisconnectOutput(
      {required BiquadFilterNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 191, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeFrbOverrideConnect(
      {required BiquadFilterNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 192, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeBiquadFilterNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "BiquadFilterNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeBiquadFilterNodeNumberOfInputs(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 195, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeBiquadFilterNodeNumberOfOutputs(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 196, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeRegistration(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 198, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeSetOnProcessorError(
      {required BiquadFilterNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 199, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeBiquadFilterNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "BiquadFilterNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeBiquadFilterNodeSetType(
      {required BiquadFilterNode that, required BiquadFilterType type}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        sse_encode_biquad_filter_type(type, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 200, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeSetTypeConstMeta,
      argValues: [that, type],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeSetTypeConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_set_type",
        argNames: ["that", "type"],
      );

  @override
  Future<BiquadFilterType> webAudioApiNodeBiquadFilterNodeType(
      {required BiquadFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 201, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_biquad_filter_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterNodeTypeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterNodeTypeConstMeta =>
      const TaskConstMeta(
        debugName: "BiquadFilterNode_type_",
        argNames: ["that"],
      );

  @override
  Uint8List webAudioApiMediaRecorderBlobEventAutoAccessorGetBlob(
      {required BlobEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 202)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_list_prim_u_8_strict,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderBlobEventAutoAccessorGetBlobConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorGetBlobConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_get_blob",
            argNames: ["that"],
          );

  @override
  Event webAudioApiMediaRecorderBlobEventAutoAccessorGetEvent(
      {required BlobEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 203)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaRecorderBlobEventAutoAccessorGetEventConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorGetEventConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_get_event",
            argNames: ["that"],
          );

  @override
  double webAudioApiMediaRecorderBlobEventAutoAccessorGetTimecode(
      {required BlobEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 204)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaRecorderBlobEventAutoAccessorGetTimecodeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorGetTimecodeConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_get_timecode",
            argNames: ["that"],
          );

  @override
  void webAudioApiMediaRecorderBlobEventAutoAccessorSetBlob(
      {required BlobEvent that, required Uint8List blob}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        sse_encode_list_prim_u_8_strict(blob, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 205)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderBlobEventAutoAccessorSetBlobConstMeta,
      argValues: [that, blob],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorSetBlobConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_set_blob",
            argNames: ["that", "blob"],
          );

  @override
  void webAudioApiMediaRecorderBlobEventAutoAccessorSetEvent(
      {required BlobEvent that, required Event event}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
            event, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 206)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaRecorderBlobEventAutoAccessorSetEventConstMeta,
      argValues: [that, event],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorSetEventConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_set_event",
            argNames: ["that", "event"],
          );

  @override
  void webAudioApiMediaRecorderBlobEventAutoAccessorSetTimecode(
      {required BlobEvent that, required double timecode}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
            that, serializer);
        sse_encode_f_64(timecode, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 207)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaRecorderBlobEventAutoAccessorSetTimecodeConstMeta,
      argValues: [that, timecode],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderBlobEventAutoAccessorSetTimecodeConstMeta =>
          const TaskConstMeta(
            debugName: "BlobEvent_auto_accessor_set_timecode",
            argNames: ["that", "timecode"],
          );

  @override
  Future<ChannelConfig> webAudioApiNodeChannelConfigDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 208, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelConfigDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelConfigDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelConfig_default",
        argNames: [],
      );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeChannelConfig(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 209, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeChannelMergerNodeChannelCount(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 210, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeChannelMergerNodeChannelCountMode(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 211, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelMergerNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeChannelMergerNodeChannelInterpretation(
          {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 212, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeChannelMergerNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelMergerNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeClearOnprocessorerror(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 213, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeChannelMergerNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelMergerNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeDisconnect(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 214, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeDisconnectOutput(
      {required ChannelMergerNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 215, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelMergerNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeFrbOverrideConnect(
      {required ChannelMergerNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 216, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "ChannelMergerNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeChannelMergerNodeNumberOfInputs(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 217, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeChannelMergerNodeNumberOfOutputs(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 218, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeRegistration(
      {required ChannelMergerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 219, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelMergerNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeChannelMergerNodeSetOnProcessorError(
      {required ChannelMergerNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 220, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelMergerNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelMergerNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeChannelConfig(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 221, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelSplitterNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelSplitterNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeChannelSplitterNodeChannelCount(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 222, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelSplitterNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelSplitterNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeChannelSplitterNodeChannelCountMode(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 223, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeChannelSplitterNodeChannelInterpretation(
          {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 224, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeChannelSplitterNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeClearOnprocessorerror(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 225, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeChannelSplitterNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeDisconnect(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 226, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelSplitterNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelSplitterNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeDisconnectOutput(
      {required ChannelSplitterNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 227, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeFrbOverrideConnect(
      {required ChannelSplitterNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 228, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "ChannelSplitterNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeChannelSplitterNodeNumberOfInputs(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 229, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeChannelSplitterNodeNumberOfOutputs(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 230, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeRegistration(
      {required ChannelSplitterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 231, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelSplitterNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "ChannelSplitterNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeChannelSplitterNodeSetOnProcessorError(
      {required ChannelSplitterNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 232, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeChannelSplitterNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeChannelSplitterNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "ChannelSplitterNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiContextConcreteBaseAudioContextClearOnstatechange(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 233, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextClearOnstatechangeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextClearOnstatechangeConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_clear_onstatechange",
            argNames: ["that"],
          );

  @override
  Future<AnalyserNode> webAudioApiContextConcreteBaseAudioContextCreateAnalyser(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 234, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateAnalyserConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateAnalyserConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_analyser",
            argNames: ["that"],
          );

  @override
  Future<(AudioParam, AudioParamId)>
      webAudioApiContextConcreteBaseAudioContextCreateAudioParam(
          {required ConcreteBaseAudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_box_autoadd_audio_param_descriptor(opts, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
            dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 235, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateAudioParamConstMeta,
      argValues: [that, opts, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateAudioParamConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_audio_param",
            argNames: ["that", "opts", "dest"],
          );

  @override
  Future<BiquadFilterNode>
      webAudioApiContextConcreteBaseAudioContextCreateBiquadFilter(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 236, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateBiquadFilterConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateBiquadFilterConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_biquad_filter",
            argNames: ["that"],
          );

  @override
  Future<AudioBuffer> webAudioApiContextConcreteBaseAudioContextCreateBuffer(
      {required ConcreteBaseAudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfChannels, serializer);
        sse_encode_CastedPrimitive_usize(length, serializer);
        sse_encode_f_32(sampleRate, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 237, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateBufferConstMeta,
      argValues: [that, numberOfChannels, length, sampleRate],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateBufferConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_buffer",
            argNames: ["that", "numberOfChannels", "length", "sampleRate"],
          );

  @override
  Future<AudioBufferSourceNode>
      webAudioApiContextConcreteBaseAudioContextCreateBufferSource(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 238, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateBufferSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateBufferSourceConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_buffer_source",
            argNames: ["that"],
          );

  @override
  Future<ChannelMergerNode>
      webAudioApiContextConcreteBaseAudioContextCreateChannelMerger(
          {required ConcreteBaseAudioContext that,
          required int numberOfInputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 239, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateChannelMergerConstMeta,
      argValues: [that, numberOfInputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateChannelMergerConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_channel_merger",
            argNames: ["that", "numberOfInputs"],
          );

  @override
  Future<ChannelSplitterNode>
      webAudioApiContextConcreteBaseAudioContextCreateChannelSplitter(
          {required ConcreteBaseAudioContext that,
          required int numberOfOutputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 240, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateChannelSplitterConstMeta,
      argValues: [that, numberOfOutputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateChannelSplitterConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_channel_splitter",
            argNames: ["that", "numberOfOutputs"],
          );

  @override
  Future<ConstantSourceNode>
      webAudioApiContextConcreteBaseAudioContextCreateConstantSource(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 241, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateConstantSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateConstantSourceConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_constant_source",
            argNames: ["that"],
          );

  @override
  Future<ConvolverNode>
      webAudioApiContextConcreteBaseAudioContextCreateConvolver(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 242, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateConvolverConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateConvolverConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_convolver",
            argNames: ["that"],
          );

  @override
  Future<DelayNode> webAudioApiContextConcreteBaseAudioContextCreateDelay(
      {required ConcreteBaseAudioContext that, required double maxDelayTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_f_64(maxDelayTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 243, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateDelayConstMeta,
      argValues: [that, maxDelayTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateDelayConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_delay",
            argNames: ["that", "maxDelayTime"],
          );

  @override
  Future<DynamicsCompressorNode>
      webAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressor(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 244, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressorConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_dynamics_compressor",
            argNames: ["that"],
          );

  @override
  Future<GainNode> webAudioApiContextConcreteBaseAudioContextCreateGain(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 245, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextConcreteBaseAudioContextCreateGainConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateGainConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_gain",
            argNames: ["that"],
          );

  @override
  Future<IirFilterNode>
      webAudioApiContextConcreteBaseAudioContextCreateIirFilter(
          {required ConcreteBaseAudioContext that,
          required List<double> feedforward,
          required List<double> feedback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_list_prim_f_64_loose(feedforward, serializer);
        sse_encode_list_prim_f_64_loose(feedback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 246, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateIirFilterConstMeta,
      argValues: [that, feedforward, feedback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateIirFilterConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_iir_filter",
            argNames: ["that", "feedforward", "feedback"],
          );

  @override
  Future<OscillatorNode>
      webAudioApiContextConcreteBaseAudioContextCreateOscillator(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 247, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateOscillatorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateOscillatorConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_oscillator",
            argNames: ["that"],
          );

  @override
  Future<PannerNode> webAudioApiContextConcreteBaseAudioContextCreatePanner(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 248, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreatePannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreatePannerConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_panner",
            argNames: ["that"],
          );

  @override
  Future<PeriodicWave>
      webAudioApiContextConcreteBaseAudioContextCreatePeriodicWave(
          {required ConcreteBaseAudioContext that,
          required PeriodicWaveOptions options}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_box_autoadd_periodic_wave_options(options, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 249, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreatePeriodicWaveConstMeta,
      argValues: [that, options],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreatePeriodicWaveConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_periodic_wave",
            argNames: ["that", "options"],
          );

  @override
  Future<ScriptProcessorNode>
      webAudioApiContextConcreteBaseAudioContextCreateScriptProcessor(
          {required ConcreteBaseAudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(bufferSize, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputChannels, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputChannels, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 250, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateScriptProcessorConstMeta,
      argValues: [
        that,
        bufferSize,
        numberOfInputChannels,
        numberOfOutputChannels
      ],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateScriptProcessorConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_script_processor",
            argNames: [
              "that",
              "bufferSize",
              "numberOfInputChannels",
              "numberOfOutputChannels"
            ],
          );

  @override
  Future<StereoPannerNode>
      webAudioApiContextConcreteBaseAudioContextCreateStereoPanner(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 251, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateStereoPannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateStereoPannerConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_stereo_panner",
            argNames: ["that"],
          );

  @override
  Future<WaveShaperNode>
      webAudioApiContextConcreteBaseAudioContextCreateWaveShaper(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 252, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCreateWaveShaperConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCreateWaveShaperConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_create_wave_shaper",
            argNames: ["that"],
          );

  @override
  Future<double> webAudioApiContextConcreteBaseAudioContextCurrentTime(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 253, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextCurrentTimeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextCurrentTimeConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_current_time",
            argNames: ["that"],
          );

  @override
  Future<AudioDestinationNode>
      webAudioApiContextConcreteBaseAudioContextDestination(
          {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 254, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextDestinationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextDestinationConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_destination",
            argNames: ["that"],
          );

  @override
  Future<AudioListener> webAudioApiContextConcreteBaseAudioContextListener(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 255, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextConcreteBaseAudioContextListenerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextListenerConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_listener",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiContextConcreteBaseAudioContextMarkCycleBreaker(
      {required ConcreteBaseAudioContext that,
      required AudioContextRegistration reg}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
            reg, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 256, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextConcreteBaseAudioContextMarkCycleBreakerConstMeta,
      argValues: [that, reg],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextMarkCycleBreakerConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_mark_cycle_breaker",
            argNames: ["that", "reg"],
          );

  @override
  Future<double> webAudioApiContextConcreteBaseAudioContextSampleRate(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 257, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextConcreteBaseAudioContextSampleRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextConcreteBaseAudioContextSampleRateConstMeta =>
          const TaskConstMeta(
            debugName: "ConcreteBaseAudioContext_sample_rate",
            argNames: ["that"],
          );

  @override
  Future<AudioContextState> webAudioApiContextConcreteBaseAudioContextState(
      {required ConcreteBaseAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 258, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_context_state,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextConcreteBaseAudioContextStateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextConcreteBaseAudioContextStateConstMeta =>
      const TaskConstMeta(
        debugName: "ConcreteBaseAudioContext_state",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeChannelConfig(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 259, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeConstantSourceNodeChannelCount(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 260, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeConstantSourceNodeChannelCountMode(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 261, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeConstantSourceNodeChannelInterpretation(
          {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 262, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeConstantSourceNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeClearOnended(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 263, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeClearOnendedConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeClearOnendedConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_clear_onended",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeClearOnprocessorerror(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 264, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeConstantSourceNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeDisconnect(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 265, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeDisconnectOutput(
      {required ConstantSourceNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 266, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeFrbOverrideConnect(
      {required ConstantSourceNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 267, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "ConstantSourceNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeConstantSourceNodeNumberOfInputs(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 268, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeConstantSourceNodeNumberOfOutputs(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 269, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeRegistration(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 271, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeSetOnEnded(
      {required ConstantSourceNode that,
      required FutureOr<void> Function(Event) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 272, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeSetOnEndedConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeSetOnEndedConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_set_on_ended",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeSetOnProcessorError(
      {required ConstantSourceNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 273, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConstantSourceNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "ConstantSourceNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeStart(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 274, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeStartConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeStartConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_start",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeStartAt(
      {required ConstantSourceNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 275, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeStartAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeStartAtConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_start_at",
        argNames: ["that", "when"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeStop(
      {required ConstantSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 276, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeStopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeStopConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_stop",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConstantSourceNodeStopAt(
      {required ConstantSourceNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 277, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceNodeStopAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceNodeStopAtConstMeta =>
      const TaskConstMeta(
        debugName: "ConstantSourceNode_stop_at",
        argNames: ["that", "when"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeChannelConfig(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 278, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeConvolverNodeChannelCount(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 279, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeConvolverNodeChannelCountMode(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 280, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeConvolverNodeChannelInterpretation(
          {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 281, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConvolverNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "ConvolverNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeConvolverNodeClearOnprocessorerror(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 282, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeConvolverNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "ConvolverNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeConvolverNodeDisconnect(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 283, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeDisconnectOutput(
      {required ConvolverNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 284, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeFrbOverrideConnect(
      {required ConvolverNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 285, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<bool> webAudioApiNodeConvolverNodeNormalize(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 286, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_bool,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeNormalizeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeNormalizeConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_normalize",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeConvolverNodeNumberOfInputs(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 287, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeConvolverNodeNumberOfOutputs(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 288, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeRegistration(
      {required ConvolverNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 289, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeSetBuffer(
      {required ConvolverNode that, required AudioBuffer buffer}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            buffer, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 290, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeSetBufferConstMeta,
      argValues: [that, buffer],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeSetBufferConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_set_buffer",
        argNames: ["that", "buffer"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeSetNormalize(
      {required ConvolverNode that, required bool value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        sse_encode_bool(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 291, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeSetNormalizeConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeSetNormalizeConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_set_normalize",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodeConvolverNodeSetOnProcessorError(
      {required ConvolverNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 292, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "ConvolverNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeChannelConfig(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 293, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeDelayNodeChannelCount({required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 294, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeDelayNodeChannelCountMode(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 295, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation> webAudioApiNodeDelayNodeChannelInterpretation(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 296, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeChannelInterpretationConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_channel_interpretation",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeClearOnprocessorerror(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 297, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeClearOnprocessorerrorConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_clear_onprocessorerror",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeDisconnect({required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 299, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeDisconnectOutput(
      {required DelayNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 300, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeFrbOverrideConnect(
      {required DelayNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 301, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<int> webAudioApiNodeDelayNodeNumberOfInputs(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 302, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeDelayNodeNumberOfOutputs(
      {required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 303, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeRegistration({required DelayNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 304, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDelayNodeSetOnProcessorError(
      {required DelayNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 305, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "DelayNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeChannelConfig(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 307, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeDynamicsCompressorNodeChannelCount(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 308, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode>
      webAudioApiNodeDynamicsCompressorNodeChannelCountMode(
          {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 309, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeDynamicsCompressorNodeChannelInterpretation(
          {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 310, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeClearOnprocessorerror(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 311, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeDisconnect(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 312, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDynamicsCompressorNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "DynamicsCompressorNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeDisconnectOutput(
      {required DynamicsCompressorNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 313, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeFrbOverrideConnect(
      {required DynamicsCompressorNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 314, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "DynamicsCompressorNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeDynamicsCompressorNodeNumberOfInputs(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 316, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeDynamicsCompressorNodeNumberOfOutputs(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 317, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<double> webAudioApiNodeDynamicsCompressorNodeReduction(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 319, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeReductionConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDynamicsCompressorNodeReductionConstMeta =>
      const TaskConstMeta(
        debugName: "DynamicsCompressorNode_reduction",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeRegistration(
      {required DynamicsCompressorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 320, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeDynamicsCompressorNodeSetOnProcessorError(
      {required DynamicsCompressorNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 322, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeDynamicsCompressorNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeDynamicsCompressorNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "DynamicsCompressorNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  String webAudioApiEventType({required Event that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 324)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_String,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiEventTypeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiEventTypeConstMeta => const TaskConstMeta(
        debugName: "Event_type_",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeChannelConfig({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 325, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeGainNodeChannelCount({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 326, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeGainNodeChannelCountMode(
      {required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 327, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation> webAudioApiNodeGainNodeChannelInterpretation(
      {required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 328, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeChannelInterpretationConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_channel_interpretation",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeClearOnprocessorerror(
      {required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 329, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeClearOnprocessorerrorConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_clear_onprocessorerror",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeDisconnect({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 330, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeDisconnectOutput(
      {required GainNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 331, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeFrbOverrideConnect(
      {required GainNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 332, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<int> webAudioApiNodeGainNodeNumberOfInputs({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 334, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeGainNodeNumberOfOutputs({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 335, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeRegistration({required GainNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 336, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeGainNodeSetOnProcessorError(
      {required GainNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 337, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "GainNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeIirFilterNodeChannelConfig(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 338, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeIirFilterNodeChannelCount(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 339, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeIirFilterNodeChannelCountMode(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 340, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeIirFilterNodeChannelInterpretation(
          {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 341, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeIirFilterNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "IirFilterNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeIirFilterNodeClearOnprocessorerror(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 342, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeIirFilterNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "IirFilterNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeIirFilterNodeDisconnect(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 343, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeIirFilterNodeDisconnectOutput(
      {required IirFilterNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 344, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeIirFilterNodeFrbOverrideConnect(
      {required IirFilterNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 345, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<int> webAudioApiNodeIirFilterNodeNumberOfInputs(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 346, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeIirFilterNodeNumberOfOutputs(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 347, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeIirFilterNodeRegistration(
      {required IirFilterNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 348, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeIirFilterNodeSetOnProcessorError(
      {required IirFilterNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 349, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeIirFilterNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeIirFilterNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "IirFilterNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  int webAudioApiMaxChannels() {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 350)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMaxChannelsConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMaxChannelsConstMeta => const TaskConstMeta(
        debugName: "MAX_CHANNELS",
        argNames: [],
      );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeChannelConfig(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 351, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaElementAudioSourceNodeChannelCount(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 352, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode>
      webAudioApiNodeMediaElementAudioSourceNodeChannelCountMode(
          {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 353, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeMediaElementAudioSourceNodeChannelInterpretation(
          {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 354, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerror(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 355, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeDisconnect(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 356, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeMediaElementAudioSourceNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeDisconnectConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_disconnect",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeDisconnectOutput(
      {required MediaElementAudioSourceNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 357, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnect(
      {required MediaElementAudioSourceNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 358, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "MediaElementAudioSourceNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeMediaElementAudioSourceNodeNumberOfInputs(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 359, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputs(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 360, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeRegistration(
      {required MediaElementAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 361, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorError(
      {required MediaElementAudioSourceNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 362, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaElementAudioSourceNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiMediaRecorderMediaRecorderClearOndataavailable(
      {required MediaRecorder that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 363, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaRecorderMediaRecorderClearOndataavailableConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderMediaRecorderClearOndataavailableConstMeta =>
          const TaskConstMeta(
            debugName: "MediaRecorder_clear_ondataavailable",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiMediaRecorderMediaRecorderClearOnerror(
      {required MediaRecorder that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 364, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderMediaRecorderClearOnerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderMediaRecorderClearOnerrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaRecorder_clear_onerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiMediaRecorderMediaRecorderClearOnstop(
      {required MediaRecorder that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 365, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderMediaRecorderClearOnstopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaRecorderMediaRecorderClearOnstopConstMeta =>
          const TaskConstMeta(
            debugName: "MediaRecorder_clear_onstop",
            argNames: ["that"],
          );

  @override
  Future<MediaRecorder> webAudioApiMediaRecorderMediaRecorderNew(
      {required MediaStream stream}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
            stream, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 366, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderMediaRecorderNewConstMeta,
      argValues: [stream],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaRecorderMediaRecorderNewConstMeta =>
      const TaskConstMeta(
        debugName: "MediaRecorder_new",
        argNames: ["stream"],
      );

  @override
  Future<void> webAudioApiMediaRecorderMediaRecorderStart(
      {required MediaRecorder that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 367, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderMediaRecorderStartConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaRecorderMediaRecorderStartConstMeta =>
      const TaskConstMeta(
        debugName: "MediaRecorder_start",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiMediaRecorderMediaRecorderStop(
      {required MediaRecorder that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 368, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaRecorderMediaRecorderStopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaRecorderMediaRecorderStopConstMeta =>
      const TaskConstMeta(
        debugName: "MediaRecorder_stop",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeChannelConfig(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 369, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeChannelCount(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 370, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamAudioDestinationNodeChannelCountMode(
          {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 371, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretation(
          {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 372, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void>
      webAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerror(
          {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 373, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeDisconnect(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 374, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeDisconnectConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_disconnect",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutput(
      {required MediaStreamAudioDestinationNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 375, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnect(
      {required MediaStreamAudioDestinationNode that,
      required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 376, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "MediaStreamAudioDestinationNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputs(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 377, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputs(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 378, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioDestinationNodeRegistration(
      {required MediaStreamAudioDestinationNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 379, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void>
      webAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorError(
          {required MediaStreamAudioDestinationNode that,
          required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 380, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioDestinationNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeChannelConfig(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 382, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeChannelCount(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 383, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamAudioSourceNodeChannelCountMode(
          {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 384, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretation(
          {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 385, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerror(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 386, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeDisconnect(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 387, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeMediaStreamAudioSourceNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeDisconnectConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_disconnect",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutput(
      {required MediaStreamAudioSourceNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 388, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnect(
      {required MediaStreamAudioSourceNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 389, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "MediaStreamAudioSourceNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputs(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 390, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputs(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 391, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeRegistration(
      {required MediaStreamAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 392, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorError(
      {required MediaStreamAudioSourceNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 393, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamAudioSourceNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfig(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 394, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfigConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_channel_config",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCount(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 395, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_channel_count",
            argNames: ["that"],
          );

  @override
  Future<ChannelCountMode>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountMode(
          {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 396, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretation(
          {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 397, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerror(
          {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 398, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnect(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 399, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_disconnect",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutput(
      {required MediaStreamTrackAudioSourceNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 400, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnect(
      {required MediaStreamTrackAudioSourceNode that,
      required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 401, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "MediaStreamTrackAudioSourceNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputs(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 402, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputs(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 403, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeMediaStreamTrackAudioSourceNodeRegistration(
      {required MediaStreamTrackAudioSourceNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 404, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeRegistrationConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_registration",
            argNames: ["that"],
          );

  @override
  Future<void>
      webAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorError(
          {required MediaStreamTrackAudioSourceNode that,
          required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 405, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrackAudioSourceNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiMediaStreamsMediaStreamTrackClose(
      {required MediaStreamTrack that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 406, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaStreamsMediaStreamTrackCloseConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaStreamsMediaStreamTrackCloseConstMeta =>
      const TaskConstMeta(
        debugName: "MediaStreamTrack_close",
        argNames: ["that"],
      );

  @override
  Future<MediaStreamTrackState>
      webAudioApiMediaStreamsMediaStreamTrackReadyState(
          {required MediaStreamTrack that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 407, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_media_stream_track_state,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaStreamsMediaStreamTrackReadyStateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaStreamsMediaStreamTrackReadyStateConstMeta =>
          const TaskConstMeta(
            debugName: "MediaStreamTrack_ready_state",
            argNames: ["that"],
          );

  @override
  Future<List<MediaStreamTrack>>
      webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(
          {required MediaStream that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 408, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_list_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiMediaStreamsMediaStreamFrbOverrideGetTracksConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiMediaStreamsMediaStreamFrbOverrideGetTracksConstMeta =>
          const TaskConstMeta(
            debugName:
                "MediaStream_frb_override_get_tracks(dart_style=get_tracks)",
            argNames: ["that"],
          );

  @override
  Future<MediaStream> webAudioApiMediaStreamsMediaStreamFromTracks(
      {required List<MediaStreamTrack> tracks}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_list_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
            tracks, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 409, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaStreamsMediaStreamFromTracksConstMeta,
      argValues: [tracks],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaStreamsMediaStreamFromTracksConstMeta =>
      const TaskConstMeta(
        debugName: "MediaStream_from_tracks",
        argNames: ["tracks"],
      );

  @override
  Future<double> crateApiMediaElementMyMediaElementCurrentTime(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 410, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementCurrentTimeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementCurrentTimeConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_current_time",
        argNames: ["that"],
      );

  @override
  Future<bool> crateApiMediaElementMyMediaElementLoop(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 411, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_bool,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementLoopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementLoopConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_loop_",
        argNames: ["that"],
      );

  @override
  MediaElement crateApiMediaElementMyMediaElementNew({required String file}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_String(file, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 412)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement,
        decodeErrorData: sse_decode_AnyhowException,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementNewConstMeta,
      argValues: [file],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementNewConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_new",
        argNames: ["file"],
      );

  @override
  Future<void> crateApiMediaElementMyMediaElementPause(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 413, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementPauseConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementPauseConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_pause",
        argNames: ["that"],
      );

  @override
  Future<bool> crateApiMediaElementMyMediaElementPaused(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 414, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_bool,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementPausedConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementPausedConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_paused",
        argNames: ["that"],
      );

  @override
  Future<void> crateApiMediaElementMyMediaElementPlay(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 415, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementPlayConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementPlayConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_play",
        argNames: ["that"],
      );

  @override
  Future<double> crateApiMediaElementMyMediaElementPlaybackRate(
      {required MediaElement that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 416, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementPlaybackRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementPlaybackRateConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_playback_rate",
        argNames: ["that"],
      );

  @override
  Future<void> crateApiMediaElementMyMediaElementSetCurrentTime(
      {required MediaElement that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 417, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementSetCurrentTimeConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kCrateApiMediaElementMyMediaElementSetCurrentTimeConstMeta =>
          const TaskConstMeta(
            debugName: "MyMediaElement_set_current_time",
            argNames: ["that", "value"],
          );

  @override
  Future<void> crateApiMediaElementMyMediaElementSetLoop(
      {required MediaElement that, required bool value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        sse_encode_bool(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 418, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementSetLoopConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiMediaElementMyMediaElementSetLoopConstMeta =>
      const TaskConstMeta(
        debugName: "MyMediaElement_set_loop",
        argNames: ["that", "value"],
      );

  @override
  Future<void> crateApiMediaElementMyMediaElementSetPlaybackRate(
      {required MediaElement that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 419, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiMediaElementMyMediaElementSetPlaybackRateConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kCrateApiMediaElementMyMediaElementSetPlaybackRateConstMeta =>
          const TaskConstMeta(
            debugName: "MyMediaElement_set_playback_rate",
            argNames: ["that", "value"],
          );

  @override
  Event webAudioApiOfflineAudioCompletionEventAutoAccessorGetEvent(
      {required OfflineAudioCompletionEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 420)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiOfflineAudioCompletionEventAutoAccessorGetEventConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiOfflineAudioCompletionEventAutoAccessorGetEventConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioCompletionEvent_auto_accessor_get_event",
            argNames: ["that"],
          );

  @override
  AudioBuffer
      webAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBuffer(
          {required OfflineAudioCompletionEvent that}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
            that, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 421)!;
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBufferConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBufferConstMeta =>
          const TaskConstMeta(
            debugName:
                "OfflineAudioCompletionEvent_auto_accessor_get_rendered_buffer",
            argNames: ["that"],
          );

  @override
  void webAudioApiOfflineAudioCompletionEventAutoAccessorSetEvent(
      {required OfflineAudioCompletionEvent that, required Event event}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
            event, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 422)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiOfflineAudioCompletionEventAutoAccessorSetEventConstMeta,
      argValues: [that, event],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiOfflineAudioCompletionEventAutoAccessorSetEventConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioCompletionEvent_auto_accessor_set_event",
            argNames: ["that", "event"],
          );

  @override
  void webAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBuffer(
      {required OfflineAudioCompletionEvent that,
      required AudioBuffer renderedBuffer}) {
    return handler.executeSync(SyncTask(
      callFfi: () {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            renderedBuffer, serializer);
        return pdeCallFfi(generalizedFrbRustBinding, serializer, funcId: 423)!;
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBufferConstMeta,
      argValues: [that, renderedBuffer],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBufferConstMeta =>
          const TaskConstMeta(
            debugName:
                "OfflineAudioCompletionEvent_auto_accessor_set_rendered_buffer",
            argNames: ["that", "renderedBuffer"],
          );

  @override
  Future<void> webAudioApiContextOfflineAudioContextClearOncomplete(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 424, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextClearOncompleteConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextClearOncompleteConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_clear_oncomplete",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiContextOfflineAudioContextClearOnstatechange(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 425, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextClearOnstatechangeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextClearOnstatechangeConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_clear_onstatechange",
            argNames: ["that"],
          );

  @override
  Future<AnalyserNode> webAudioApiContextOfflineAudioContextCreateAnalyser(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 426, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateAnalyserConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateAnalyserConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_analyser",
            argNames: ["that"],
          );

  @override
  Future<(AudioParam, AudioParamId)>
      webAudioApiContextOfflineAudioContextCreateAudioParam(
          {required OfflineAudioContext that,
          required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_box_autoadd_audio_param_descriptor(opts, serializer);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
            dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 427, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateAudioParamConstMeta,
      argValues: [that, opts, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateAudioParamConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_audio_param",
            argNames: ["that", "opts", "dest"],
          );

  @override
  Future<BiquadFilterNode>
      webAudioApiContextOfflineAudioContextCreateBiquadFilter(
          {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 428, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateBiquadFilterConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateBiquadFilterConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_biquad_filter",
            argNames: ["that"],
          );

  @override
  Future<AudioBuffer> webAudioApiContextOfflineAudioContextCreateBuffer(
      {required OfflineAudioContext that,
      required int numberOfChannels,
      required int length,
      required double sampleRate}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfChannels, serializer);
        sse_encode_CastedPrimitive_usize(length, serializer);
        sse_encode_f_32(sampleRate, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 429, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateBufferConstMeta,
      argValues: [that, numberOfChannels, length, sampleRate],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateBufferConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_buffer",
            argNames: ["that", "numberOfChannels", "length", "sampleRate"],
          );

  @override
  Future<AudioBufferSourceNode>
      webAudioApiContextOfflineAudioContextCreateBufferSource(
          {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 430, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateBufferSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateBufferSourceConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_buffer_source",
            argNames: ["that"],
          );

  @override
  Future<ChannelMergerNode>
      webAudioApiContextOfflineAudioContextCreateChannelMerger(
          {required OfflineAudioContext that, required int numberOfInputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 431, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateChannelMergerConstMeta,
      argValues: [that, numberOfInputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateChannelMergerConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_channel_merger",
            argNames: ["that", "numberOfInputs"],
          );

  @override
  Future<ChannelSplitterNode>
      webAudioApiContextOfflineAudioContextCreateChannelSplitter(
          {required OfflineAudioContext that, required int numberOfOutputs}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputs, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 432, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateChannelSplitterConstMeta,
      argValues: [that, numberOfOutputs],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateChannelSplitterConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_channel_splitter",
            argNames: ["that", "numberOfOutputs"],
          );

  @override
  Future<ConstantSourceNode>
      webAudioApiContextOfflineAudioContextCreateConstantSource(
          {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 433, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateConstantSourceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateConstantSourceConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_constant_source",
            argNames: ["that"],
          );

  @override
  Future<ConvolverNode> webAudioApiContextOfflineAudioContextCreateConvolver(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 434, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateConvolverConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateConvolverConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_convolver",
            argNames: ["that"],
          );

  @override
  Future<DelayNode> webAudioApiContextOfflineAudioContextCreateDelay(
      {required OfflineAudioContext that, required double maxDelayTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_f_64(maxDelayTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 435, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateDelayConstMeta,
      argValues: [that, maxDelayTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateDelayConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_delay",
            argNames: ["that", "maxDelayTime"],
          );

  @override
  Future<DynamicsCompressorNode>
      webAudioApiContextOfflineAudioContextCreateDynamicsCompressor(
          {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 436, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateDynamicsCompressorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateDynamicsCompressorConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_dynamics_compressor",
            argNames: ["that"],
          );

  @override
  Future<GainNode> webAudioApiContextOfflineAudioContextCreateGain(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 437, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateGainConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextCreateGainConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_create_gain",
        argNames: ["that"],
      );

  @override
  Future<IirFilterNode> webAudioApiContextOfflineAudioContextCreateIirFilter(
      {required OfflineAudioContext that,
      required List<double> feedforward,
      required List<double> feedback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_list_prim_f_64_loose(feedforward, serializer);
        sse_encode_list_prim_f_64_loose(feedback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 438, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreateIirFilterConstMeta,
      argValues: [that, feedforward, feedback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateIirFilterConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_iir_filter",
            argNames: ["that", "feedforward", "feedback"],
          );

  @override
  Future<OscillatorNode> webAudioApiContextOfflineAudioContextCreateOscillator(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 439, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateOscillatorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateOscillatorConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_oscillator",
            argNames: ["that"],
          );

  @override
  Future<PannerNode> webAudioApiContextOfflineAudioContextCreatePanner(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 440, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCreatePannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreatePannerConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_panner",
            argNames: ["that"],
          );

  @override
  Future<PeriodicWave> webAudioApiContextOfflineAudioContextCreatePeriodicWave(
      {required OfflineAudioContext that,
      required PeriodicWaveOptions options}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_box_autoadd_periodic_wave_options(options, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 441, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreatePeriodicWaveConstMeta,
      argValues: [that, options],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreatePeriodicWaveConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_periodic_wave",
            argNames: ["that", "options"],
          );

  @override
  Future<ScriptProcessorNode>
      webAudioApiContextOfflineAudioContextCreateScriptProcessor(
          {required OfflineAudioContext that,
          required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_CastedPrimitive_usize(bufferSize, serializer);
        sse_encode_CastedPrimitive_usize(numberOfInputChannels, serializer);
        sse_encode_CastedPrimitive_usize(numberOfOutputChannels, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 442, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateScriptProcessorConstMeta,
      argValues: [
        that,
        bufferSize,
        numberOfInputChannels,
        numberOfOutputChannels
      ],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateScriptProcessorConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_script_processor",
            argNames: [
              "that",
              "bufferSize",
              "numberOfInputChannels",
              "numberOfOutputChannels"
            ],
          );

  @override
  Future<StereoPannerNode>
      webAudioApiContextOfflineAudioContextCreateStereoPanner(
          {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 443, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateStereoPannerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateStereoPannerConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_stereo_panner",
            argNames: ["that"],
          );

  @override
  Future<WaveShaperNode> webAudioApiContextOfflineAudioContextCreateWaveShaper(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 444, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextCreateWaveShaperConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCreateWaveShaperConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_create_wave_shaper",
            argNames: ["that"],
          );

  @override
  Future<double> webAudioApiContextOfflineAudioContextCurrentTime(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 445, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextCurrentTimeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextCurrentTimeConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_current_time",
            argNames: ["that"],
          );

  @override
  Future<AudioDestinationNode> webAudioApiContextOfflineAudioContextDestination(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 446, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextDestinationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextDestinationConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_destination",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiContextOfflineAudioContextLength(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 447, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextLengthConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextLengthConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_length",
        argNames: ["that"],
      );

  @override
  Future<AudioListener> webAudioApiContextOfflineAudioContextListener(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 448, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextListenerConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextListenerConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_listener",
        argNames: ["that"],
      );

  @override
  Future<OfflineAudioContext> webAudioApiContextOfflineAudioContextNew(
      {required int numberOfChannels,
      required int length,
      required double sampleRate}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_CastedPrimitive_usize(numberOfChannels, serializer);
        sse_encode_CastedPrimitive_usize(length, serializer);
        sse_encode_f_32(sampleRate, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 449, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextNewConstMeta,
      argValues: [numberOfChannels, length, sampleRate],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextNewConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_new",
        argNames: ["numberOfChannels", "length", "sampleRate"],
      );

  @override
  Future<void> webAudioApiContextOfflineAudioContextResume(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 450, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextResumeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextResumeConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_resume",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiContextOfflineAudioContextSampleRate(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 451, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_32,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextSampleRateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextSampleRateConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_sample_rate",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextOfflineAudioContextSetOnComplete(
      {required OfflineAudioContext that,
      required FutureOr<void> Function(OfflineAudioCompletionEvent) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 452, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextSetOnCompleteConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextSetOnCompleteConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_set_on_complete",
            argNames: ["that", "callback"],
          );

  @override
  Future<AudioBuffer> webAudioApiContextOfflineAudioContextStartRendering(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 453, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextStartRenderingConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextStartRenderingConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_start_rendering",
            argNames: ["that"],
          );

  @override
  Future<AudioBuffer> webAudioApiContextOfflineAudioContextStartRenderingSync(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 454, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiContextOfflineAudioContextStartRenderingSyncConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextOfflineAudioContextStartRenderingSyncConstMeta =>
          const TaskConstMeta(
            debugName: "OfflineAudioContext_start_rendering_sync",
            argNames: ["that"],
          );

  @override
  Future<AudioContextState> webAudioApiContextOfflineAudioContextState(
      {required OfflineAudioContext that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 455, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_context_state,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextStateConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextStateConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_state",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiContextOfflineAudioContextSuspend(
      {required OfflineAudioContext that, required double suspendTime}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
            that, serializer);
        sse_encode_f_64(suspendTime, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 456, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextOfflineAudioContextSuspendConstMeta,
      argValues: [that, suspendTime],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextOfflineAudioContextSuspendConstMeta =>
      const TaskConstMeta(
        debugName: "OfflineAudioContext_suspend",
        argNames: ["that", "suspendTime"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeChannelConfig(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 457, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeOscillatorNodeChannelCount(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 458, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeOscillatorNodeChannelCountMode(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 459, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeOscillatorNodeChannelInterpretation(
          {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 460, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeOscillatorNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "OscillatorNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeOscillatorNodeClearOnended(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 461, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeClearOnendedConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeClearOnendedConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_clear_onended",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeClearOnprocessorerror(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 462, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeOscillatorNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "OscillatorNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeOscillatorNodeDisconnect(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 464, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeDisconnectOutput(
      {required OscillatorNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 465, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeFrbOverrideConnect(
      {required OscillatorNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 466, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<int> webAudioApiNodeOscillatorNodeNumberOfInputs(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 468, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeOscillatorNodeNumberOfOutputs(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 469, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeRegistration(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 470, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeSetOnEnded(
      {required OscillatorNode that,
      required FutureOr<void> Function(Event) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 471, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeSetOnEndedConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeSetOnEndedConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_set_on_ended",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeSetOnProcessorError(
      {required OscillatorNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 472, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeOscillatorNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "OscillatorNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeOscillatorNodeSetPeriodicWave(
      {required OscillatorNode that, required PeriodicWave periodicWave}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
            periodicWave, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 473, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeSetPeriodicWaveConstMeta,
      argValues: [that, periodicWave],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeSetPeriodicWaveConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_set_periodic_wave",
        argNames: ["that", "periodicWave"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeSetType(
      {required OscillatorNode that, required OscillatorType type}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_oscillator_type(type, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 474, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeSetTypeConstMeta,
      argValues: [that, type],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeSetTypeConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_set_type",
        argNames: ["that", "type"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeStart(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 475, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeStartConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeStartConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_start",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeStartAt(
      {required OscillatorNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 476, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeStartAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeStartAtConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_start_at",
        argNames: ["that", "when"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeStop(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 477, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeStopConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeStopConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_stop",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeOscillatorNodeStopAt(
      {required OscillatorNode that, required double when}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        sse_encode_f_64(when, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 478, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeStopAtConstMeta,
      argValues: [that, when],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeStopAtConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_stop_at",
        argNames: ["that", "when"],
      );

  @override
  Future<OscillatorType> webAudioApiNodeOscillatorNodeType(
      {required OscillatorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 479, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_oscillator_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorNodeTypeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorNodeTypeConstMeta =>
      const TaskConstMeta(
        debugName: "OscillatorNode_type_",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeChannelConfig(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 480, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodePannerNodeChannelCount(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 481, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodePannerNodeChannelCountMode(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 482, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation> webAudioApiNodePannerNodeChannelInterpretation(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 483, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeChannelInterpretationConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_channel_interpretation",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeClearOnprocessorerror(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 484, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeClearOnprocessorerrorConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_clear_onprocessorerror",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeConeInnerAngle(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 485, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeConeInnerAngleConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeConeInnerAngleConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_cone_inner_angle",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeConeOuterAngle(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 486, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeConeOuterAngleConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeConeOuterAngleConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_cone_outer_angle",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeConeOuterGain(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 487, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeConeOuterGainConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeConeOuterGainConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_cone_outer_gain",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeDisconnect({required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 488, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeDisconnectOutput(
      {required PannerNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 489, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<DistanceModelType> webAudioApiNodePannerNodeDistanceModel(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 490, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_distance_model_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeDistanceModelConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeDistanceModelConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_distance_model",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeFrbOverrideConnect(
      {required PannerNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 491, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeMaxDistance(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 492, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeMaxDistanceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeMaxDistanceConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_max_distance",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodePannerNodeNumberOfInputs(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 493, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodePannerNodeNumberOfOutputs(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 494, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<PanningModelType> webAudioApiNodePannerNodePanningModel(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 498, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_panning_model_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodePanningModelConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodePanningModelConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_panning_model",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeRefDistance(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 502, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeRefDistanceConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeRefDistanceConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_ref_distance",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeRegistration(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 503, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_registration",
        argNames: ["that"],
      );

  @override
  Future<double> webAudioApiNodePannerNodeRolloffFactor(
      {required PannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 504, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_f_64,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeRolloffFactorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeRolloffFactorConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_rolloff_factor",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetConeInnerAngle(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 505, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetConeInnerAngleConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetConeInnerAngleConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_cone_inner_angle",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetConeOuterAngle(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 506, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetConeOuterAngleConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetConeOuterAngleConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_cone_outer_angle",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetConeOuterGain(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 507, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetConeOuterGainConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetConeOuterGainConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_cone_outer_gain",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetDistanceModel(
      {required PannerNode that, required DistanceModelType value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_distance_model_type(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 508, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetDistanceModelConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetDistanceModelConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_distance_model",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetMaxDistance(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 509, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetMaxDistanceConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetMaxDistanceConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_max_distance",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetOnProcessorError(
      {required PannerNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 510, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetOnProcessorErrorConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_on_processor_error",
        argNames: ["that", "callback"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetOrientation(
      {required PannerNode that,
      required double x,
      required double y,
      required double z}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_32(x, serializer);
        sse_encode_f_32(y, serializer);
        sse_encode_f_32(z, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 511, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetOrientationConstMeta,
      argValues: [that, x, y, z],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetOrientationConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_orientation",
        argNames: ["that", "x", "y", "z"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetPanningModel(
      {required PannerNode that, required PanningModelType value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_panning_model_type(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 512, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetPanningModelConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetPanningModelConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_panning_model",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetPosition(
      {required PannerNode that,
      required double x,
      required double y,
      required double z}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_32(x, serializer);
        sse_encode_f_32(y, serializer);
        sse_encode_f_32(z, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 513, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetPositionConstMeta,
      argValues: [that, x, y, z],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetPositionConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_position",
        argNames: ["that", "x", "y", "z"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetRefDistance(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 514, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetRefDistanceConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetRefDistanceConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_ref_distance",
        argNames: ["that", "value"],
      );

  @override
  Future<void> webAudioApiNodePannerNodeSetRolloffFactor(
      {required PannerNode that, required double value}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            that, serializer);
        sse_encode_f_64(value, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 515, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerNodeSetRolloffFactorConstMeta,
      argValues: [that, value],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerNodeSetRolloffFactorConstMeta =>
      const TaskConstMeta(
        debugName: "PannerNode_set_rolloff_factor",
        argNames: ["that", "value"],
      );

  @override
  Future<PeriodicWave> webAudioApiPeriodicWaveDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 516, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiPeriodicWaveDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiPeriodicWaveDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "PeriodicWave_default",
        argNames: [],
      );

  @override
  Future<int> webAudioApiNodeScriptProcessorNodeBufferSize(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 517, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeBufferSizeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeScriptProcessorNodeBufferSizeConstMeta =>
      const TaskConstMeta(
        debugName: "ScriptProcessorNode_buffer_size",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeChannelConfig(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 518, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeScriptProcessorNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "ScriptProcessorNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeScriptProcessorNodeChannelCount(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 519, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeScriptProcessorNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "ScriptProcessorNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeScriptProcessorNodeChannelCountMode(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 520, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeChannelCountModeConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_channel_count_mode",
            argNames: ["that"],
          );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeScriptProcessorNodeChannelInterpretation(
          {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 521, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeScriptProcessorNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeClearOnaudioprocess(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 522, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeScriptProcessorNodeClearOnaudioprocessConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeClearOnaudioprocessConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_clear_onaudioprocess",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeClearOnprocessorerror(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 523, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeScriptProcessorNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeDisconnect(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 524, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeScriptProcessorNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "ScriptProcessorNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeDisconnectOutput(
      {required ScriptProcessorNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 525, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeDisconnectOutputConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_disconnect_output",
            argNames: ["that", "output"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeFrbOverrideConnect(
      {required ScriptProcessorNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 526, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "ScriptProcessorNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeFrbOverrideSetOnaudioprocess(
      {required ScriptProcessorNode that,
      required FutureOr<void> Function(AudioProcessingEvent) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 527, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeScriptProcessorNodeFrbOverrideSetOnaudioprocessConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeFrbOverrideSetOnaudioprocessConstMeta =>
          const TaskConstMeta(
            debugName:
                "ScriptProcessorNode_frb_override_set_onaudioprocess(dart_style=set_onaudioprocess)",
            argNames: ["that", "callback"],
          );

  @override
  Future<int> webAudioApiNodeScriptProcessorNodeNumberOfInputs(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 528, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeNumberOfInputsConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_number_of_inputs",
            argNames: ["that"],
          );

  @override
  Future<int> webAudioApiNodeScriptProcessorNodeNumberOfOutputs(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 529, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeNumberOfOutputsConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_number_of_outputs",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeRegistration(
      {required ScriptProcessorNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 530, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeScriptProcessorNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeScriptProcessorNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "ScriptProcessorNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeScriptProcessorNodeSetOnProcessorError(
      {required ScriptProcessorNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 531, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta:
          kWebAudioApiNodeScriptProcessorNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeScriptProcessorNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "ScriptProcessorNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeChannelConfig(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 532, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeStereoPannerNodeChannelCount(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 533, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeStereoPannerNodeChannelCountMode(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 534, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeStereoPannerNodeChannelInterpretation(
          {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 535, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeStereoPannerNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "StereoPannerNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeClearOnprocessorerror(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 536, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeStereoPannerNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "StereoPannerNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeDisconnect(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 537, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeDisconnectOutput(
      {required StereoPannerNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 538, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeFrbOverrideConnect(
      {required StereoPannerNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 539, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeStereoPannerNodeFrbOverrideConnectConstMeta =>
          const TaskConstMeta(
            debugName:
                "StereoPannerNode_frb_override_connect(dart_style=connect)",
            argNames: ["that", "dest"],
          );

  @override
  Future<int> webAudioApiNodeStereoPannerNodeNumberOfInputs(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 540, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeStereoPannerNodeNumberOfOutputs(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 541, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeRegistration(
      {required StereoPannerNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 543, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "StereoPannerNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeStereoPannerNodeSetOnProcessorError(
      {required StereoPannerNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 544, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeStereoPannerNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "StereoPannerNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeChannelConfig(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 645, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeChannelConfigConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeChannelConfigConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_channel_config",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeWaveShaperNodeChannelCount(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 646, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeChannelCountConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeChannelCountConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_channel_count",
        argNames: ["that"],
      );

  @override
  Future<ChannelCountMode> webAudioApiNodeWaveShaperNodeChannelCountMode(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 647, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_count_mode,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeChannelCountModeConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeChannelCountModeConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_channel_count_mode",
        argNames: ["that"],
      );

  @override
  Future<ChannelInterpretation>
      webAudioApiNodeWaveShaperNodeChannelInterpretation(
          {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 648, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_interpretation,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeChannelInterpretationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeWaveShaperNodeChannelInterpretationConstMeta =>
          const TaskConstMeta(
            debugName: "WaveShaperNode_channel_interpretation",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeClearOnprocessorerror(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 649, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeClearOnprocessorerrorConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeWaveShaperNodeClearOnprocessorerrorConstMeta =>
          const TaskConstMeta(
            debugName: "WaveShaperNode_clear_onprocessorerror",
            argNames: ["that"],
          );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeDisconnect(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 650, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeDisconnectConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeDisconnectConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_disconnect",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeDisconnectOutput(
      {required WaveShaperNode that, required int output}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        sse_encode_CastedPrimitive_usize(output, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 651, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeDisconnectOutputConstMeta,
      argValues: [that, output],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeDisconnectOutputConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_disconnect_output",
        argNames: ["that", "output"],
      );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeFrbOverrideConnect(
      {required WaveShaperNode that, required AudioNode dest}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        sse_encode_DynTrait_AudioNode(dest, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 652, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeFrbOverrideConnectConstMeta,
      argValues: [that, dest],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeFrbOverrideConnectConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_frb_override_connect(dart_style=connect)",
        argNames: ["that", "dest"],
      );

  @override
  Future<Float32List?> webAudioApiNodeWaveShaperNodeFrbOverrideCurve(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 653, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_opt_list_prim_f_32_strict,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeFrbOverrideCurveConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeFrbOverrideCurveConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_frb_override_curve(dart_style=curve)",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeWaveShaperNodeNumberOfInputs(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 654, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeNumberOfInputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeNumberOfInputsConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_number_of_inputs",
        argNames: ["that"],
      );

  @override
  Future<int> webAudioApiNodeWaveShaperNodeNumberOfOutputs(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 655, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_CastedPrimitive_usize,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeNumberOfOutputsConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeNumberOfOutputsConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_number_of_outputs",
        argNames: ["that"],
      );

  @override
  Future<OverSampleType> webAudioApiNodeWaveShaperNodeOversample(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 656, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_over_sample_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeOversampleConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeOversampleConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_oversample",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeRegistration(
      {required WaveShaperNode that}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 657, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeRegistrationConstMeta,
      argValues: [that],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeRegistrationConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_registration",
        argNames: ["that"],
      );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeSetCurve(
      {required WaveShaperNode that, required List<double> curve}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        sse_encode_list_prim_f_32_loose(curve, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 658, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeSetCurveConstMeta,
      argValues: [that, curve],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeSetCurveConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_set_curve",
        argNames: ["that", "curve"],
      );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeSetOnProcessorError(
      {required WaveShaperNode that,
      required FutureOr<void> Function(String) callback}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
            callback, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 659, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeSetOnProcessorErrorConstMeta,
      argValues: [that, callback],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiNodeWaveShaperNodeSetOnProcessorErrorConstMeta =>
          const TaskConstMeta(
            debugName: "WaveShaperNode_set_on_processor_error",
            argNames: ["that", "callback"],
          );

  @override
  Future<void> webAudioApiNodeWaveShaperNodeSetOversample(
      {required WaveShaperNode that, required OverSampleType oversample}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            that, serializer);
        sse_encode_over_sample_type(oversample, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 660, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperNodeSetOversampleConstMeta,
      argValues: [that, oversample],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperNodeSetOversampleConstMeta =>
      const TaskConstMeta(
        debugName: "WaveShaperNode_set_oversample",
        argNames: ["that", "oversample"],
      );

  @override
  Future<AnalyserOptions> webAudioApiNodeAnalyserOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 661, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_analyser_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAnalyserOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAnalyserOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "analyser_options_default",
        argNames: [],
      );

  @override
  Future<AudioBufferSourceOptions>
      webAudioApiNodeAudioBufferSourceOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 662, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_buffer_source_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioBufferSourceOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioBufferSourceOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "audio_buffer_source_options_default",
        argNames: [],
      );

  @override
  Future<AudioContextLatencyCategory>
      webAudioApiContextAudioContextLatencyCategoryDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 663, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_context_latency_category,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextLatencyCategoryDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta
      get kWebAudioApiContextAudioContextLatencyCategoryDefaultConstMeta =>
          const TaskConstMeta(
            debugName: "audio_context_latency_category_default",
            argNames: [],
          );

  @override
  Future<AudioContextOptions> webAudioApiContextAudioContextOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 664, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_context_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiContextAudioContextOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiContextAudioContextOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "audio_context_options_default",
        argNames: [],
      );

  @override
  Future<AudioNodeOptions> webAudioApiNodeAudioNodeOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 665, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_node_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeAudioNodeOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeAudioNodeOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "audio_node_options_default",
        argNames: [],
      );

  @override
  Future<AudioRenderCapacityOptions>
      webAudioApiAudioRenderCapacityOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 666, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_audio_render_capacity_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiAudioRenderCapacityOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiAudioRenderCapacityOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "audio_render_capacity_options_default",
        argNames: [],
      );

  @override
  Future<BiquadFilterOptions> webAudioApiNodeBiquadFilterOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 667, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_biquad_filter_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "biquad_filter_options_default",
        argNames: [],
      );

  @override
  Future<BiquadFilterType> webAudioApiNodeBiquadFilterTypeDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 668, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_biquad_filter_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeBiquadFilterTypeDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeBiquadFilterTypeDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "biquad_filter_type_default",
        argNames: [],
      );

  @override
  Future<ChannelMergerOptions> webAudioApiNodeChannelMergerOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 669, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_merger_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelMergerOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelMergerOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "channel_merger_options_default",
        argNames: [],
      );

  @override
  Future<ChannelSplitterOptions>
      webAudioApiNodeChannelSplitterOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 670, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_channel_splitter_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeChannelSplitterOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeChannelSplitterOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "channel_splitter_options_default",
        argNames: [],
      );

  @override
  Future<ConstantSourceOptions> webAudioApiNodeConstantSourceOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 671, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_constant_source_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConstantSourceOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConstantSourceOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "constant_source_options_default",
        argNames: [],
      );

  @override
  Future<ConvolverOptions> webAudioApiNodeConvolverOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 672, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_convolver_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeConvolverOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeConvolverOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "convolver_options_default",
        argNames: [],
      );

  @override
  Future<DelayOptions> webAudioApiNodeDelayOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 673, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_delay_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDelayOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDelayOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "delay_options_default",
        argNames: [],
      );

  @override
  Future<DistanceModelType> webAudioApiNodeDistanceModelTypeDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 674, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_distance_model_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDistanceModelTypeDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDistanceModelTypeDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "distance_model_type_default",
        argNames: [],
      );

  @override
  Future<DynamicsCompressorOptions>
      webAudioApiNodeDynamicsCompressorOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 675, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_dynamics_compressor_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeDynamicsCompressorOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeDynamicsCompressorOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "dynamics_compressor_options_default",
        argNames: [],
      );

  @override
  Future<void> crateApiSimpleF({required DummyStruct a}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
            a, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 676, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiSimpleFConstMeta,
      argValues: [a],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiSimpleFConstMeta => const TaskConstMeta(
        debugName: "f",
        argNames: ["a"],
      );

  @override
  Future<GainOptions> webAudioApiNodeGainOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 680, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_gain_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeGainOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeGainOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "gain_options_default",
        argNames: [],
      );

  @override
  Future<MediaStream> webAudioApiMediaDevicesGetUserMediaSync(
      {required MediaStreamConstraints constraints}) {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
            constraints, serializer);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 681, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData:
            sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiMediaDevicesGetUserMediaSyncConstMeta,
      argValues: [constraints],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiMediaDevicesGetUserMediaSyncConstMeta =>
      const TaskConstMeta(
        debugName: "get_user_media_sync",
        argNames: ["constraints"],
      );

  @override
  Future<void> crateApiSimpleInitApp() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 682, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_unit,
        decodeErrorData: null,
      ),
      constMeta: kCrateApiSimpleInitAppConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kCrateApiSimpleInitAppConstMeta => const TaskConstMeta(
        debugName: "init_app",
        argNames: [],
      );

  @override
  Future<OscillatorOptions> webAudioApiNodeOscillatorOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 683, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_oscillator_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "oscillator_options_default",
        argNames: [],
      );

  @override
  Future<OscillatorType> webAudioApiNodeOscillatorTypeDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 684, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_oscillator_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOscillatorTypeDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOscillatorTypeDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "oscillator_type_default",
        argNames: [],
      );

  @override
  Future<OverSampleType> webAudioApiNodeOverSampleTypeDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 685, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_over_sample_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeOverSampleTypeDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeOverSampleTypeDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "over_sample_type_default",
        argNames: [],
      );

  @override
  Future<PannerOptions> webAudioApiNodePannerOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 686, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_panner_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePannerOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePannerOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "panner_options_default",
        argNames: [],
      );

  @override
  Future<PanningModelType> webAudioApiNodePanningModelTypeDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 687, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_panning_model_type,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodePanningModelTypeDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodePanningModelTypeDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "panning_model_type_default",
        argNames: [],
      );

  @override
  Future<PeriodicWaveOptions> webAudioApiPeriodicWaveOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 688, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_periodic_wave_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiPeriodicWaveOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiPeriodicWaveOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "periodic_wave_options_default",
        argNames: [],
      );

  @override
  Future<StereoPannerOptions> webAudioApiNodeStereoPannerOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 689, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_stereo_panner_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeStereoPannerOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeStereoPannerOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "stereo_panner_options_default",
        argNames: [],
      );

  @override
  Future<WaveShaperOptions> webAudioApiNodeWaveShaperOptionsDefault() {
    return handler.executeNormal(NormalTask(
      callFfi: (port_) {
        final serializer = SseSerializer(generalizedFrbRustBinding);
        pdeCallFfi(generalizedFrbRustBinding, serializer,
            funcId: 690, port: port_);
      },
      codec: SseCodec(
        decodeSuccessData: sse_decode_wave_shaper_options,
        decodeErrorData: null,
      ),
      constMeta: kWebAudioApiNodeWaveShaperOptionsDefaultConstMeta,
      argValues: [],
      apiImpl: this,
    ));
  }

  TaskConstMeta get kWebAudioApiNodeWaveShaperOptionsDefaultConstMeta =>
      const TaskConstMeta(
        debugName: "wave_shaper_options_default",
        argNames: [],
      );

  Future<void> Function(int, dynamic)
      encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(AudioProcessingEvent) raw) {
    return (callId, rawArg0) async {
      final arg0 =
          dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
              rawArg0);

      Box<void>? rawOutput;
      Box<AnyhowException>? rawError;
      try {
        rawOutput = Box(await raw(arg0));
      } catch (e, s) {
        rawError = Box(AnyhowException("$e\n\n$s"));
      }

      final serializer = SseSerializer(generalizedFrbRustBinding);
      assert((rawOutput != null) ^ (rawError != null));
      if (rawOutput != null) {
        serializer.buffer.putUint8(0);
        sse_encode_unit(rawOutput.value, serializer);
      } else {
        serializer.buffer.putUint8(1);
        sse_encode_AnyhowException(rawError!.value, serializer);
      }
      final output = serializer.intoRaw();

      generalizedFrbRustBinding.dartFnDeliverOutput(
          callId: callId,
          ptr: output.ptr,
          rustVecLen: output.rustVecLen,
          dataLen: output.dataLen);
    };
  }

  Future<void> Function(int, dynamic)
      encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(Event) raw) {
    return (callId, rawArg0) async {
      final arg0 =
          dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
              rawArg0);

      Box<void>? rawOutput;
      Box<AnyhowException>? rawError;
      try {
        rawOutput = Box(await raw(arg0));
      } catch (e, s) {
        rawError = Box(AnyhowException("$e\n\n$s"));
      }

      final serializer = SseSerializer(generalizedFrbRustBinding);
      assert((rawOutput != null) ^ (rawError != null));
      if (rawOutput != null) {
        serializer.buffer.putUint8(0);
        sse_encode_unit(rawOutput.value, serializer);
      } else {
        serializer.buffer.putUint8(1);
        sse_encode_AnyhowException(rawError!.value, serializer);
      }
      final output = serializer.intoRaw();

      generalizedFrbRustBinding.dartFnDeliverOutput(
          callId: callId,
          ptr: output.ptr,
          rustVecLen: output.rustVecLen,
          dataLen: output.dataLen);
    };
  }

  Future<void> Function(int, dynamic)
      encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(OfflineAudioCompletionEvent) raw) {
    return (callId, rawArg0) async {
      final arg0 =
          dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
              rawArg0);

      Box<void>? rawOutput;
      Box<AnyhowException>? rawError;
      try {
        rawOutput = Box(await raw(arg0));
      } catch (e, s) {
        rawError = Box(AnyhowException("$e\n\n$s"));
      }

      final serializer = SseSerializer(generalizedFrbRustBinding);
      assert((rawOutput != null) ^ (rawError != null));
      if (rawOutput != null) {
        serializer.buffer.putUint8(0);
        sse_encode_unit(rawOutput.value, serializer);
      } else {
        serializer.buffer.putUint8(1);
        sse_encode_AnyhowException(rawError!.value, serializer);
      }
      final output = serializer.intoRaw();

      generalizedFrbRustBinding.dartFnDeliverOutput(
          callId: callId,
          ptr: output.ptr,
          rustVecLen: output.rustVecLen,
          dataLen: output.dataLen);
    };
  }

  Future<void> Function(int, dynamic)
      encode_DartFn_Inputs_String_Output_unit_AnyhowException(
          FutureOr<void> Function(String) raw) {
    return (callId, rawArg0) async {
      final arg0 = dco_decode_String(rawArg0);

      Box<void>? rawOutput;
      Box<AnyhowException>? rawError;
      try {
        rawOutput = Box(await raw(arg0));
      } catch (e, s) {
        rawError = Box(AnyhowException("$e\n\n$s"));
      }

      final serializer = SseSerializer(generalizedFrbRustBinding);
      assert((rawOutput != null) ^ (rawError != null));
      if (rawOutput != null) {
        serializer.buffer.putUint8(0);
        sse_encode_unit(rawOutput.value, serializer);
      } else {
        serializer.buffer.putUint8(1);
        sse_encode_AnyhowException(rawError!.value, serializer);
      }
      final output = serializer.intoRaw();

      generalizedFrbRustBinding.dartFnDeliverOutput(
          callId: callId,
          ptr: output.ptr,
          rustVecLen: output.rustVecLen,
          dataLen: output.dataLen);
    };
  }

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AnalyserNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AnalyserNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioBuffer => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioBuffer => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioBufferSourceNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioBufferSourceNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioContext => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioContext => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioContextRegistration => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioContextRegistration => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioDestinationNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioDestinationNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioListener => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioListener => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioParam => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioParam => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioParamId => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioParamId => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioProcessingEvent => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioProcessingEvent => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioRenderCapacity => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioRenderCapacity => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioRenderCapacityEvent => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioRenderCapacityEvent => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_AudioWorkletNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_AudioWorkletNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_BiquadFilterNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_BiquadFilterNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_BlobEvent => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_BlobEvent => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelConfig => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelConfig => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelMergerNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelMergerNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ChannelSplitterNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ChannelSplitterNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConcreteBaseAudioContext => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConcreteBaseAudioContext => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConstantSourceNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConstantSourceNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ConvolverNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ConvolverNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DelayNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DelayNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DummyStruct => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DummyStruct => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_DynamicsCompressorNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_DynamicsCompressorNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode;

  RustArcIncrementStrongCountFnType get rust_arc_increment_strong_count_Event =>
      wire.rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent;

  RustArcDecrementStrongCountFnType get rust_arc_decrement_strong_count_Event =>
      wire.rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_GainNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_GainNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_IirFilterNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_IirFilterNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaElementAudioSourceNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaElementAudioSourceNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaRecorder => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaRecorder => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStream => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStream => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamAudioDestinationNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamAudioDestinationNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamAudioSourceNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamAudioSourceNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamConstraints => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamConstraints => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamTrack => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamTrack => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaStreamTrackAudioSourceNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_MediaElement => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_MediaElement => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OfflineAudioCompletionEvent => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OfflineAudioCompletionEvent => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OfflineAudioContext => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OfflineAudioContext => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_OscillatorNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_OscillatorNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_PannerNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_PannerNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_PeriodicWave => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_PeriodicWave => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_ScriptProcessorNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_ScriptProcessorNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_StereoPannerNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_StereoPannerNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode;

  RustArcIncrementStrongCountFnType
      get rust_arc_increment_strong_count_WaveShaperNode => wire
          .rust_arc_increment_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode;

  RustArcDecrementStrongCountFnType
      get rust_arc_decrement_strong_count_WaveShaperNode => wire
          .rust_arc_decrement_strong_count_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode;

  @protected
  AnyhowException dco_decode_AnyhowException(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AnyhowException(raw as String);
  }

  @protected
  AnalyserNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
        raw);
  }

  @protected
  AudioBufferSourceNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
        raw);
  }

  @protected
  AudioDestinationNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
        raw);
  }

  @protected
  AudioListener
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
        raw);
  }

  @protected
  AudioParam
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
        raw);
  }

  @protected
  AudioWorkletNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
        raw);
  }

  @protected
  BiquadFilterNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
        raw);
  }

  @protected
  ChannelMergerNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
        raw);
  }

  @protected
  ChannelSplitterNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
        raw);
  }

  @protected
  ConstantSourceNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
        raw);
  }

  @protected
  ConvolverNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
        raw);
  }

  @protected
  DelayNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
        raw);
  }

  @protected
  DynamicsCompressorNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
        raw);
  }

  @protected
  GainNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
        raw);
  }

  @protected
  IirFilterNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
        raw);
  }

  @protected
  MediaElementAudioSourceNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
        raw);
  }

  @protected
  MediaStreamAudioDestinationNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
        raw);
  }

  @protected
  MediaStreamAudioSourceNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
        raw);
  }

  @protected
  MediaStreamTrackAudioSourceNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
        raw);
  }

  @protected
  OscillatorNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
        raw);
  }

  @protected
  PannerNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
        raw);
  }

  @protected
  ScriptProcessorNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
        raw);
  }

  @protected
  StereoPannerNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
        raw);
  }

  @protected
  WaveShaperNode
      dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
        raw);
  }

  @protected
  AnalyserNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBuffer
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBufferSourceNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioContext
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioDestinationNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioListener
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioListenerImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioParam
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioParamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioParamId
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioParamIdImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioProcessingEvent
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacity
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacityEvent
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  AudioWorkletNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BiquadFilterNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BlobEvent
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BlobEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelConfig
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelConfigImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelMergerNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelSplitterNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConcreteBaseAudioContext
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  ConstantSourceNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConvolverNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DelayNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DelayNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DummyStruct
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DummyStructImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DynamicsCompressorNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  Event
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return EventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  GainNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return GainNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  IirFilterNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaElementAudioSourceNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaRecorder
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStream
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioDestinationNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioSourceNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamConstraints
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamConstraintsImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamTrack
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamTrackAudioSourceNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaElement
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OfflineAudioCompletionEvent
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  OfflineAudioContext
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OscillatorNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PannerNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PeriodicWave
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PeriodicWaveImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ScriptProcessorNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  StereoPannerNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  WaveShaperNode
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AnalyserNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBuffer
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBufferSourceNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioProcessingEvent
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacityEvent
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  BiquadFilterNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BlobEvent
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BlobEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConstantSourceNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConvolverNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaElement
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OfflineAudioCompletionEvent
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  OfflineAudioContext
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OscillatorNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PannerNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  WaveShaperNode
      dco_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AnalyserNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBuffer
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBufferSourceNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioContext
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioContextRegistration
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextRegistrationImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  AudioDestinationNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioListener
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioListenerImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioParam
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioParamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioProcessingEvent
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacity
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacityEvent
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  AudioWorkletNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BiquadFilterNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BlobEvent
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BlobEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelMergerNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelSplitterNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConcreteBaseAudioContext
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  ConstantSourceNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConvolverNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DelayNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DelayNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DynamicsCompressorNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  Event
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return EventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  GainNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return GainNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  IirFilterNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaElementAudioSourceNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaRecorder
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStream
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioDestinationNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioSourceNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamTrack
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamTrackAudioSourceNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaElement
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OfflineAudioCompletionEvent
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  OfflineAudioContext
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OscillatorNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PannerNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ScriptProcessorNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  StereoPannerNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  WaveShaperNode
      dco_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  int dco_decode_CastedPrimitive_usize(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  FutureOr<void> Function(AudioProcessingEvent)
      dco_decode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent_Output_unit_AnyhowException(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError('');
  }

  @protected
  FutureOr<void> Function(Event)
      dco_decode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError('');
  }

  @protected
  FutureOr<void> Function(OfflineAudioCompletionEvent)
      dco_decode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent_Output_unit_AnyhowException(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError('');
  }

  @protected
  FutureOr<void> Function(String)
      dco_decode_DartFn_Inputs_String_Output_unit_AnyhowException(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError('');
  }

  @protected
  Object dco_decode_DartOpaque(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return decodeDartOpaque(raw, generalizedFrbRustBinding);
  }

  @protected
  AudioNode dco_decode_DynTrait_AudioNode(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioParam
      dco_decode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  MediaStream
      dco_decode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_detune(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_playback_rate(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_x(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_y(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_z(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_x(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_y(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_z(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_x(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_y(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_z(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_detune(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_frequency(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_gain(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_q(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode_offset(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode_delay_time(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_attack(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_knee(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_ratio(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_release(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_threshold(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode_gain(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  MediaStream
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode_stream(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_detune(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_frequency(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_x(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_y(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_z(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_x(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_y(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_z(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AudioParam
      dco_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode_pan(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError(
        'Not implemented in this codec, please use the other one');
  }

  @protected
  AnalyserNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBuffer
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioBufferSourceNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioContext
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioContextRegistration
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextRegistrationImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  AudioDestinationNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioListener
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioListenerImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioParam
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioParamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioParamId
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioParamIdImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioProcessingEvent
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacity
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  AudioRenderCapacityEvent
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  AudioWorkletNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BiquadFilterNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  BlobEvent
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BlobEventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelConfig
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelConfigImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelMergerNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ChannelSplitterNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConcreteBaseAudioContext
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  ConstantSourceNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ConvolverNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DelayNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DelayNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DummyStruct
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DummyStructImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  DynamicsCompressorNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  Event
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return EventImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  GainNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return GainNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  IirFilterNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaElementAudioSourceNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaRecorder
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStream
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioDestinationNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamAudioSourceNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamConstraints
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamConstraintsImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaStreamTrack
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  MediaStreamTrackAudioSourceNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  MediaElement
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaElementImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OfflineAudioCompletionEvent
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalDcoDecode(
        raw as List<dynamic>);
  }

  @protected
  OfflineAudioContext
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  OscillatorNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PannerNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  PeriodicWave
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PeriodicWaveImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  ScriptProcessorNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  StereoPannerNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  WaveShaperNode
      dco_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalDcoDecode(raw as List<dynamic>);
  }

  @protected
  String dco_decode_String(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as String;
  }

  @protected
  AnalyserNodeExt dco_decode_TraitDef_AnalyserNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AnalyserNodeMiscExt dco_decode_TraitDef_AnalyserNodeMiscExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioBufferSourceNodeExt dco_decode_TraitDef_AudioBufferSourceNodeExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioBufferSourceNodeMiscExt dco_decode_TraitDef_AudioBufferSourceNodeMiscExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioBufferSourceNodeScheduledSourceNodeMiscExt
      dco_decode_TraitDef_AudioBufferSourceNodeScheduledSourceNodeMiscExt(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioContextExt dco_decode_TraitDef_AudioContextExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioDestinationNodeExt dco_decode_TraitDef_AudioDestinationNodeExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioNode dco_decode_TraitDef_AudioNode(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioParamExt dco_decode_TraitDef_AudioParamExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioScheduledSourceNode dco_decode_TraitDef_AudioScheduledSourceNode(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AudioWorkletProcessor dco_decode_TraitDef_AudioWorkletProcessor(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  BaseAudioContext dco_decode_TraitDef_BaseAudioContext(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  BiquadFilterNodeExt dco_decode_TraitDef_BiquadFilterNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ChannelMergerNodeExt dco_decode_TraitDef_ChannelMergerNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ChannelSplitterNodeExt dco_decode_TraitDef_ChannelSplitterNodeExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ConstantSourceNodeExt dco_decode_TraitDef_ConstantSourceNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ConstantSourceNodeScheduledSourceNodeMiscExt
      dco_decode_TraitDef_ConstantSourceNodeScheduledSourceNodeMiscExt(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ConvolverNodeExt dco_decode_TraitDef_ConvolverNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  DelayNodeExt dco_decode_TraitDef_DelayNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  DynamicsCompressorNodeExt dco_decode_TraitDef_DynamicsCompressorNodeExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  EventExt dco_decode_TraitDef_EventExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  GainNodeExt dco_decode_TraitDef_GainNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  IIRFilterNodeExt dco_decode_TraitDef_IIRFilterNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  MediaElementAudioSourceNodeExt
      dco_decode_TraitDef_MediaElementAudioSourceNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  MediaStreamAudioDestinationNodeExt
      dco_decode_TraitDef_MediaStreamAudioDestinationNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  MediaStreamAudioSourceNodeExt
      dco_decode_TraitDef_MediaStreamAudioSourceNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  MediaStreamExt dco_decode_TraitDef_MediaStreamExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  MediaStreamTrackAudioSourceNodeExt
      dco_decode_TraitDef_MediaStreamTrackAudioSourceNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  OfflineAudioContextExt dco_decode_TraitDef_OfflineAudioContextExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  OscillatorNodeExt dco_decode_TraitDef_OscillatorNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  OscillatorNodeScheduledSourceNodeMiscExt
      dco_decode_TraitDef_OscillatorNodeScheduledSourceNodeMiscExt(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  PannerNodeExt dco_decode_TraitDef_PannerNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ScriptProcessorNodeExt dco_decode_TraitDef_ScriptProcessorNodeExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  ScriptProcessorNodeMiscExt dco_decode_TraitDef_ScriptProcessorNodeMiscExt(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  StereoPannerNodeExt dco_decode_TraitDef_StereoPannerNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  WaveShaperNodeExt dco_decode_TraitDef_WaveShaperNodeExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  WaveShaperNodeMiscExt dco_decode_TraitDef_WaveShaperNodeMiscExt(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    throw UnimplementedError();
  }

  @protected
  AnalyserOptions dco_decode_analyser_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 5)
      throw Exception('unexpected arr length: expect 5 but see ${arr.length}');
    return AnalyserOptions(
      fftSize: dco_decode_CastedPrimitive_usize(arr[0]),
      maxDecibels: dco_decode_f_64(arr[1]),
      minDecibels: dco_decode_f_64(arr[2]),
      smoothingTimeConstant: dco_decode_f_64(arr[3]),
      audioNodeOptions: dco_decode_audio_node_options(arr[4]),
    );
  }

  @protected
  AudioBufferOptions dco_decode_audio_buffer_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return AudioBufferOptions(
      numberOfChannels: dco_decode_CastedPrimitive_usize(arr[0]),
      length: dco_decode_CastedPrimitive_usize(arr[1]),
      sampleRate: dco_decode_f_32(arr[2]),
    );
  }

  @protected
  AudioBufferSourceOptions dco_decode_audio_buffer_source_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 6)
      throw Exception('unexpected arr length: expect 6 but see ${arr.length}');
    return AudioBufferSourceOptions(
      buffer:
          dco_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
              arr[0]),
      detune: dco_decode_f_32(arr[1]),
      loop: dco_decode_bool(arr[2]),
      loopStart: dco_decode_f_64(arr[3]),
      loopEnd: dco_decode_f_64(arr[4]),
      playbackRate: dco_decode_f_32(arr[5]),
    );
  }

  @protected
  AudioContextLatencyCategory dco_decode_audio_context_latency_category(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    switch (raw[0]) {
      case 0:
        return AudioContextLatencyCategory_Balanced();
      case 1:
        return AudioContextLatencyCategory_Interactive();
      case 2:
        return AudioContextLatencyCategory_Playback();
      case 3:
        return AudioContextLatencyCategory_Custom(
          dco_decode_f_64(raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  @protected
  AudioContextOptions dco_decode_audio_context_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 4)
      throw Exception('unexpected arr length: expect 4 but see ${arr.length}');
    return AudioContextOptions(
      latencyHint: dco_decode_audio_context_latency_category(arr[0]),
      sampleRate: dco_decode_opt_box_autoadd_f_32(arr[1]),
      sinkId: dco_decode_String(arr[2]),
      renderSizeHint: dco_decode_audio_context_render_size_category(arr[3]),
    );
  }

  @protected
  AudioContextRenderSizeCategory dco_decode_audio_context_render_size_category(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextRenderSizeCategory.values[raw as int];
  }

  @protected
  AudioContextState dco_decode_audio_context_state(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AudioContextState.values[raw as int];
  }

  @protected
  AudioNodeImplementor dco_decode_audio_node_implementor(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    switch (raw[0]) {
      case 0:
        return AudioNodeImplementor_Variant0(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
              raw[1]),
        );
      case 1:
        return AudioNodeImplementor_Variant1(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
              raw[1]),
        );
      case 2:
        return AudioNodeImplementor_Variant2(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
              raw[1]),
        );
      case 3:
        return AudioNodeImplementor_Variant3(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
              raw[1]),
        );
      case 4:
        return AudioNodeImplementor_Variant4(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
              raw[1]),
        );
      case 5:
        return AudioNodeImplementor_Variant5(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
              raw[1]),
        );
      case 6:
        return AudioNodeImplementor_Variant6(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
              raw[1]),
        );
      case 7:
        return AudioNodeImplementor_Variant7(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
              raw[1]),
        );
      case 8:
        return AudioNodeImplementor_Variant8(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
              raw[1]),
        );
      case 9:
        return AudioNodeImplementor_Variant9(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
              raw[1]),
        );
      case 10:
        return AudioNodeImplementor_Variant10(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
              raw[1]),
        );
      case 11:
        return AudioNodeImplementor_Variant11(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 12:
        return AudioNodeImplementor_Variant12(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
              raw[1]),
        );
      case 13:
        return AudioNodeImplementor_Variant13(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
              raw[1]),
        );
      case 14:
        return AudioNodeImplementor_Variant14(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
              raw[1]),
        );
      case 15:
        return AudioNodeImplementor_Variant15(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
              raw[1]),
        );
      case 16:
        return AudioNodeImplementor_Variant16(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
              raw[1]),
        );
      case 17:
        return AudioNodeImplementor_Variant17(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
              raw[1]),
        );
      case 18:
        return AudioNodeImplementor_Variant18(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
              raw[1]),
        );
      case 19:
        return AudioNodeImplementor_Variant19(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 20:
        return AudioNodeImplementor_Variant20(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
              raw[1]),
        );
      case 21:
        return AudioNodeImplementor_Variant21(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
              raw[1]),
        );
      case 22:
        return AudioNodeImplementor_Variant22(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
              raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  @protected
  AudioNodeOptions dco_decode_audio_node_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return AudioNodeOptions(
      channelCount: dco_decode_CastedPrimitive_usize(arr[0]),
      channelCountMode: dco_decode_channel_count_mode(arr[1]),
      channelInterpretation: dco_decode_channel_interpretation(arr[2]),
    );
  }

  @protected
  AudioParamDescriptor dco_decode_audio_param_descriptor(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 5)
      throw Exception('unexpected arr length: expect 5 but see ${arr.length}');
    return AudioParamDescriptor(
      name: dco_decode_String(arr[0]),
      automationRate: dco_decode_automation_rate(arr[1]),
      defaultValue: dco_decode_f_32(arr[2]),
      minValue: dco_decode_f_32(arr[3]),
      maxValue: dco_decode_f_32(arr[4]),
    );
  }

  @protected
  AudioRenderCapacityOptions dco_decode_audio_render_capacity_options(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 1)
      throw Exception('unexpected arr length: expect 1 but see ${arr.length}');
    return AudioRenderCapacityOptions(
      updateInterval: dco_decode_f_64(arr[0]),
    );
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
      dco_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    switch (raw[0]) {
      case 0:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant0(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
              raw[1]),
        );
      case 1:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant1(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
              raw[1]),
        );
      case 2:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant2(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 3:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant3(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 4:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant4(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 5:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant5(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 6:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant6(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 7:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant7(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 8:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant8(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 9:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant9(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 10:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant10(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
              raw[1]),
        );
      case 11:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant11(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
              raw[1]),
        );
      case 12:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant12(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
              raw[1]),
        );
      case 13:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant13(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
              raw[1]),
        );
      case 14:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant14(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
              raw[1]),
        );
      case 15:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant15(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
              raw[1]),
        );
      case 16:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant16(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
              raw[1]),
        );
      case 17:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant17(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 18:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant18(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 19:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant19(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 20:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant20(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 21:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant21(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
              raw[1]),
        );
      case 22:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant22(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
              raw[1]),
        );
      case 23:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant23(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
              raw[1]),
        );
      case 24:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant24(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
              raw[1]),
        );
      case 25:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant25(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 26:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant26(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 27:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant27(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 28:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant28(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 29:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant29(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 30:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant30(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
              raw[1]),
        );
      case 31:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant31(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
              raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
      dco_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    switch (raw[0]) {
      case 0:
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum_Variant0(
          dco_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
              raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  @protected
  AutomationRate dco_decode_automation_rate(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return AutomationRate.values[raw as int];
  }

  @protected
  BiquadFilterOptions dco_decode_biquad_filter_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 6)
      throw Exception('unexpected arr length: expect 6 but see ${arr.length}');
    return BiquadFilterOptions(
      q: dco_decode_f_32(arr[0]),
      detune: dco_decode_f_32(arr[1]),
      frequency: dco_decode_f_32(arr[2]),
      gain: dco_decode_f_32(arr[3]),
      type: dco_decode_biquad_filter_type(arr[4]),
      audioNodeOptions: dco_decode_audio_node_options(arr[5]),
    );
  }

  @protected
  BiquadFilterType dco_decode_biquad_filter_type(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return BiquadFilterType.values[raw as int];
  }

  @protected
  bool dco_decode_bool(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as bool;
  }

  @protected
  AudioBuffer
      dco_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
        raw);
  }

  @protected
  PeriodicWave
      dco_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
        raw);
  }

  @protected
  AudioBufferOptions dco_decode_box_autoadd_audio_buffer_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_audio_buffer_options(raw);
  }

  @protected
  AudioContextOptions dco_decode_box_autoadd_audio_context_options(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_audio_context_options(raw);
  }

  @protected
  AudioNodeImplementor dco_decode_box_autoadd_audio_node_implementor(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_audio_node_implementor(raw);
  }

  @protected
  AudioParamDescriptor dco_decode_box_autoadd_audio_param_descriptor(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_audio_param_descriptor(raw);
  }

  @protected
  AudioRenderCapacityOptions
      dco_decode_box_autoadd_audio_render_capacity_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_audio_render_capacity_options(raw);
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
      dco_decode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
        raw);
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
      dco_decode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
        raw);
  }

  @protected
  double dco_decode_box_autoadd_f_32(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as double;
  }

  @protected
  PeriodicWaveOptions dco_decode_box_autoadd_periodic_wave_options(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dco_decode_periodic_wave_options(raw);
  }

  @protected
  ChannelCountMode dco_decode_channel_count_mode(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelCountMode.values[raw as int];
  }

  @protected
  ChannelInterpretation dco_decode_channel_interpretation(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return ChannelInterpretation.values[raw as int];
  }

  @protected
  ChannelMergerOptions dco_decode_channel_merger_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return ChannelMergerOptions(
      numberOfInputs: dco_decode_CastedPrimitive_usize(arr[0]),
      audioNodeOptions: dco_decode_audio_node_options(arr[1]),
    );
  }

  @protected
  ChannelSplitterOptions dco_decode_channel_splitter_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return ChannelSplitterOptions(
      numberOfOutputs: dco_decode_CastedPrimitive_usize(arr[0]),
      audioNodeOptions: dco_decode_audio_node_options(arr[1]),
    );
  }

  @protected
  ConstantSourceOptions dco_decode_constant_source_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 1)
      throw Exception('unexpected arr length: expect 1 but see ${arr.length}');
    return ConstantSourceOptions(
      offset: dco_decode_f_32(arr[0]),
    );
  }

  @protected
  ConvolverOptions dco_decode_convolver_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return ConvolverOptions(
      buffer:
          dco_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
              arr[0]),
      disableNormalization: dco_decode_bool(arr[1]),
      audioNodeOptions: dco_decode_audio_node_options(arr[2]),
    );
  }

  @protected
  DelayOptions dco_decode_delay_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return DelayOptions(
      maxDelayTime: dco_decode_f_64(arr[0]),
      delayTime: dco_decode_f_64(arr[1]),
      audioNodeOptions: dco_decode_audio_node_options(arr[2]),
    );
  }

  @protected
  DistanceModelType dco_decode_distance_model_type(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return DistanceModelType.values[raw as int];
  }

  @protected
  DynamicsCompressorOptions dco_decode_dynamics_compressor_options(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 6)
      throw Exception('unexpected arr length: expect 6 but see ${arr.length}');
    return DynamicsCompressorOptions(
      attack: dco_decode_f_32(arr[0]),
      knee: dco_decode_f_32(arr[1]),
      ratio: dco_decode_f_32(arr[2]),
      release: dco_decode_f_32(arr[3]),
      threshold: dco_decode_f_32(arr[4]),
      audioNodeOptions: dco_decode_audio_node_options(arr[5]),
    );
  }

  @protected
  double dco_decode_f_32(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as double;
  }

  @protected
  double dco_decode_f_64(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as double;
  }

  @protected
  GainOptions dco_decode_gain_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return GainOptions(
      gain: dco_decode_f_32(arr[0]),
      audioNodeOptions: dco_decode_audio_node_options(arr[1]),
    );
  }

  @protected
  int dco_decode_i_32(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as int;
  }

  @protected
  PlatformInt64 dco_decode_isize(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dcoDecodeI64(raw);
  }

  @protected
  List<MediaStreamTrack>
      dco_decode_list_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return (raw as List<dynamic>)
        .map(
            dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack)
        .toList();
  }

  @protected
  List<AudioParamDescriptor> dco_decode_list_audio_param_descriptor(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return (raw as List<dynamic>)
        .map(dco_decode_audio_param_descriptor)
        .toList();
  }

  @protected
  List<Float32List> dco_decode_list_list_prim_f_32_strict(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return (raw as List<dynamic>)
        .map(dco_decode_list_prim_f_32_strict)
        .toList();
  }

  @protected
  List<double> dco_decode_list_prim_f_32_loose(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as List<double>;
  }

  @protected
  Float32List dco_decode_list_prim_f_32_strict(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as Float32List;
  }

  @protected
  List<double> dco_decode_list_prim_f_64_loose(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as List<double>;
  }

  @protected
  Float64List dco_decode_list_prim_f_64_strict(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as Float64List;
  }

  @protected
  Uint8List dco_decode_list_prim_u_8_strict(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as Uint8List;
  }

  @protected
  MediaStreamTrackState dco_decode_media_stream_track_state(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return MediaStreamTrackState.values[raw as int];
  }

  @protected
  AudioBuffer?
      dco_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw == null
        ? null
        : dco_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            raw);
  }

  @protected
  PeriodicWave?
      dco_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw == null
        ? null
        : dco_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
            raw);
  }

  @protected
  double? dco_decode_opt_box_autoadd_f_32(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw == null ? null : dco_decode_box_autoadd_f_32(raw);
  }

  @protected
  Float32List? dco_decode_opt_list_prim_f_32_strict(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw == null ? null : dco_decode_list_prim_f_32_strict(raw);
  }

  @protected
  OscillatorOptions dco_decode_oscillator_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 5)
      throw Exception('unexpected arr length: expect 5 but see ${arr.length}');
    return OscillatorOptions(
      type: dco_decode_oscillator_type(arr[0]),
      frequency: dco_decode_f_32(arr[1]),
      detune: dco_decode_f_32(arr[2]),
      periodicWave:
          dco_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
              arr[3]),
      audioNodeOptions: dco_decode_audio_node_options(arr[4]),
    );
  }

  @protected
  OscillatorType dco_decode_oscillator_type(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OscillatorType.values[raw as int];
  }

  @protected
  OverSampleType dco_decode_over_sample_type(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return OverSampleType.values[raw as int];
  }

  @protected
  PannerOptions dco_decode_panner_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 15)
      throw Exception('unexpected arr length: expect 15 but see ${arr.length}');
    return PannerOptions(
      panningModel: dco_decode_panning_model_type(arr[0]),
      distanceModel: dco_decode_distance_model_type(arr[1]),
      positionX: dco_decode_f_32(arr[2]),
      positionY: dco_decode_f_32(arr[3]),
      positionZ: dco_decode_f_32(arr[4]),
      orientationX: dco_decode_f_32(arr[5]),
      orientationY: dco_decode_f_32(arr[6]),
      orientationZ: dco_decode_f_32(arr[7]),
      refDistance: dco_decode_f_64(arr[8]),
      maxDistance: dco_decode_f_64(arr[9]),
      rolloffFactor: dco_decode_f_64(arr[10]),
      coneInnerAngle: dco_decode_f_64(arr[11]),
      coneOuterAngle: dco_decode_f_64(arr[12]),
      coneOuterGain: dco_decode_f_64(arr[13]),
      audioNodeOptions: dco_decode_audio_node_options(arr[14]),
    );
  }

  @protected
  PanningModelType dco_decode_panning_model_type(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return PanningModelType.values[raw as int];
  }

  @protected
  PeriodicWaveOptions dco_decode_periodic_wave_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return PeriodicWaveOptions(
      real: dco_decode_opt_list_prim_f_32_strict(arr[0]),
      imag: dco_decode_opt_list_prim_f_32_strict(arr[1]),
      disableNormalization: dco_decode_bool(arr[2]),
    );
  }

  @protected
  (
    AudioParam,
    AudioParamId
  ) dco_decode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id(
      dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 2) {
      throw Exception('Expected 2 elements, got ${arr.length}');
    }
    return (
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          arr[0]),
      dco_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          arr[1]),
    );
  }

  @protected
  StereoPannerOptions dco_decode_stereo_panner_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return StereoPannerOptions(
      pan: dco_decode_f_32(arr[0]),
      audioNodeOptions: dco_decode_audio_node_options(arr[1]),
    );
  }

  @protected
  int dco_decode_u_8(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return raw as int;
  }

  @protected
  void dco_decode_unit(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return;
  }

  @protected
  BigInt dco_decode_usize(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    return dcoDecodeU64(raw);
  }

  @protected
  WaveShaperOptions dco_decode_wave_shaper_options(dynamic raw) {
    // Codec=Dco (DartCObject based), see doc to use other codecs
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return WaveShaperOptions(
      curve: dco_decode_opt_list_prim_f_32_strict(arr[0]),
      oversample: dco_decode_over_sample_type(arr[1]),
      audioNodeOptions: dco_decode_audio_node_options(arr[2]),
    );
  }

  @protected
  AnyhowException sse_decode_AnyhowException(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_String(deserializer);
    return AnyhowException(inner);
  }

  @protected
  AnalyserNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            deserializer);
    return inner;
  }

  @protected
  AudioBufferSourceNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            deserializer);
    return inner;
  }

  @protected
  AudioDestinationNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            deserializer);
    return inner;
  }

  @protected
  AudioListener
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            deserializer);
    return inner;
  }

  @protected
  AudioParam
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
            deserializer);
    return inner;
  }

  @protected
  AudioWorkletNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            deserializer);
    return inner;
  }

  @protected
  BiquadFilterNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            deserializer);
    return inner;
  }

  @protected
  ChannelMergerNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            deserializer);
    return inner;
  }

  @protected
  ChannelSplitterNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            deserializer);
    return inner;
  }

  @protected
  ConstantSourceNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            deserializer);
    return inner;
  }

  @protected
  ConvolverNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            deserializer);
    return inner;
  }

  @protected
  DelayNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            deserializer);
    return inner;
  }

  @protected
  DynamicsCompressorNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            deserializer);
    return inner;
  }

  @protected
  GainNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            deserializer);
    return inner;
  }

  @protected
  IirFilterNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            deserializer);
    return inner;
  }

  @protected
  MediaElementAudioSourceNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            deserializer);
    return inner;
  }

  @protected
  MediaStreamAudioDestinationNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            deserializer);
    return inner;
  }

  @protected
  MediaStreamAudioSourceNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            deserializer);
    return inner;
  }

  @protected
  MediaStreamTrackAudioSourceNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            deserializer);
    return inner;
  }

  @protected
  OscillatorNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            deserializer);
    return inner;
  }

  @protected
  PannerNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            deserializer);
    return inner;
  }

  @protected
  ScriptProcessorNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            deserializer);
    return inner;
  }

  @protected
  StereoPannerNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            deserializer);
    return inner;
  }

  @protected
  WaveShaperNode
      sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner =
        sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            deserializer);
    return inner;
  }

  @protected
  AnalyserNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBuffer
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBufferSourceNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioContext
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioDestinationNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioListener
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioListenerImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioParam
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioParamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioParamId
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioParamIdImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioProcessingEvent
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacity
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacityEvent
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioWorkletNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BiquadFilterNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BlobEvent
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BlobEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelConfig
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelConfigImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelMergerNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelSplitterNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConcreteBaseAudioContext
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConstantSourceNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConvolverNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DelayNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DelayNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DummyStruct
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DummyStructImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DynamicsCompressorNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  Event
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return EventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  GainNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return GainNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  IirFilterNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElementAudioSourceNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaRecorder
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStream
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioDestinationNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioSourceNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamConstraints
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamConstraintsImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrack
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrackAudioSourceNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElement
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioCompletionEvent
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioContext
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OscillatorNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PannerNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PeriodicWave
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PeriodicWaveImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ScriptProcessorNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  StereoPannerNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  WaveShaperNode
      sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AnalyserNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBuffer
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBufferSourceNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioProcessingEvent
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacityEvent
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BiquadFilterNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BlobEvent
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BlobEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConstantSourceNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConvolverNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElement
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioCompletionEvent
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioContext
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OscillatorNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PannerNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  WaveShaperNode
      sse_decode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AnalyserNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBuffer
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBufferSourceNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioContext
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioContextRegistration
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioContextRegistrationImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioDestinationNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioListener
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioListenerImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioParam
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioParamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioProcessingEvent
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacity
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacityEvent
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioWorkletNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BiquadFilterNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BlobEvent
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BlobEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelMergerNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelSplitterNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConcreteBaseAudioContext
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConstantSourceNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConvolverNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DelayNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DelayNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DynamicsCompressorNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  Event
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return EventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  GainNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return GainNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  IirFilterNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElementAudioSourceNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaRecorder
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStream
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioDestinationNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioSourceNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrack
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrackAudioSourceNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElement
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioCompletionEvent
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioContext
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OscillatorNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PannerNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ScriptProcessorNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  StereoPannerNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  WaveShaperNode
      sse_decode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  int sse_decode_CastedPrimitive_usize(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_usize(deserializer);
    return inner.toInt();
  }

  @protected
  Object sse_decode_DartOpaque(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_isize(deserializer);
    return decodeDartOpaque(inner, generalizedFrbRustBinding);
  }

  @protected
  AudioNode sse_decode_DynTrait_AudioNode(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('');
  }

  @protected
  AudioParam
      sse_decode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  MediaStream
      sse_decode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_detune(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_playback_rate(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_x(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_y(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_z(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_x(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_y(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_z(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_x(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_y(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_z(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_detune(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_frequency(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_gain(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_q(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode_offset(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode_delay_time(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_attack(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_knee(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_ratio(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_release(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_threshold(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode_gain(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  MediaStream
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode_stream(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_detune(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_frequency(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_x(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_y(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_z(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_x(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_y(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_z(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AudioParam
      sse_decode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode_pan(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  AnalyserNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AnalyserNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBuffer
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioBufferSourceNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioBufferSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioContext
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioContextRegistration
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioContextRegistrationImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioDestinationNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioListener
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioListenerImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioParam
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioParamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioParamId
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioParamIdImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioProcessingEvent
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioProcessingEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacity
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioRenderCapacityEvent
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioRenderCapacityEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  AudioWorkletNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return AudioWorkletNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BiquadFilterNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BiquadFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  BlobEvent
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return BlobEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelConfig
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelConfigImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelMergerNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelMergerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ChannelSplitterNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ChannelSplitterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConcreteBaseAudioContext
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConcreteBaseAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConstantSourceNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConstantSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ConvolverNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ConvolverNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DelayNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DelayNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DummyStruct
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DummyStructImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  DynamicsCompressorNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return DynamicsCompressorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  Event
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return EventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  GainNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return GainNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  IirFilterNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return IirFilterNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElementAudioSourceNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaRecorder
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaRecorderImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStream
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioDestinationNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioDestinationNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamAudioSourceNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamConstraints
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamConstraintsImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrack
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaStreamTrackAudioSourceNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaStreamTrackAudioSourceNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  MediaElement
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return MediaElementImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioCompletionEvent
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioCompletionEventImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OfflineAudioContext
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OfflineAudioContextImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  OscillatorNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return OscillatorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PannerNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  PeriodicWave
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return PeriodicWaveImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  ScriptProcessorNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return ScriptProcessorNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  StereoPannerNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return StereoPannerNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  WaveShaperNode
      sse_decode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return WaveShaperNodeImpl.frbInternalSseDecode(
        sse_decode_usize(deserializer), sse_decode_i_32(deserializer));
  }

  @protected
  String sse_decode_String(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_list_prim_u_8_strict(deserializer);
    return utf8.decoder.convert(inner);
  }

  @protected
  AnalyserOptions sse_decode_analyser_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_fftSize = sse_decode_CastedPrimitive_usize(deserializer);
    var var_maxDecibels = sse_decode_f_64(deserializer);
    var var_minDecibels = sse_decode_f_64(deserializer);
    var var_smoothingTimeConstant = sse_decode_f_64(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return AnalyserOptions(
        fftSize: var_fftSize,
        maxDecibels: var_maxDecibels,
        minDecibels: var_minDecibels,
        smoothingTimeConstant: var_smoothingTimeConstant,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  AudioBufferOptions sse_decode_audio_buffer_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_numberOfChannels = sse_decode_CastedPrimitive_usize(deserializer);
    var var_length = sse_decode_CastedPrimitive_usize(deserializer);
    var var_sampleRate = sse_decode_f_32(deserializer);
    return AudioBufferOptions(
        numberOfChannels: var_numberOfChannels,
        length: var_length,
        sampleRate: var_sampleRate);
  }

  @protected
  AudioBufferSourceOptions sse_decode_audio_buffer_source_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_buffer =
        sse_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            deserializer);
    var var_detune = sse_decode_f_32(deserializer);
    var var_loop = sse_decode_bool(deserializer);
    var var_loopStart = sse_decode_f_64(deserializer);
    var var_loopEnd = sse_decode_f_64(deserializer);
    var var_playbackRate = sse_decode_f_32(deserializer);
    return AudioBufferSourceOptions(
        buffer: var_buffer,
        detune: var_detune,
        loop: var_loop,
        loopStart: var_loopStart,
        loopEnd: var_loopEnd,
        playbackRate: var_playbackRate);
  }

  @protected
  AudioContextLatencyCategory sse_decode_audio_context_latency_category(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var tag_ = sse_decode_i_32(deserializer);
    switch (tag_) {
      case 0:
        return AudioContextLatencyCategory_Balanced();
      case 1:
        return AudioContextLatencyCategory_Interactive();
      case 2:
        return AudioContextLatencyCategory_Playback();
      case 3:
        var var_field0 = sse_decode_f_64(deserializer);
        return AudioContextLatencyCategory_Custom(var_field0);
      default:
        throw UnimplementedError('');
    }
  }

  @protected
  AudioContextOptions sse_decode_audio_context_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_latencyHint =
        sse_decode_audio_context_latency_category(deserializer);
    var var_sampleRate = sse_decode_opt_box_autoadd_f_32(deserializer);
    var var_sinkId = sse_decode_String(deserializer);
    var var_renderSizeHint =
        sse_decode_audio_context_render_size_category(deserializer);
    return AudioContextOptions(
        latencyHint: var_latencyHint,
        sampleRate: var_sampleRate,
        sinkId: var_sinkId,
        renderSizeHint: var_renderSizeHint);
  }

  @protected
  AudioContextRenderSizeCategory sse_decode_audio_context_render_size_category(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return AudioContextRenderSizeCategory.values[inner];
  }

  @protected
  AudioContextState sse_decode_audio_context_state(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return AudioContextState.values[inner];
  }

  @protected
  AudioNodeImplementor sse_decode_audio_node_implementor(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var tag_ = sse_decode_i_32(deserializer);
    switch (tag_) {
      case 0:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
                deserializer);
        return AudioNodeImplementor_Variant0(var_field0);
      case 1:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
                deserializer);
        return AudioNodeImplementor_Variant1(var_field0);
      case 2:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
                deserializer);
        return AudioNodeImplementor_Variant2(var_field0);
      case 3:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
                deserializer);
        return AudioNodeImplementor_Variant3(var_field0);
      case 4:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
                deserializer);
        return AudioNodeImplementor_Variant4(var_field0);
      case 5:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
                deserializer);
        return AudioNodeImplementor_Variant5(var_field0);
      case 6:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
                deserializer);
        return AudioNodeImplementor_Variant6(var_field0);
      case 7:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
                deserializer);
        return AudioNodeImplementor_Variant7(var_field0);
      case 8:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
                deserializer);
        return AudioNodeImplementor_Variant8(var_field0);
      case 9:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
                deserializer);
        return AudioNodeImplementor_Variant9(var_field0);
      case 10:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
                deserializer);
        return AudioNodeImplementor_Variant10(var_field0);
      case 11:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return AudioNodeImplementor_Variant11(var_field0);
      case 12:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
                deserializer);
        return AudioNodeImplementor_Variant12(var_field0);
      case 13:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
                deserializer);
        return AudioNodeImplementor_Variant13(var_field0);
      case 14:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
                deserializer);
        return AudioNodeImplementor_Variant14(var_field0);
      case 15:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
                deserializer);
        return AudioNodeImplementor_Variant15(var_field0);
      case 16:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
                deserializer);
        return AudioNodeImplementor_Variant16(var_field0);
      case 17:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
                deserializer);
        return AudioNodeImplementor_Variant17(var_field0);
      case 18:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
                deserializer);
        return AudioNodeImplementor_Variant18(var_field0);
      case 19:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return AudioNodeImplementor_Variant19(var_field0);
      case 20:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
                deserializer);
        return AudioNodeImplementor_Variant20(var_field0);
      case 21:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
                deserializer);
        return AudioNodeImplementor_Variant21(var_field0);
      case 22:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
                deserializer);
        return AudioNodeImplementor_Variant22(var_field0);
      default:
        throw UnimplementedError('');
    }
  }

  @protected
  AudioNodeOptions sse_decode_audio_node_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_channelCount = sse_decode_CastedPrimitive_usize(deserializer);
    var var_channelCountMode = sse_decode_channel_count_mode(deserializer);
    var var_channelInterpretation =
        sse_decode_channel_interpretation(deserializer);
    return AudioNodeOptions(
        channelCount: var_channelCount,
        channelCountMode: var_channelCountMode,
        channelInterpretation: var_channelInterpretation);
  }

  @protected
  AudioParamDescriptor sse_decode_audio_param_descriptor(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_name = sse_decode_String(deserializer);
    var var_automationRate = sse_decode_automation_rate(deserializer);
    var var_defaultValue = sse_decode_f_32(deserializer);
    var var_minValue = sse_decode_f_32(deserializer);
    var var_maxValue = sse_decode_f_32(deserializer);
    return AudioParamDescriptor(
        name: var_name,
        automationRate: var_automationRate,
        defaultValue: var_defaultValue,
        minValue: var_minValue,
        maxValue: var_maxValue);
  }

  @protected
  AudioRenderCapacityOptions sse_decode_audio_render_capacity_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_updateInterval = sse_decode_f_64(deserializer);
    return AudioRenderCapacityOptions(updateInterval: var_updateInterval);
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
      sse_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var tag_ = sse_decode_i_32(deserializer);
    switch (tag_) {
      case 0:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant0(
            var_field0);
      case 1:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant1(
            var_field0);
      case 2:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant2(
            var_field0);
      case 3:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant3(
            var_field0);
      case 4:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant4(
            var_field0);
      case 5:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant5(
            var_field0);
      case 6:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant6(
            var_field0);
      case 7:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant7(
            var_field0);
      case 8:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant8(
            var_field0);
      case 9:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant9(
            var_field0);
      case 10:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant10(
            var_field0);
      case 11:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant11(
            var_field0);
      case 12:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant12(
            var_field0);
      case 13:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant13(
            var_field0);
      case 14:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant14(
            var_field0);
      case 15:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant15(
            var_field0);
      case 16:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant16(
            var_field0);
      case 17:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant17(
            var_field0);
      case 18:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant18(
            var_field0);
      case 19:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant19(
            var_field0);
      case 20:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant20(
            var_field0);
      case 21:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant21(
            var_field0);
      case 22:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant22(
            var_field0);
      case 23:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant23(
            var_field0);
      case 24:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant24(
            var_field0);
      case 25:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant25(
            var_field0);
      case 26:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant26(
            var_field0);
      case 27:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant27(
            var_field0);
      case 28:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant28(
            var_field0);
      case 29:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant29(
            var_field0);
      case 30:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant30(
            var_field0);
      case 31:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant31(
            var_field0);
      default:
        throw UnimplementedError('');
    }
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
      sse_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var tag_ = sse_decode_i_32(deserializer);
    switch (tag_) {
      case 0:
        var var_field0 =
            sse_decode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
                deserializer);
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum_Variant0(
            var_field0);
      default:
        throw UnimplementedError('');
    }
  }

  @protected
  AutomationRate sse_decode_automation_rate(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return AutomationRate.values[inner];
  }

  @protected
  BiquadFilterOptions sse_decode_biquad_filter_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_q = sse_decode_f_32(deserializer);
    var var_detune = sse_decode_f_32(deserializer);
    var var_frequency = sse_decode_f_32(deserializer);
    var var_gain = sse_decode_f_32(deserializer);
    var var_type = sse_decode_biquad_filter_type(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return BiquadFilterOptions(
        q: var_q,
        detune: var_detune,
        frequency: var_frequency,
        gain: var_gain,
        type: var_type,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  BiquadFilterType sse_decode_biquad_filter_type(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return BiquadFilterType.values[inner];
  }

  @protected
  bool sse_decode_bool(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getUint8() != 0;
  }

  @protected
  AudioBuffer
      sse_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
        deserializer));
  }

  @protected
  PeriodicWave
      sse_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
        deserializer));
  }

  @protected
  AudioBufferOptions sse_decode_box_autoadd_audio_buffer_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_audio_buffer_options(deserializer));
  }

  @protected
  AudioContextOptions sse_decode_box_autoadd_audio_context_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_audio_context_options(deserializer));
  }

  @protected
  AudioNodeImplementor sse_decode_box_autoadd_audio_node_implementor(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_audio_node_implementor(deserializer));
  }

  @protected
  AudioParamDescriptor sse_decode_box_autoadd_audio_param_descriptor(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_audio_param_descriptor(deserializer));
  }

  @protected
  AudioRenderCapacityOptions
      sse_decode_box_autoadd_audio_render_capacity_options(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_audio_render_capacity_options(deserializer));
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
      sse_decode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
        deserializer));
  }

  @protected
  Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
      sse_decode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
        deserializer));
  }

  @protected
  double sse_decode_box_autoadd_f_32(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_f_32(deserializer));
  }

  @protected
  PeriodicWaveOptions sse_decode_box_autoadd_periodic_wave_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return (sse_decode_periodic_wave_options(deserializer));
  }

  @protected
  ChannelCountMode sse_decode_channel_count_mode(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return ChannelCountMode.values[inner];
  }

  @protected
  ChannelInterpretation sse_decode_channel_interpretation(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return ChannelInterpretation.values[inner];
  }

  @protected
  ChannelMergerOptions sse_decode_channel_merger_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_numberOfInputs = sse_decode_CastedPrimitive_usize(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return ChannelMergerOptions(
        numberOfInputs: var_numberOfInputs,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  ChannelSplitterOptions sse_decode_channel_splitter_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_numberOfOutputs = sse_decode_CastedPrimitive_usize(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return ChannelSplitterOptions(
        numberOfOutputs: var_numberOfOutputs,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  ConstantSourceOptions sse_decode_constant_source_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_offset = sse_decode_f_32(deserializer);
    return ConstantSourceOptions(offset: var_offset);
  }

  @protected
  ConvolverOptions sse_decode_convolver_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_buffer =
        sse_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
            deserializer);
    var var_disableNormalization = sse_decode_bool(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return ConvolverOptions(
        buffer: var_buffer,
        disableNormalization: var_disableNormalization,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  DelayOptions sse_decode_delay_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_maxDelayTime = sse_decode_f_64(deserializer);
    var var_delayTime = sse_decode_f_64(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return DelayOptions(
        maxDelayTime: var_maxDelayTime,
        delayTime: var_delayTime,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  DistanceModelType sse_decode_distance_model_type(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return DistanceModelType.values[inner];
  }

  @protected
  DynamicsCompressorOptions sse_decode_dynamics_compressor_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_attack = sse_decode_f_32(deserializer);
    var var_knee = sse_decode_f_32(deserializer);
    var var_ratio = sse_decode_f_32(deserializer);
    var var_release = sse_decode_f_32(deserializer);
    var var_threshold = sse_decode_f_32(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return DynamicsCompressorOptions(
        attack: var_attack,
        knee: var_knee,
        ratio: var_ratio,
        release: var_release,
        threshold: var_threshold,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  double sse_decode_f_32(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getFloat32();
  }

  @protected
  double sse_decode_f_64(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getFloat64();
  }

  @protected
  GainOptions sse_decode_gain_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_gain = sse_decode_f_32(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return GainOptions(gain: var_gain, audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  int sse_decode_i_32(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getInt32();
  }

  @protected
  PlatformInt64 sse_decode_isize(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getPlatformInt64();
  }

  @protected
  List<MediaStreamTrack>
      sse_decode_list_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var len_ = sse_decode_i_32(deserializer);
    var ans_ = <MediaStreamTrack>[];
    for (var idx_ = 0; idx_ < len_; ++idx_) {
      ans_.add(
          sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
              deserializer));
    }
    return ans_;
  }

  @protected
  List<AudioParamDescriptor> sse_decode_list_audio_param_descriptor(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var len_ = sse_decode_i_32(deserializer);
    var ans_ = <AudioParamDescriptor>[];
    for (var idx_ = 0; idx_ < len_; ++idx_) {
      ans_.add(sse_decode_audio_param_descriptor(deserializer));
    }
    return ans_;
  }

  @protected
  List<Float32List> sse_decode_list_list_prim_f_32_strict(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    var len_ = sse_decode_i_32(deserializer);
    var ans_ = <Float32List>[];
    for (var idx_ = 0; idx_ < len_; ++idx_) {
      ans_.add(sse_decode_list_prim_f_32_strict(deserializer));
    }
    return ans_;
  }

  @protected
  List<double> sse_decode_list_prim_f_32_loose(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var len_ = sse_decode_i_32(deserializer);
    return deserializer.buffer.getFloat32List(len_);
  }

  @protected
  Float32List sse_decode_list_prim_f_32_strict(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var len_ = sse_decode_i_32(deserializer);
    return deserializer.buffer.getFloat32List(len_);
  }

  @protected
  List<double> sse_decode_list_prim_f_64_loose(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var len_ = sse_decode_i_32(deserializer);
    return deserializer.buffer.getFloat64List(len_);
  }

  @protected
  Float64List sse_decode_list_prim_f_64_strict(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var len_ = sse_decode_i_32(deserializer);
    return deserializer.buffer.getFloat64List(len_);
  }

  @protected
  Uint8List sse_decode_list_prim_u_8_strict(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var len_ = sse_decode_i_32(deserializer);
    return deserializer.buffer.getUint8List(len_);
  }

  @protected
  MediaStreamTrackState sse_decode_media_stream_track_state(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return MediaStreamTrackState.values[inner];
  }

  @protected
  AudioBuffer?
      sse_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    if (sse_decode_bool(deserializer)) {
      return (sse_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          deserializer));
    } else {
      return null;
    }
  }

  @protected
  PeriodicWave?
      sse_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    if (sse_decode_bool(deserializer)) {
      return (sse_decode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          deserializer));
    } else {
      return null;
    }
  }

  @protected
  double? sse_decode_opt_box_autoadd_f_32(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    if (sse_decode_bool(deserializer)) {
      return (sse_decode_box_autoadd_f_32(deserializer));
    } else {
      return null;
    }
  }

  @protected
  Float32List? sse_decode_opt_list_prim_f_32_strict(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    if (sse_decode_bool(deserializer)) {
      return (sse_decode_list_prim_f_32_strict(deserializer));
    } else {
      return null;
    }
  }

  @protected
  OscillatorOptions sse_decode_oscillator_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_type = sse_decode_oscillator_type(deserializer);
    var var_frequency = sse_decode_f_32(deserializer);
    var var_detune = sse_decode_f_32(deserializer);
    var var_periodicWave =
        sse_decode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
            deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return OscillatorOptions(
        type: var_type,
        frequency: var_frequency,
        detune: var_detune,
        periodicWave: var_periodicWave,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  OscillatorType sse_decode_oscillator_type(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return OscillatorType.values[inner];
  }

  @protected
  OverSampleType sse_decode_over_sample_type(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return OverSampleType.values[inner];
  }

  @protected
  PannerOptions sse_decode_panner_options(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_panningModel = sse_decode_panning_model_type(deserializer);
    var var_distanceModel = sse_decode_distance_model_type(deserializer);
    var var_positionX = sse_decode_f_32(deserializer);
    var var_positionY = sse_decode_f_32(deserializer);
    var var_positionZ = sse_decode_f_32(deserializer);
    var var_orientationX = sse_decode_f_32(deserializer);
    var var_orientationY = sse_decode_f_32(deserializer);
    var var_orientationZ = sse_decode_f_32(deserializer);
    var var_refDistance = sse_decode_f_64(deserializer);
    var var_maxDistance = sse_decode_f_64(deserializer);
    var var_rolloffFactor = sse_decode_f_64(deserializer);
    var var_coneInnerAngle = sse_decode_f_64(deserializer);
    var var_coneOuterAngle = sse_decode_f_64(deserializer);
    var var_coneOuterGain = sse_decode_f_64(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return PannerOptions(
        panningModel: var_panningModel,
        distanceModel: var_distanceModel,
        positionX: var_positionX,
        positionY: var_positionY,
        positionZ: var_positionZ,
        orientationX: var_orientationX,
        orientationY: var_orientationY,
        orientationZ: var_orientationZ,
        refDistance: var_refDistance,
        maxDistance: var_maxDistance,
        rolloffFactor: var_rolloffFactor,
        coneInnerAngle: var_coneInnerAngle,
        coneOuterAngle: var_coneOuterAngle,
        coneOuterGain: var_coneOuterGain,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  PanningModelType sse_decode_panning_model_type(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var inner = sse_decode_i_32(deserializer);
    return PanningModelType.values[inner];
  }

  @protected
  PeriodicWaveOptions sse_decode_periodic_wave_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_real = sse_decode_opt_list_prim_f_32_strict(deserializer);
    var var_imag = sse_decode_opt_list_prim_f_32_strict(deserializer);
    var var_disableNormalization = sse_decode_bool(deserializer);
    return PeriodicWaveOptions(
        real: var_real,
        imag: var_imag,
        disableNormalization: var_disableNormalization);
  }

  @protected
  (
    AudioParam,
    AudioParamId
  ) sse_decode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_field0 =
        sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
            deserializer);
    var var_field1 =
        sse_decode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
            deserializer);
    return (var_field0, var_field1);
  }

  @protected
  StereoPannerOptions sse_decode_stereo_panner_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_pan = sse_decode_f_32(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return StereoPannerOptions(
        pan: var_pan, audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  int sse_decode_u_8(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getUint8();
  }

  @protected
  void sse_decode_unit(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
  }

  @protected
  BigInt sse_decode_usize(SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    return deserializer.buffer.getBigUint64();
  }

  @protected
  WaveShaperOptions sse_decode_wave_shaper_options(
      SseDeserializer deserializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    var var_curve = sse_decode_opt_list_prim_f_32_strict(deserializer);
    var var_oversample = sse_decode_over_sample_type(deserializer);
    var var_audioNodeOptions = sse_decode_audio_node_options(deserializer);
    return WaveShaperOptions(
        curve: var_curve,
        oversample: var_oversample,
        audioNodeOptions: var_audioNodeOptions);
  }

  @protected
  void sse_encode_AnyhowException(
      AnyhowException self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_String(self.message, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          AnalyserNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          AudioBufferSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          AudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          AudioListener self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          AudioWorkletNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          BiquadFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          ChannelMergerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          ChannelSplitterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          ConstantSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          ConvolverNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          DelayNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          DynamicsCompressorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          GainNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          IirFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          MediaElementAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          MediaStreamAudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          MediaStreamAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          MediaStreamTrackAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          OscillatorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          PannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          ScriptProcessorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          StereoPannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          WaveShaperNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
        self, serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          AnalyserNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AnalyserNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          AudioBufferSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferSourceNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          AudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioContextImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          AudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioDestinationNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          AudioListener self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioListenerImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioParamImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          AudioParamId self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioParamIdImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          AudioProcessingEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioProcessingEventImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          AudioRenderCapacity self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          AudioRenderCapacityEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityEventImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          AudioWorkletNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioWorkletNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          BiquadFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BiquadFilterNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          BlobEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BlobEventImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          ChannelConfig self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelConfigImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          ChannelMergerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelMergerNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          ChannelSplitterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelSplitterNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          ConcreteBaseAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConcreteBaseAudioContextImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          ConstantSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConstantSourceNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          ConvolverNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConvolverNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          DelayNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DelayNodeImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          DummyStruct self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DummyStructImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          DynamicsCompressorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DynamicsCompressorNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          Event self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as EventImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          GainNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as GainNodeImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          IirFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as IirFilterNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          MediaElementAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementAudioSourceNodeImpl)
            .frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          MediaRecorder self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaRecorderImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          MediaStream self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          MediaStreamAudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioDestinationNodeImpl)
            .frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          MediaStreamAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioSourceNodeImpl)
            .frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          MediaStreamConstraints self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamConstraintsImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          MediaStreamTrack self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          MediaStreamTrackAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackAudioSourceNodeImpl)
            .frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          MediaElement self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          OfflineAudioCompletionEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioCompletionEventImpl)
            .frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          OfflineAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioContextImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          OscillatorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OscillatorNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          PannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PannerNodeImpl).frbInternalSseEncode(move: true), serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          PeriodicWave self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PeriodicWaveImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          ScriptProcessorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ScriptProcessorNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          StereoPannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as StereoPannerNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          WaveShaperNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as WaveShaperNodeImpl).frbInternalSseEncode(move: true),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          AnalyserNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AnalyserNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          AudioBufferSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferSourceNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          AudioProcessingEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioProcessingEventImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          AudioRenderCapacityEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityEventImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          BiquadFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BiquadFilterNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          BlobEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BlobEventImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          ConstantSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConstantSourceNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          ConvolverNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConvolverNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          MediaElement self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          OfflineAudioCompletionEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioCompletionEventImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          OfflineAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioContextImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          OscillatorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OscillatorNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          PannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PannerNodeImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_RefMut_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          WaveShaperNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as WaveShaperNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          AnalyserNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AnalyserNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          AudioBufferSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferSourceNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          AudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioContextImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          AudioContextRegistration self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioContextRegistrationImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          AudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioDestinationNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          AudioListener self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioListenerImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioParamImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          AudioProcessingEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioProcessingEventImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          AudioRenderCapacity self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          AudioRenderCapacityEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityEventImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          AudioWorkletNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioWorkletNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          BiquadFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BiquadFilterNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          BlobEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BlobEventImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          ChannelMergerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelMergerNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          ChannelSplitterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelSplitterNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          ConcreteBaseAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConcreteBaseAudioContextImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          ConstantSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConstantSourceNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          ConvolverNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConvolverNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          DelayNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DelayNodeImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          DynamicsCompressorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DynamicsCompressorNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          Event self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as EventImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          GainNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as GainNodeImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          IirFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as IirFilterNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          MediaElementAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementAudioSourceNodeImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          MediaRecorder self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaRecorderImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          MediaStream self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          MediaStreamAudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioDestinationNodeImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          MediaStreamAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioSourceNodeImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          MediaStreamTrack self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          MediaStreamTrackAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackAudioSourceNodeImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          MediaElement self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          OfflineAudioCompletionEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioCompletionEventImpl)
            .frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          OfflineAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioContextImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          OscillatorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OscillatorNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          PannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PannerNodeImpl).frbInternalSseEncode(move: false), serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          ScriptProcessorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ScriptProcessorNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          StereoPannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as StereoPannerNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void
      sse_encode_Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          WaveShaperNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as WaveShaperNodeImpl).frbInternalSseEncode(move: false),
        serializer);
  }

  @protected
  void sse_encode_CastedPrimitive_usize(int self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(sseEncodeCastedPrimitiveU64(self), serializer);
  }

  @protected
  void
      sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(AudioProcessingEvent) self,
          SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_DartOpaque(
        encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent_Output_unit_AnyhowException(
            self),
        serializer);
  }

  @protected
  void
      sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(Event) self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_DartOpaque(
        encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent_Output_unit_AnyhowException(
            self),
        serializer);
  }

  @protected
  void
      sse_encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent_Output_unit_AnyhowException(
          FutureOr<void> Function(OfflineAudioCompletionEvent) self,
          SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_DartOpaque(
        encode_DartFn_Inputs_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent_Output_unit_AnyhowException(
            self),
        serializer);
  }

  @protected
  void sse_encode_DartFn_Inputs_String_Output_unit_AnyhowException(
      FutureOr<void> Function(String) self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_DartOpaque(
        encode_DartFn_Inputs_String_Output_unit_AnyhowException(self),
        serializer);
  }

  @protected
  void sse_encode_DartOpaque(Object self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_isize(
        PlatformPointerUtil.ptrToPlatformInt64(encodeDartOpaque(
            self, portManager.dartHandlerPort, generalizedFrbRustBinding)),
        serializer);
  }

  @protected
  void sse_encode_DynTrait_AudioNode(AudioNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_node_implementor((() {
      if (self is AnalyserNode) {
        return AudioNodeImplementor.variant0(self);
      }
      if (self is AudioBufferSourceNode) {
        return AudioNodeImplementor.variant1(self);
      }
      if (self is AudioDestinationNode) {
        return AudioNodeImplementor.variant2(self);
      }
      if (self is AudioParam) {
        return AudioNodeImplementor.variant3(self);
      }
      if (self is AudioWorkletNode) {
        return AudioNodeImplementor.variant4(self);
      }
      if (self is BiquadFilterNode) {
        return AudioNodeImplementor.variant5(self);
      }
      if (self is ChannelMergerNode) {
        return AudioNodeImplementor.variant6(self);
      }
      if (self is ChannelSplitterNode) {
        return AudioNodeImplementor.variant7(self);
      }
      if (self is ConstantSourceNode) {
        return AudioNodeImplementor.variant8(self);
      }
      if (self is ConvolverNode) {
        return AudioNodeImplementor.variant9(self);
      }
      if (self is DelayNode) {
        return AudioNodeImplementor.variant10(self);
      }
      if (self is DynamicsCompressorNode) {
        return AudioNodeImplementor.variant11(self);
      }
      if (self is GainNode) {
        return AudioNodeImplementor.variant12(self);
      }
      if (self is IirFilterNode) {
        return AudioNodeImplementor.variant13(self);
      }
      if (self is MediaElementAudioSourceNode) {
        return AudioNodeImplementor.variant14(self);
      }
      if (self is MediaStreamAudioDestinationNode) {
        return AudioNodeImplementor.variant15(self);
      }
      if (self is MediaStreamAudioSourceNode) {
        return AudioNodeImplementor.variant16(self);
      }
      if (self is MediaStreamTrackAudioSourceNode) {
        return AudioNodeImplementor.variant17(self);
      }
      if (self is OscillatorNode) {
        return AudioNodeImplementor.variant18(self);
      }
      if (self is PannerNode) {
        return AudioNodeImplementor.variant19(self);
      }
      if (self is ScriptProcessorNode) {
        return AudioNodeImplementor.variant20(self);
      }
      if (self is StereoPannerNode) {
        return AudioNodeImplementor.variant21(self);
      }
      if (self is WaveShaperNode) {
        return AudioNodeImplementor.variant22(self);
      }

      throw Exception('not reachable');
    })(), serializer);
  }

  @protected
  void
      sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
        (() {
      if (self is AudioParamProxyVariantAudioBufferSourceNodeDetune) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant0(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioBufferSourceNodePlaybackRate) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant1(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerForwardX) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant2(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerForwardY) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant3(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerForwardZ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant4(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerPositionX) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant5(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerPositionY) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant6(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerPositionZ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant7(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerUpX) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant8(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerUpY) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant9(self._upstream);
      }
      if (self is AudioParamProxyVariantAudioListenerUpZ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant10(self._upstream);
      }
      if (self is AudioParamProxyVariantBiquadFilterNodeDetune) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant11(self._upstream);
      }
      if (self is AudioParamProxyVariantBiquadFilterNodeFrequency) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant12(self._upstream);
      }
      if (self is AudioParamProxyVariantBiquadFilterNodeGain) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant13(self._upstream);
      }
      if (self is AudioParamProxyVariantBiquadFilterNodeQ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant14(self._upstream);
      }
      if (self is AudioParamProxyVariantConstantSourceNodeOffset) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant15(self._upstream);
      }
      if (self is AudioParamProxyVariantDelayNodeDelayTime) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant16(self._upstream);
      }
      if (self is AudioParamProxyVariantDynamicsCompressorNodeAttack) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant17(self._upstream);
      }
      if (self is AudioParamProxyVariantDynamicsCompressorNodeKnee) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant18(self._upstream);
      }
      if (self is AudioParamProxyVariantDynamicsCompressorNodeRatio) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant19(self._upstream);
      }
      if (self is AudioParamProxyVariantDynamicsCompressorNodeRelease) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant20(self._upstream);
      }
      if (self is AudioParamProxyVariantDynamicsCompressorNodeThreshold) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant21(self._upstream);
      }
      if (self is AudioParamProxyVariantGainNodeGain) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant22(self._upstream);
      }
      if (self is AudioParamProxyVariantOscillatorNodeDetune) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant23(self._upstream);
      }
      if (self is AudioParamProxyVariantOscillatorNodeFrequency) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant24(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodeOrientationX) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant25(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodeOrientationY) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant26(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodeOrientationZ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant27(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodePositionX) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant28(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodePositionY) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant29(self._upstream);
      }
      if (self is AudioParamProxyVariantPannerNodePositionZ) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant30(self._upstream);
      }
      if (self is AudioParamProxyVariantStereoPannerNodePan) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
            .variant31(self._upstream);
      }

      throw Exception('not reachable');
    })(), serializer);
  }

  @protected
  void
      sse_encode_ProxyEnum_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
          MediaStream self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
        (() {
      if (self
          is MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream) {
        return Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
            .variant0(self._upstream);
      }

      throw Exception('not reachable');
    })(), serializer);
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_detune(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode_playback_rate(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_x(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_y(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_forward_z(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_x(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_y(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_position_z(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_x(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_y(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener_up_z(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_detune(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_frequency(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_gain(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode_q(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode_offset(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode_delay_time(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_attack(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_knee(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_ratio(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_release(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode_threshold(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode_gain(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode_stream(
          MediaStream self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_detune(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode_frequency(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_x(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_y(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_orientation_z(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_x(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_y(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode_position_z(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_ProxyVariant_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode_pan(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    throw UnimplementedError('Unreachable ()');
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
          AnalyserNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AnalyserNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
          AudioBufferSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioBufferSourceNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContext(
          AudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioContextImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioContextRegistration(
          AudioContextRegistration self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioContextRegistrationImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
          AudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioDestinationNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
          AudioListener self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioListenerImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
          AudioParam self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioParamImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
          AudioParamId self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioParamIdImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioProcessingEvent(
          AudioProcessingEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioProcessingEventImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacity(
          AudioRenderCapacity self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioRenderCapacityEvent(
          AudioRenderCapacityEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioRenderCapacityEventImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
          AudioWorkletNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as AudioWorkletNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
          BiquadFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BiquadFilterNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBlobEvent(
          BlobEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as BlobEventImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelConfig(
          ChannelConfig self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelConfigImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
          ChannelMergerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelMergerNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
          ChannelSplitterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ChannelSplitterNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConcreteBaseAudioContext(
          ConcreteBaseAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConcreteBaseAudioContextImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
          ConstantSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConstantSourceNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
          ConvolverNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ConvolverNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
          DelayNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DelayNodeImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDummyStruct(
          DummyStruct self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DummyStructImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
          DynamicsCompressorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as DynamicsCompressorNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerEvent(
          Event self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as EventImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
          GainNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as GainNodeImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
          IirFilterNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as IirFilterNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
          MediaElementAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementAudioSourceNodeImpl)
            .frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaRecorder(
          MediaRecorder self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaRecorderImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStream(
          MediaStream self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
          MediaStreamAudioDestinationNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioDestinationNodeImpl)
            .frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
          MediaStreamAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamAudioSourceNodeImpl)
            .frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamConstraints(
          MediaStreamConstraints self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamConstraintsImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          MediaStreamTrack self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
          MediaStreamTrackAudioSourceNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaStreamTrackAudioSourceNodeImpl)
            .frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMyMediaElement(
          MediaElement self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as MediaElementImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioCompletionEvent(
          OfflineAudioCompletionEvent self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioCompletionEventImpl)
            .frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOfflineAudioContext(
          OfflineAudioContext self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OfflineAudioContextImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
          OscillatorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as OscillatorNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
          PannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PannerNodeImpl).frbInternalSseEncode(move: null), serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          PeriodicWave self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as PeriodicWaveImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
          ScriptProcessorNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as ScriptProcessorNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
          StereoPannerNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as StereoPannerNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void
      sse_encode_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
          WaveShaperNode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_usize(
        (self as WaveShaperNodeImpl).frbInternalSseEncode(move: null),
        serializer);
  }

  @protected
  void sse_encode_String(String self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_list_prim_u_8_strict(utf8.encoder.convert(self), serializer);
  }

  @protected
  void sse_encode_analyser_options(
      AnalyserOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_CastedPrimitive_usize(self.fftSize, serializer);
    sse_encode_f_64(self.maxDecibels, serializer);
    sse_encode_f_64(self.minDecibels, serializer);
    sse_encode_f_64(self.smoothingTimeConstant, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_audio_buffer_options(
      AudioBufferOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_CastedPrimitive_usize(self.numberOfChannels, serializer);
    sse_encode_CastedPrimitive_usize(self.length, serializer);
    sse_encode_f_32(self.sampleRate, serializer);
  }

  @protected
  void sse_encode_audio_buffer_source_options(
      AudioBufferSourceOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
        self.buffer, serializer);
    sse_encode_f_32(self.detune, serializer);
    sse_encode_bool(self.loop, serializer);
    sse_encode_f_64(self.loopStart, serializer);
    sse_encode_f_64(self.loopEnd, serializer);
    sse_encode_f_32(self.playbackRate, serializer);
  }

  @protected
  void sse_encode_audio_context_latency_category(
      AudioContextLatencyCategory self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    switch (self) {
      case AudioContextLatencyCategory_Balanced():
        sse_encode_i_32(0, serializer);
      case AudioContextLatencyCategory_Interactive():
        sse_encode_i_32(1, serializer);
      case AudioContextLatencyCategory_Playback():
        sse_encode_i_32(2, serializer);
      case AudioContextLatencyCategory_Custom(field0: final field0):
        sse_encode_i_32(3, serializer);
        sse_encode_f_64(field0, serializer);
    }
  }

  @protected
  void sse_encode_audio_context_options(
      AudioContextOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_context_latency_category(self.latencyHint, serializer);
    sse_encode_opt_box_autoadd_f_32(self.sampleRate, serializer);
    sse_encode_String(self.sinkId, serializer);
    sse_encode_audio_context_render_size_category(
        self.renderSizeHint, serializer);
  }

  @protected
  void sse_encode_audio_context_render_size_category(
      AudioContextRenderSizeCategory self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_audio_context_state(
      AudioContextState self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_audio_node_implementor(
      AudioNodeImplementor self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    switch (self) {
      case AudioNodeImplementor_Variant0(field0: final field0):
        sse_encode_i_32(0, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAnalyserNode(
            field0, serializer);
      case AudioNodeImplementor_Variant1(field0: final field0):
        sse_encode_i_32(1, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            field0, serializer);
      case AudioNodeImplementor_Variant2(field0: final field0):
        sse_encode_i_32(2, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioDestinationNode(
            field0, serializer);
      case AudioNodeImplementor_Variant3(field0: final field0):
        sse_encode_i_32(3, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
            field0, serializer);
      case AudioNodeImplementor_Variant4(field0: final field0):
        sse_encode_i_32(4, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioWorkletNode(
            field0, serializer);
      case AudioNodeImplementor_Variant5(field0: final field0):
        sse_encode_i_32(5, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            field0, serializer);
      case AudioNodeImplementor_Variant6(field0: final field0):
        sse_encode_i_32(6, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelMergerNode(
            field0, serializer);
      case AudioNodeImplementor_Variant7(field0: final field0):
        sse_encode_i_32(7, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerChannelSplitterNode(
            field0, serializer);
      case AudioNodeImplementor_Variant8(field0: final field0):
        sse_encode_i_32(8, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            field0, serializer);
      case AudioNodeImplementor_Variant9(field0: final field0):
        sse_encode_i_32(9, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConvolverNode(
            field0, serializer);
      case AudioNodeImplementor_Variant10(field0: final field0):
        sse_encode_i_32(10, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            field0, serializer);
      case AudioNodeImplementor_Variant11(field0: final field0):
        sse_encode_i_32(11, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case AudioNodeImplementor_Variant12(field0: final field0):
        sse_encode_i_32(12, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            field0, serializer);
      case AudioNodeImplementor_Variant13(field0: final field0):
        sse_encode_i_32(13, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerIIRFilterNode(
            field0, serializer);
      case AudioNodeImplementor_Variant14(field0: final field0):
        sse_encode_i_32(14, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaElementAudioSourceNode(
            field0, serializer);
      case AudioNodeImplementor_Variant15(field0: final field0):
        sse_encode_i_32(15, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            field0, serializer);
      case AudioNodeImplementor_Variant16(field0: final field0):
        sse_encode_i_32(16, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioSourceNode(
            field0, serializer);
      case AudioNodeImplementor_Variant17(field0: final field0):
        sse_encode_i_32(17, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrackAudioSourceNode(
            field0, serializer);
      case AudioNodeImplementor_Variant18(field0: final field0):
        sse_encode_i_32(18, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            field0, serializer);
      case AudioNodeImplementor_Variant19(field0: final field0):
        sse_encode_i_32(19, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case AudioNodeImplementor_Variant20(field0: final field0):
        sse_encode_i_32(20, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerScriptProcessorNode(
            field0, serializer);
      case AudioNodeImplementor_Variant21(field0: final field0):
        sse_encode_i_32(21, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            field0, serializer);
      case AudioNodeImplementor_Variant22(field0: final field0):
        sse_encode_i_32(22, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerWaveShaperNode(
            field0, serializer);
    }
  }

  @protected
  void sse_encode_audio_node_options(
      AudioNodeOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_CastedPrimitive_usize(self.channelCount, serializer);
    sse_encode_channel_count_mode(self.channelCountMode, serializer);
    sse_encode_channel_interpretation(self.channelInterpretation, serializer);
  }

  @protected
  void sse_encode_audio_param_descriptor(
      AudioParamDescriptor self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_String(self.name, serializer);
    sse_encode_automation_rate(self.automationRate, serializer);
    sse_encode_f_32(self.defaultValue, serializer);
    sse_encode_f_32(self.minValue, serializer);
    sse_encode_f_32(self.maxValue, serializer);
  }

  @protected
  void sse_encode_audio_render_capacity_options(
      AudioRenderCapacityOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_64(self.updateInterval, serializer);
  }

  @protected
  void sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
      Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
          self,
      SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    switch (self) {
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant0(
          field0: final field0
        ):
        sse_encode_i_32(0, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant1(
          field0: final field0
        ):
        sse_encode_i_32(1, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBufferSourceNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant2(
          field0: final field0
        ):
        sse_encode_i_32(2, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant3(
          field0: final field0
        ):
        sse_encode_i_32(3, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant4(
          field0: final field0
        ):
        sse_encode_i_32(4, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant5(
          field0: final field0
        ):
        sse_encode_i_32(5, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant6(
          field0: final field0
        ):
        sse_encode_i_32(6, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant7(
          field0: final field0
        ):
        sse_encode_i_32(7, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant8(
          field0: final field0
        ):
        sse_encode_i_32(8, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant9(
          field0: final field0
        ):
        sse_encode_i_32(9, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant10(
          field0: final field0
        ):
        sse_encode_i_32(10, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioListener(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant11(
          field0: final field0
        ):
        sse_encode_i_32(11, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant12(
          field0: final field0
        ):
        sse_encode_i_32(12, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant13(
          field0: final field0
        ):
        sse_encode_i_32(13, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant14(
          field0: final field0
        ):
        sse_encode_i_32(14, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerBiquadFilterNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant15(
          field0: final field0
        ):
        sse_encode_i_32(15, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerConstantSourceNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant16(
          field0: final field0
        ):
        sse_encode_i_32(16, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDelayNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant17(
          field0: final field0
        ):
        sse_encode_i_32(17, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant18(
          field0: final field0
        ):
        sse_encode_i_32(18, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant19(
          field0: final field0
        ):
        sse_encode_i_32(19, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant20(
          field0: final field0
        ):
        sse_encode_i_32(20, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant21(
          field0: final field0
        ):
        sse_encode_i_32(21, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerDynamicsCompressorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant22(
          field0: final field0
        ):
        sse_encode_i_32(22, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerGainNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant23(
          field0: final field0
        ):
        sse_encode_i_32(23, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant24(
          field0: final field0
        ):
        sse_encode_i_32(24, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerOscillatorNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant25(
          field0: final field0
        ):
        sse_encode_i_32(25, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant26(
          field0: final field0
        ):
        sse_encode_i_32(26, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant27(
          field0: final field0
        ):
        sse_encode_i_32(27, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant28(
          field0: final field0
        ):
        sse_encode_i_32(28, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant29(
          field0: final field0
        ):
        sse_encode_i_32(29, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant30(
          field0: final field0
        ):
        sse_encode_i_32(30, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPannerNode(
            field0, serializer);
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant31(
          field0: final field0
        ):
        sse_encode_i_32(31, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerStereoPannerNode(
            field0, serializer);
    }
  }

  @protected
  void sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
      Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
          self,
      SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    switch (self) {
      case Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum_Variant0(
          field0: final field0
        ):
        sse_encode_i_32(0, serializer);
        sse_encode_AutoExplicit_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamAudioDestinationNode(
            field0, serializer);
    }
  }

  @protected
  void sse_encode_automation_rate(
      AutomationRate self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_biquad_filter_options(
      BiquadFilterOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self.q, serializer);
    sse_encode_f_32(self.detune, serializer);
    sse_encode_f_32(self.frequency, serializer);
    sse_encode_f_32(self.gain, serializer);
    sse_encode_biquad_filter_type(self.type, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_biquad_filter_type(
      BiquadFilterType self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_bool(bool self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putUint8(self ? 1 : 0);
  }

  @protected
  void
      sse_encode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
        self, serializer);
  }

  @protected
  void
      sse_encode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          PeriodicWave self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
        self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_audio_buffer_options(
      AudioBufferOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_buffer_options(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_audio_context_options(
      AudioContextOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_context_options(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_audio_node_implementor(
      AudioNodeImplementor self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_node_implementor(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_audio_param_descriptor(
      AudioParamDescriptor self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_param_descriptor(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_audio_render_capacity_options(
      AudioRenderCapacityOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_audio_render_capacity_options(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
      Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
          self,
      SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_proxy_enum(
        self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
      Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
          self,
      SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_auto_ref_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_media_stream_proxy_enum(
        self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_f_32(double self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self, serializer);
  }

  @protected
  void sse_encode_box_autoadd_periodic_wave_options(
      PeriodicWaveOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_periodic_wave_options(self, serializer);
  }

  @protected
  void sse_encode_channel_count_mode(
      ChannelCountMode self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_channel_interpretation(
      ChannelInterpretation self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_channel_merger_options(
      ChannelMergerOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_CastedPrimitive_usize(self.numberOfInputs, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_channel_splitter_options(
      ChannelSplitterOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_CastedPrimitive_usize(self.numberOfOutputs, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_constant_source_options(
      ConstantSourceOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self.offset, serializer);
  }

  @protected
  void sse_encode_convolver_options(
      ConvolverOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
        self.buffer, serializer);
    sse_encode_bool(self.disableNormalization, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_delay_options(DelayOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_64(self.maxDelayTime, serializer);
    sse_encode_f_64(self.delayTime, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_distance_model_type(
      DistanceModelType self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_dynamics_compressor_options(
      DynamicsCompressorOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self.attack, serializer);
    sse_encode_f_32(self.knee, serializer);
    sse_encode_f_32(self.ratio, serializer);
    sse_encode_f_32(self.release, serializer);
    sse_encode_f_32(self.threshold, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_f_32(double self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putFloat32(self);
  }

  @protected
  void sse_encode_f_64(double self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putFloat64(self);
  }

  @protected
  void sse_encode_gain_options(GainOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self.gain, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_i_32(int self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putInt32(self);
  }

  @protected
  void sse_encode_isize(PlatformInt64 self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putPlatformInt64(self);
  }

  @protected
  void
      sse_encode_list_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          List<MediaStreamTrack> self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    for (final item in self) {
      sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamTrack(
          item, serializer);
    }
  }

  @protected
  void sse_encode_list_audio_param_descriptor(
      List<AudioParamDescriptor> self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    for (final item in self) {
      sse_encode_audio_param_descriptor(item, serializer);
    }
  }

  @protected
  void sse_encode_list_list_prim_f_32_strict(
      List<Float32List> self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    for (final item in self) {
      sse_encode_list_prim_f_32_strict(item, serializer);
    }
  }

  @protected
  void sse_encode_list_prim_f_32_loose(
      List<double> self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    serializer.buffer.putFloat32List(
        self is Float32List ? self : Float32List.fromList(self));
  }

  @protected
  void sse_encode_list_prim_f_32_strict(
      Float32List self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    serializer.buffer.putFloat32List(self);
  }

  @protected
  void sse_encode_list_prim_f_64_loose(
      List<double> self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    serializer.buffer.putFloat64List(
        self is Float64List ? self : Float64List.fromList(self));
  }

  @protected
  void sse_encode_list_prim_f_64_strict(
      Float64List self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    serializer.buffer.putFloat64List(self);
  }

  @protected
  void sse_encode_list_prim_u_8_strict(
      Uint8List self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.length, serializer);
    serializer.buffer.putUint8List(self);
  }

  @protected
  void sse_encode_media_stream_track_state(
      MediaStreamTrackState self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void
      sse_encode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          AudioBuffer? self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    sse_encode_bool(self != null, serializer);
    if (self != null) {
      sse_encode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioBuffer(
          self, serializer);
    }
  }

  @protected
  void
      sse_encode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          PeriodicWave? self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    sse_encode_bool(self != null, serializer);
    if (self != null) {
      sse_encode_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
          self, serializer);
    }
  }

  @protected
  void sse_encode_opt_box_autoadd_f_32(double? self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    sse_encode_bool(self != null, serializer);
    if (self != null) {
      sse_encode_box_autoadd_f_32(self, serializer);
    }
  }

  @protected
  void sse_encode_opt_list_prim_f_32_strict(
      Float32List? self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs

    sse_encode_bool(self != null, serializer);
    if (self != null) {
      sse_encode_list_prim_f_32_strict(self, serializer);
    }
  }

  @protected
  void sse_encode_oscillator_options(
      OscillatorOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_oscillator_type(self.type, serializer);
    sse_encode_f_32(self.frequency, serializer);
    sse_encode_f_32(self.detune, serializer);
    sse_encode_opt_box_autoadd_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerPeriodicWave(
        self.periodicWave, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_oscillator_type(
      OscillatorType self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_over_sample_type(
      OverSampleType self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_panner_options(PannerOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_panning_model_type(self.panningModel, serializer);
    sse_encode_distance_model_type(self.distanceModel, serializer);
    sse_encode_f_32(self.positionX, serializer);
    sse_encode_f_32(self.positionY, serializer);
    sse_encode_f_32(self.positionZ, serializer);
    sse_encode_f_32(self.orientationX, serializer);
    sse_encode_f_32(self.orientationY, serializer);
    sse_encode_f_32(self.orientationZ, serializer);
    sse_encode_f_64(self.refDistance, serializer);
    sse_encode_f_64(self.maxDistance, serializer);
    sse_encode_f_64(self.rolloffFactor, serializer);
    sse_encode_f_64(self.coneInnerAngle, serializer);
    sse_encode_f_64(self.coneOuterAngle, serializer);
    sse_encode_f_64(self.coneOuterGain, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_panning_model_type(
      PanningModelType self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_i_32(self.index, serializer);
  }

  @protected
  void sse_encode_periodic_wave_options(
      PeriodicWaveOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_opt_list_prim_f_32_strict(self.real, serializer);
    sse_encode_opt_list_prim_f_32_strict(self.imag, serializer);
    sse_encode_bool(self.disableNormalization, serializer);
  }

  @protected
  void
      sse_encode_record_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_auto_owned_rust_opaque_flutter_rust_bridgefor_generated_rust_auto_opaque_inner_audio_param_id(
          (AudioParam, AudioParamId) self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParam(
        self.$1, serializer);
    sse_encode_Auto_Owned_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamId(
        self.$2, serializer);
  }

  @protected
  void sse_encode_stereo_panner_options(
      StereoPannerOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_f_32(self.pan, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }

  @protected
  void sse_encode_u_8(int self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putUint8(self);
  }

  @protected
  void sse_encode_unit(void self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
  }

  @protected
  void sse_encode_usize(BigInt self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    serializer.buffer.putBigUint64(self);
  }

  @protected
  void sse_encode_wave_shaper_options(
      WaveShaperOptions self, SseSerializer serializer) {
    // Codec=Sse (Serialization based), see doc to use other codecs
    sse_encode_opt_list_prim_f_32_strict(self.curve, serializer);
    sse_encode_over_sample_type(self.oversample, serializer);
    sse_encode_audio_node_options(self.audioNodeOptions, serializer);
  }
}

@freezed
sealed class AudioNodeImplementor with _$AudioNodeImplementor {
  const AudioNodeImplementor._();

  const factory AudioNodeImplementor.variant0(
    AnalyserNode field0,
  ) = AudioNodeImplementor_Variant0;
  const factory AudioNodeImplementor.variant1(
    AudioBufferSourceNode field0,
  ) = AudioNodeImplementor_Variant1;
  const factory AudioNodeImplementor.variant2(
    AudioDestinationNode field0,
  ) = AudioNodeImplementor_Variant2;
  const factory AudioNodeImplementor.variant3(
    AudioParam field0,
  ) = AudioNodeImplementor_Variant3;
  const factory AudioNodeImplementor.variant4(
    AudioWorkletNode field0,
  ) = AudioNodeImplementor_Variant4;
  const factory AudioNodeImplementor.variant5(
    BiquadFilterNode field0,
  ) = AudioNodeImplementor_Variant5;
  const factory AudioNodeImplementor.variant6(
    ChannelMergerNode field0,
  ) = AudioNodeImplementor_Variant6;
  const factory AudioNodeImplementor.variant7(
    ChannelSplitterNode field0,
  ) = AudioNodeImplementor_Variant7;
  const factory AudioNodeImplementor.variant8(
    ConstantSourceNode field0,
  ) = AudioNodeImplementor_Variant8;
  const factory AudioNodeImplementor.variant9(
    ConvolverNode field0,
  ) = AudioNodeImplementor_Variant9;
  const factory AudioNodeImplementor.variant10(
    DelayNode field0,
  ) = AudioNodeImplementor_Variant10;
  const factory AudioNodeImplementor.variant11(
    DynamicsCompressorNode field0,
  ) = AudioNodeImplementor_Variant11;
  const factory AudioNodeImplementor.variant12(
    GainNode field0,
  ) = AudioNodeImplementor_Variant12;
  const factory AudioNodeImplementor.variant13(
    IirFilterNode field0,
  ) = AudioNodeImplementor_Variant13;
  const factory AudioNodeImplementor.variant14(
    MediaElementAudioSourceNode field0,
  ) = AudioNodeImplementor_Variant14;
  const factory AudioNodeImplementor.variant15(
    MediaStreamAudioDestinationNode field0,
  ) = AudioNodeImplementor_Variant15;
  const factory AudioNodeImplementor.variant16(
    MediaStreamAudioSourceNode field0,
  ) = AudioNodeImplementor_Variant16;
  const factory AudioNodeImplementor.variant17(
    MediaStreamTrackAudioSourceNode field0,
  ) = AudioNodeImplementor_Variant17;
  const factory AudioNodeImplementor.variant18(
    OscillatorNode field0,
  ) = AudioNodeImplementor_Variant18;
  const factory AudioNodeImplementor.variant19(
    PannerNode field0,
  ) = AudioNodeImplementor_Variant19;
  const factory AudioNodeImplementor.variant20(
    ScriptProcessorNode field0,
  ) = AudioNodeImplementor_Variant20;
  const factory AudioNodeImplementor.variant21(
    StereoPannerNode field0,
  ) = AudioNodeImplementor_Variant21;
  const factory AudioNodeImplementor.variant22(
    WaveShaperNode field0,
  ) = AudioNodeImplementor_Variant22;
}

@freezed
sealed class Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum
    with
        _$Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum {
  const Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum._();

  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant0(
    AudioBufferSourceNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant0;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant1(
    AudioBufferSourceNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant1;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant2(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant2;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant3(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant3;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant4(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant4;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant5(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant5;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant6(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant6;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant7(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant7;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant8(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant8;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant9(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant9;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant10(
    AudioListener field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant10;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant11(
    BiquadFilterNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant11;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant12(
    BiquadFilterNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant12;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant13(
    BiquadFilterNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant13;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant14(
    BiquadFilterNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant14;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant15(
    ConstantSourceNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant15;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant16(
    DelayNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant16;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant17(
    DynamicsCompressorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant17;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant18(
    DynamicsCompressorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant18;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant19(
    DynamicsCompressorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant19;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant20(
    DynamicsCompressorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant20;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant21(
    DynamicsCompressorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant21;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant22(
    GainNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant22;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant23(
    OscillatorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant23;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant24(
    OscillatorNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant24;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant25(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant25;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant26(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant26;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant27(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant27;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant28(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant28;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant29(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant29;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant30(
    PannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant30;
  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant31(
    StereoPannerNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant31;
}

@freezed
sealed class Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum
    with
        _$Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum {
  const Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum._();

  const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum.variant0(
    MediaStreamAudioDestinationNode field0,
  ) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum_Variant0;
}

@sealed
class AnalyserNodeImpl extends RustOpaque implements AnalyserNode {
  // Not to be used by end users
  AnalyserNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AnalyserNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AnalyserNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeDisconnectOutput(that: this, output: output);

  /// The size of the FFT used for frequency-domain analysis (in sample-frames)
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<int> fftSize() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeFftSize(
        that: this,
      );

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeFrbOverrideConnect(that: this, dest: dest);

  Future<Uint8List> getByteTimeDomainData({required int len}) =>
      RustLib.instance.api
          .webAudioApiNodeAnalyserNodeFrbOverrideGetByteTimeDomainData(
              that: this, len: len);

  Future<Float32List> getFloatTimeDomainData({required int len}) =>
      RustLib.instance.api
          .webAudioApiNodeAnalyserNodeFrbOverrideGetFloatTimeDomainData(
              that: this, len: len);

  /// Number of bins in the FFT results, is half the FFT size
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<int> frequencyBinCount() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeFrequencyBinCount(
        that: this,
      );

  /// Maximum power value in the scaling range for the FFT analysis data for
  /// conversion to unsigned byte values. The default value is -30.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> maxDecibels() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeMaxDecibels(
        that: this,
      );

  /// Minimum power value in the scaling range for the FFT analysis data for
  /// conversion to unsigned byte values. The default value is -100.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> minDecibels() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeMinDecibels(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeRegistration(
        that: this,
      );

  /// Set FFT size
  ///
  /// # Panics
  ///
  /// This function panics if fft_size is not a power of two or not in the range [32, 32768]
  Future<void> setFftSize({required int fftSize}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetFftSize(that: this, fftSize: fftSize);

  /// Set max decibels
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value less than or equal
  /// to min decibels.
  Future<void> setMaxDecibels({required double value}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetMaxDecibels(that: this, value: value);

  /// Set min decibels
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value more than or equal
  /// to max decibels.
  Future<void> setMinDecibels({required double value}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetMinDecibels(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeSetOnProcessorError(
          that: this, callback: callback);

  /// Set smoothing time constant
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value less than 0 or more than 1.
  Future<void> setSmoothingTimeConstant({required double value}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeSetSmoothingTimeConstant(
          that: this, value: value);

  /// Time averaging parameter with the last analysis frame.
  /// A value from 0 -> 1 where 0 represents no time averaging with the last
  /// analysis frame. The default value is 0.8.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> smoothingTimeConstant() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeSmoothingTimeConstant(
        that: this,
      );
}

@sealed
class AudioBufferImpl extends RustOpaque implements AudioBuffer {
  // Not to be used by end users
  AudioBufferImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioBufferImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioBuffer,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioBuffer,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioBufferPtr,
  );

  /// Duration in seconds of the `AudioBuffer`
  Future<double> duration() =>
      RustLib.instance.api.webAudioApiAudioBufferDuration(
        that: this,
      );

  /// Return a read-only copy of the underlying data of the channel
  ///
  /// # Panics
  ///
  /// This function will panic if:
  /// - the given channel number is greater than or equal to the given number of channels.
  Future<void> getChannelData({required int channelNumber}) =>
      RustLib.instance.api.webAudioApiAudioBufferGetChannelData(
          that: this, channelNumber: channelNumber);

  /// Return a mutable slice of the underlying data of the channel
  ///
  /// # Panics
  ///
  /// This function will panic if:
  /// - the given channel number is greater than or equal to the given number of channels.
  Future<void> getChannelDataMut({required int channelNumber}) =>
      RustLib.instance.api.webAudioApiAudioBufferGetChannelDataMut(
          that: this, channelNumber: channelNumber);

  /// Number of samples per channel in this `AudioBuffer`
  Future<int> length() => RustLib.instance.api.webAudioApiAudioBufferLength(
        that: this,
      );

  /// Number of channels in this `AudioBuffer`
  Future<int> numberOfChannels() =>
      RustLib.instance.api.webAudioApiAudioBufferNumberOfChannels(
        that: this,
      );

  /// Sample rate of this `AudioBuffer` in Hertz
  Future<double> sampleRate() =>
      RustLib.instance.api.webAudioApiAudioBufferSampleRate(
        that: this,
      );
}

@sealed
class AudioBufferSourceNodeImpl extends RustOpaque
    implements AudioBufferSourceNode {
  // Not to be used by end users
  AudioBufferSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioBufferSourceNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioBufferSourceNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when the source node has stopped playing
  Future<void> clearOnended() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeClearOnended(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeClearOnprocessorerror(
        that: this,
      );

  /// K-rate [`AudioParam`] that defines a pitch transposition of the file,
  /// expressed in cents
  ///
  /// see <https://en.wikipedia.org/wiki/Cent_(music)>
  AudioParam get detune =>
      AudioParamProxyVariantAudioBufferSourceNodeDetune(this);

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<void> setBuffer({required AudioBuffer audioBuffer}) => RustLib
      .instance.api
      .webAudioApiNodeAudioBufferSourceNodeFrbOverrideSetBuffer(
          that: this, audioBuffer: audioBuffer);

  /// Defines if the playback the [`AudioBuffer`] should be looped
  Future<bool> loop() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoop(
        that: this,
      );

  /// Defines the loop end point, in the time reference of the [`AudioBuffer`]
  Future<double> loopEnd() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopEnd(
        that: this,
      );

  /// Defines the loop start point, in the time reference of the [`AudioBuffer`]
  Future<double> loopStart() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopStart(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeNumberOfOutputs(
        that: this,
      );

  /// K-rate [`AudioParam`] that defines the speed at which the [`AudioBuffer`]
  /// will be played, e.g.:
  /// - `0.5` will play the file at half speed
  /// - `-1` will play the file in reverse
  ///
  /// Note that playback rate will also alter the pitch of the [`AudioBuffer`]
  AudioParam get playbackRate =>
      AudioParamProxyVariantAudioBufferSourceNodePlaybackRate(this);

  /// Current playhead position in seconds within the [`AudioBuffer`].
  ///
  /// This value is updated at the end of each render quantum.
  ///
  /// Unofficial v2 API extension, not part of the spec yet.
  /// See also: <https://github.com/WebAudio/web-audio-api/issues/2397#issuecomment-709478405>
  Future<double> position() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodePosition(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeRegistration(
        that: this,
      );

  Future<void> setLoop({required bool value}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeSetLoop(that: this, value: value);

  Future<void> setLoopEnd({required double value}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeSetLoopEnd(that: this, value: value);

  Future<void> setLoopStart({required double value}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetLoopStart(
          that: this, value: value);

  Future<void> setOnEnded({required FutureOr<void> Function(Event) callback}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetOnEnded(
          that: this, callback: callback);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeSetOnProcessorError(
              that: this, callback: callback);

  Future<void> start() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStart(
        that: this,
      );

  Future<void> startAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeStartAt(that: this, when: when);

  /// Start the playback at the given time and with a given offset
  ///
  /// # Panics
  ///
  /// Panics if the source was already started
  Future<void> startAtWithOffset(
          {required double start, required double offset}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeStartAtWithOffset(
              that: this, start: start, offset: offset);

  /// Start the playback at the given time, with a given offset, for a given duration
  ///
  /// # Panics
  ///
  /// Panics if the source was already started
  Future<void> startAtWithOffsetAndDuration(
          {required double start,
          required double offset,
          required double duration}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDuration(
              that: this, start: start, offset: offset, duration: duration);

  Future<void> stop() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStop(
        that: this,
      );

  Future<void> stopAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeStopAt(that: this, when: when);
}

@sealed
class AudioContextImpl extends RustOpaque implements AudioContext {
  // Not to be used by end users
  AudioContextImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioContextImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioContext,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioContext,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioContextPtr,
  );

  /// This represents the number of seconds of processing latency incurred by
  /// the `AudioContext` passing the audio from the `AudioDestinationNode`
  /// to the audio subsystem.
  Future<double> baseLatency() =>
      RustLib.instance.api.webAudioApiContextAudioContextBaseLatency(
        that: this,
      );

  /// Unset the callback to run when the audio sink has changed
  Future<void> clearOnsinkchange() =>
      RustLib.instance.api.webAudioApiContextAudioContextClearOnsinkchange(
        that: this,
      );

  /// Unset the callback to run when the state of the AudioContext has changed
  Future<void> clearOnstatechange() =>
      RustLib.instance.api.webAudioApiContextAudioContextClearOnstatechange(
        that: this,
      );

  /// Closes the `AudioContext`, releasing the system resources being used.
  ///
  /// This will not automatically release all `AudioContext`-created objects, but will suspend
  /// the progression of the currentTime, and stop processing audio data.
  ///
  /// # Panics
  ///
  /// Will panic when this function is called multiple times
  Future<void> close() =>
      RustLib.instance.api.webAudioApiContextAudioContextClose(
        that: this,
      );

  /// Closes the `AudioContext`, releasing the system resources being used.
  ///
  /// This will not automatically release all `AudioContext`-created objects, but will suspend
  /// the progression of the currentTime, and stop processing audio data.
  ///
  /// This function operates synchronously and blocks the current thread until the audio thread
  /// has stopped processing.
  ///
  /// # Panics
  ///
  /// Will panic when this function is called multiple times
  Future<void> closeSync() =>
      RustLib.instance.api.webAudioApiContextAudioContextCloseSync(
        that: this,
      );

  /// Creates a `AnalyserNode`
  Future<AnalyserNode> createAnalyser() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateAnalyser(
        that: this,
      );

  /// Create an `AudioParam`.
  ///
  /// Call this inside the `register` closure when setting up your `AudioNode`
  Future<(AudioParam, AudioParamId)> createAudioParam(
          {required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateAudioParam(
          that: this, opts: opts, dest: dest);

  /// Creates an `BiquadFilterNode` which implements a second order filter
  Future<BiquadFilterNode> createBiquadFilter() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateBiquadFilter(
        that: this,
      );

  /// Create an new "in-memory" `AudioBuffer` with the given number of channels,
  /// length (i.e. number of samples per channel) and sample rate.
  ///
  /// Note: In most cases you will want the sample rate to match the current
  /// audio context sample rate.
  Future<AudioBuffer> createBuffer(
          {required int numberOfChannels,
          required int length,
          required double sampleRate}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateBuffer(
          that: this,
          numberOfChannels: numberOfChannels,
          length: length,
          sampleRate: sampleRate);

  /// Creates an `AudioBufferSourceNode`
  Future<AudioBufferSourceNode> createBufferSource() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateBufferSource(
        that: this,
      );

  /// Creates a `ChannelMergerNode`
  Future<ChannelMergerNode> createChannelMerger(
          {required int numberOfInputs}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateChannelMerger(
          that: this, numberOfInputs: numberOfInputs);

  /// Creates a `ChannelSplitterNode`
  Future<ChannelSplitterNode> createChannelSplitter(
          {required int numberOfOutputs}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateChannelSplitter(
          that: this, numberOfOutputs: numberOfOutputs);

  /// Creates an `ConstantSourceNode`, a source representing a constant value
  Future<ConstantSourceNode> createConstantSource() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateConstantSource(
        that: this,
      );

  /// Creates an `ConvolverNode`, a processing node which applies linear convolution
  Future<ConvolverNode> createConvolver() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateConvolver(
        that: this,
      );

  /// Creates a `DelayNode`, delaying the audio signal
  Future<DelayNode> createDelay({required double maxDelayTime}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateDelay(
          that: this, maxDelayTime: maxDelayTime);

  /// Creates a `DynamicsCompressorNode`, compressing the audio signal
  Future<DynamicsCompressorNode> createDynamicsCompressor() =>
      RustLib.instance.api
          .webAudioApiContextAudioContextCreateDynamicsCompressor(
        that: this,
      );

  /// Creates an `GainNode`, to control audio volume
  Future<GainNode> createGain() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateGain(
        that: this,
      );

  /// Creates an `IirFilterNode`
  ///
  /// # Arguments
  ///
  /// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  /// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  Future<IirFilterNode> createIirFilter(
          {required List<double> feedforward,
          required List<double> feedback}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateIirFilter(
          that: this, feedforward: feedforward, feedback: feedback);

  /// Creates a [`MediaStreamAudioDestinationNode`](node::MediaStreamAudioDestinationNode)
  Future<MediaStreamAudioDestinationNode> createMediaStreamDestination() =>
      RustLib.instance.api
          .webAudioApiContextAudioContextCreateMediaStreamDestination(
        that: this,
      );

  /// Creates a [`MediaStreamAudioSourceNode`](node::MediaStreamAudioSourceNode) from a
  /// [`MediaStream`]
  Future<MediaStreamAudioSourceNode> createMediaStreamSource(
          {required MediaStream media}) =>
      RustLib.instance.api
          .webAudioApiContextAudioContextCreateMediaStreamSource(
              that: this, media: media);

  /// Creates a [`MediaStreamTrackAudioSourceNode`](node::MediaStreamTrackAudioSourceNode) from a
  /// [`MediaStreamTrack`]
  Future<MediaStreamTrackAudioSourceNode> createMediaStreamTrackSource(
          {required MediaStreamTrack media}) =>
      RustLib.instance.api
          .webAudioApiContextAudioContextCreateMediaStreamTrackSource(
              that: this, media: media);

  /// Creates an `OscillatorNode`, a source representing a periodic waveform.
  Future<OscillatorNode> createOscillator() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateOscillator(
        that: this,
      );

  /// Creates a `PannerNode`
  Future<PannerNode> createPanner() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreatePanner(
        that: this,
      );

  /// Creates a periodic wave
  ///
  /// Please note that this constructor deviates slightly from the spec by requiring a single
  /// argument with the periodic wave options.
  Future<PeriodicWave> createPeriodicWave(
          {required PeriodicWaveOptions options}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreatePeriodicWave(
          that: this, options: options);

  /// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);
  ///
  /// # Panics
  ///
  /// This function panics if:
  /// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384
  /// - the number of input and output channels are both zero
  /// - either of the channel counts exceed [`crate::MAX_CHANNELS`]
  Future<ScriptProcessorNode> createScriptProcessor(
          {required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateScriptProcessor(
          that: this,
          bufferSize: bufferSize,
          numberOfInputChannels: numberOfInputChannels,
          numberOfOutputChannels: numberOfOutputChannels);

  /// Creates an `StereoPannerNode` to pan a stereo output
  Future<StereoPannerNode> createStereoPanner() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateStereoPanner(
        that: this,
      );

  /// Creates a `WaveShaperNode`
  Future<WaveShaperNode> createWaveShaper() =>
      RustLib.instance.api.webAudioApiContextAudioContextCreateWaveShaper(
        that: this,
      );

  /// This is the time in seconds of the sample frame immediately following the last sample-frame
  /// in the block of audio most recently processed by the context’s rendering graph.
  Future<double> currentTime() =>
      RustLib.instance.api.webAudioApiContextAudioContextCurrentTime(
        that: this,
      );

  /// Returns an `AudioDestinationNode` representing the final destination of all audio in the
  /// context. It can be thought of as the audio-rendering device.
  Future<AudioDestinationNode> destination() =>
      RustLib.instance.api.webAudioApiContextAudioContextDestination(
        that: this,
      );

  Future<MediaElementAudioSourceNode> createMediaElementSource(
          {required MediaElement mediaElement}) =>
      RustLib.instance.api
          .webAudioApiContextAudioContextFrbOverrideCreateMediaElementSource(
              that: this, mediaElement: mediaElement);

  Future<AudioBuffer> decodeAudioDataSync({required String inputPath}) =>
      RustLib.instance.api
          .webAudioApiContextAudioContextFrbOverrideDecodeAudioDataSync(
              that: this, inputPath: inputPath);

  /// Returns the `AudioListener` which is used for 3D spatialization
  Future<AudioListener> listener() =>
      RustLib.instance.api.webAudioApiContextAudioContextListener(
        that: this,
      );

  /// The estimation in seconds of audio output latency, i.e., the interval
  /// between the time the UA requests the host system to play a buffer and
  /// the time at which the first sample in the buffer is actually processed
  /// by the audio output device.
  Future<double> outputLatency() =>
      RustLib.instance.api.webAudioApiContextAudioContextOutputLatency(
        that: this,
      );

  /// Returns an [`AudioRenderCapacity`] instance associated with an AudioContext.
  Future<void> renderCapacity() =>
      RustLib.instance.api.webAudioApiContextAudioContextRenderCapacity(
        that: this,
      );

  /// Resumes the progression of time in an audio context that has previously been
  /// suspended/paused.
  ///
  /// This function operates synchronously and blocks the current thread until the audio thread
  /// has started processing again.
  ///
  /// # Panics
  ///
  /// Will panic if:
  ///
  /// * The audio device is not available
  /// * For a `BackendSpecificError`
  Future<void> resumeSync() =>
      RustLib.instance.api.webAudioApiContextAudioContextResumeSync(
        that: this,
      );

  /// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.
  Future<double> sampleRate() =>
      RustLib.instance.api.webAudioApiContextAudioContextSampleRate(
        that: this,
      );

  Future<void> setOnStateChange(
          {required FutureOr<void> Function(Event) callback}) =>
      RustLib.instance.api.webAudioApiContextAudioContextSetOnStateChange(
          that: this, callback: callback);

  Future<void> setSinkId({required String sinkId}) => RustLib.instance.api
      .webAudioApiContextAudioContextSetSinkId(that: this, sinkId: sinkId);

  /// Identifier or the information of the current audio output device.
  ///
  /// The initial value is `""`, which means the default audio output device.
  Future<String> sinkId() =>
      RustLib.instance.api.webAudioApiContextAudioContextSinkId(
        that: this,
      );

  /// Returns state of current context
  Future<AudioContextState> state() =>
      RustLib.instance.api.webAudioApiContextAudioContextState(
        that: this,
      );

  /// Suspends the progression of time in the audio context.
  ///
  /// This will temporarily halt audio hardware access and reducing CPU/battery usage in the
  /// process.
  ///
  /// # Panics
  ///
  /// Will panic if:
  ///
  /// * The audio device is not available
  /// * For a `BackendSpecificError`
  Future<void> suspend() =>
      RustLib.instance.api.webAudioApiContextAudioContextSuspend(
        that: this,
      );

  /// Suspends the progression of time in the audio context.
  ///
  /// This will temporarily halt audio hardware access and reducing CPU/battery usage in the
  /// process.
  ///
  /// This function operates synchronously and blocks the current thread until the audio thread
  /// has stopped processing.
  ///
  /// # Panics
  ///
  /// Will panic if:
  ///
  /// * The audio device is not available
  /// * For a `BackendSpecificError`
  Future<void> suspendSync() =>
      RustLib.instance.api.webAudioApiContextAudioContextSuspendSync(
        that: this,
      );
}

@sealed
class AudioContextRegistrationImpl extends RustOpaque
    implements AudioContextRegistration {
  // Not to be used by end users
  AudioContextRegistrationImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioContextRegistrationImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioContextRegistration,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioContextRegistration,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_AudioContextRegistrationPtr,
  );
}

@sealed
class AudioDestinationNodeImpl extends RustOpaque
    implements AudioDestinationNode {
  // Not to be used by end users
  AudioDestinationNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioDestinationNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioDestinationNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioDestinationNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioDestinationNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeAudioDestinationNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeAudioDestinationNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeAudioDestinationNodeFrbOverrideConnect(
          that: this, dest: dest);

  /// The maximum number of channels that the channelCount attribute can be set to (the max
  /// number of channels that the hardware is capable of supporting).
  /// <https://www.w3.org/TR/webaudio/#dom-audiodestinationnode-maxchannelcount>
  Future<int> maxChannelCount() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeMaxChannelCount(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioDestinationNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class AudioListenerImpl extends RustOpaque implements AudioListener {
  // Not to be used by end users
  AudioListenerImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioListenerImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioListener,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioListener,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioListenerPtr,
  );

  AudioParam get forwardX => AudioParamProxyVariantAudioListenerForwardX(this);

  AudioParam get forwardY => AudioParamProxyVariantAudioListenerForwardY(this);

  AudioParam get forwardZ => AudioParamProxyVariantAudioListenerForwardZ(this);

  AudioParam get positionX =>
      AudioParamProxyVariantAudioListenerPositionX(this);

  AudioParam get positionY =>
      AudioParamProxyVariantAudioListenerPositionY(this);

  AudioParam get positionZ =>
      AudioParamProxyVariantAudioListenerPositionZ(this);

  AudioParam get upX => AudioParamProxyVariantAudioListenerUpX(this);

  AudioParam get upY => AudioParamProxyVariantAudioListenerUpY(this);

  AudioParam get upZ => AudioParamProxyVariantAudioListenerUpZ(this);
}

@sealed
class AudioParamIdImpl extends RustOpaque implements AudioParamId {
  // Not to be used by end users
  AudioParamIdImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioParamIdImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioParamId,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamId,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamIdPtr,
  );
}

@sealed
class AudioParamImpl extends RustOpaque implements AudioParam {
  // Not to be used by end users
  AudioParamImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioParamImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioParam,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioParam,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamPtr,
  );

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

@sealed
class AudioProcessingEventImpl extends RustOpaque
    implements AudioProcessingEvent {
  // Not to be used by end users
  AudioProcessingEventImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioProcessingEventImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioProcessingEvent,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioProcessingEvent,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioProcessingEventPtr,
  );

  AudioBuffer get inputBuffer => RustLib.instance.api
          .webAudioApiAudioProcessingEventAutoAccessorGetInputBuffer(
        that: this,
      );

  AudioBuffer get outputBuffer => RustLib.instance.api
          .webAudioApiAudioProcessingEventAutoAccessorGetOutputBuffer(
        that: this,
      );

  double get playbackTime => RustLib.instance.api
          .webAudioApiAudioProcessingEventAutoAccessorGetPlaybackTime(
        that: this,
      );

  set inputBuffer(AudioBuffer inputBuffer) => RustLib.instance.api
      .webAudioApiAudioProcessingEventAutoAccessorSetInputBuffer(
          that: this, inputBuffer: inputBuffer);

  set outputBuffer(AudioBuffer outputBuffer) => RustLib.instance.api
      .webAudioApiAudioProcessingEventAutoAccessorSetOutputBuffer(
          that: this, outputBuffer: outputBuffer);

  set playbackTime(double playbackTime) => RustLib.instance.api
      .webAudioApiAudioProcessingEventAutoAccessorSetPlaybackTime(
          that: this, playbackTime: playbackTime);
}

@sealed
class AudioRenderCapacityEventImpl extends RustOpaque
    implements AudioRenderCapacityEvent {
  // Not to be used by end users
  AudioRenderCapacityEventImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioRenderCapacityEventImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioRenderCapacityEvent,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioRenderCapacityEvent,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_AudioRenderCapacityEventPtr,
  );

  double get averageLoad => RustLib.instance.api
          .webAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoad(
        that: this,
      );

  Event get event => RustLib.instance.api
          .webAudioApiAudioRenderCapacityEventAutoAccessorGetEvent(
        that: this,
      );

  double get peakLoad => RustLib.instance.api
          .webAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoad(
        that: this,
      );

  double get timestamp => RustLib.instance.api
          .webAudioApiAudioRenderCapacityEventAutoAccessorGetTimestamp(
        that: this,
      );

  double get underrunRatio => RustLib.instance.api
          .webAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatio(
        that: this,
      );

  set averageLoad(double averageLoad) => RustLib.instance.api
      .webAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoad(
          that: this, averageLoad: averageLoad);

  set event(Event event) => RustLib.instance.api
      .webAudioApiAudioRenderCapacityEventAutoAccessorSetEvent(
          that: this, event: event);

  set peakLoad(double peakLoad) => RustLib.instance.api
      .webAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoad(
          that: this, peakLoad: peakLoad);

  set timestamp(double timestamp) => RustLib.instance.api
      .webAudioApiAudioRenderCapacityEventAutoAccessorSetTimestamp(
          that: this, timestamp: timestamp);

  set underrunRatio(double underrunRatio) => RustLib.instance.api
      .webAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatio(
          that: this, underrunRatio: underrunRatio);
}

@sealed
class AudioRenderCapacityImpl extends RustOpaque
    implements AudioRenderCapacity {
  // Not to be used by end users
  AudioRenderCapacityImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioRenderCapacityImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioRenderCapacity,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioRenderCapacity,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioRenderCapacityPtr,
  );

  /// Unset the EventHandler for [`AudioRenderCapacityEvent`].
  Future<void> clearOnupdate() =>
      RustLib.instance.api.webAudioApiAudioRenderCapacityClearOnupdate(
        that: this,
      );

  /// Start metric collection and analysis
  Future<void> start({required AudioRenderCapacityOptions options}) =>
      RustLib.instance.api
          .webAudioApiAudioRenderCapacityStart(that: this, options: options);

  /// Stop metric collection and analysis
  Future<void> stop() =>
      RustLib.instance.api.webAudioApiAudioRenderCapacityStop(
        that: this,
      );
}

@sealed
class AudioWorkletNodeImpl extends RustOpaque implements AudioWorkletNode {
  // Not to be used by end users
  AudioWorkletNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioWorkletNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AudioWorkletNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AudioWorkletNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioWorkletNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiWorkletAudioWorkletNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiWorkletAudioWorkletNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeDisconnectOutput(
          that: this, output: output);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeNumberOfOutputs(
        that: this,
      );

  /// Collection of AudioParam objects with associated names of this node
  ///
  /// This map is populated from a list of [`AudioParamDescriptor`]s in the
  /// [`AudioWorkletProcessor`] class constructor at the instantiation.
  Future<void> parameters() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeParameters(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeRegistration(
        that: this,
      );
}

@sealed
class BiquadFilterNodeImpl extends RustOpaque implements BiquadFilterNode {
  // Not to be used by end users
  BiquadFilterNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  BiquadFilterNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_BiquadFilterNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_BiquadFilterNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_BiquadFilterNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeClearOnprocessorerror(
        that: this,
      );

  /// Returns the detune audio parameter
  AudioParam get detune => AudioParamProxyVariantBiquadFilterNodeDetune(this);

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeFrbOverrideConnect(
          that: this, dest: dest);

  /// Returns the frequency audio parameter
  AudioParam get frequency =>
      AudioParamProxyVariantBiquadFilterNodeFrequency(this);

  /// Returns the gain audio parameter
  AudioParam get gain => AudioParamProxyVariantBiquadFilterNodeGain(this);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeNumberOfOutputs(
        that: this,
      );

  /// Returns the Q audio parameter
  AudioParam get q => AudioParamProxyVariantBiquadFilterNodeQ(this);

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetOnProcessorError(
          that: this, callback: callback);

  /// biquad filter type setter
  ///
  /// # Arguments
  ///
  /// * `type_` - the biquad filter type (lowpass, highpass,...)
  Future<void> setType({required BiquadFilterType type}) => RustLib.instance.api
      .webAudioApiNodeBiquadFilterNodeSetType(that: this, type: type);

  /// Returns the biquad filter type
  Future<BiquadFilterType> type() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeType(
        that: this,
      );
}

@sealed
class BlobEventImpl extends RustOpaque implements BlobEvent {
  // Not to be used by end users
  BlobEventImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  BlobEventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_BlobEvent,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_BlobEvent,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_BlobEventPtr,
  );

  Uint8List get blob =>
      RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorGetBlob(
        that: this,
      );

  Event get event => RustLib.instance.api
          .webAudioApiMediaRecorderBlobEventAutoAccessorGetEvent(
        that: this,
      );

  double get timecode => RustLib.instance.api
          .webAudioApiMediaRecorderBlobEventAutoAccessorGetTimecode(
        that: this,
      );

  set blob(Uint8List blob) =>
      RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorSetBlob(
          that: this, blob: blob);

  set event(Event event) => RustLib.instance.api
      .webAudioApiMediaRecorderBlobEventAutoAccessorSetEvent(
          that: this, event: event);

  set timecode(double timecode) => RustLib.instance.api
      .webAudioApiMediaRecorderBlobEventAutoAccessorSetTimecode(
          that: this, timecode: timecode);
}

@sealed
class ChannelConfigImpl extends RustOpaque implements ChannelConfig {
  // Not to be used by end users
  ChannelConfigImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ChannelConfigImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ChannelConfig,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ChannelConfig,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_ChannelConfigPtr,
  );
}

@sealed
class ChannelMergerNodeImpl extends RustOpaque implements ChannelMergerNode {
  // Not to be used by end users
  ChannelMergerNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ChannelMergerNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ChannelMergerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ChannelMergerNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelMergerNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeChannelMergerNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeChannelMergerNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class ChannelSplitterNodeImpl extends RustOpaque
    implements ChannelSplitterNode {
  // Not to be used by end users
  ChannelSplitterNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ChannelSplitterNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_ChannelSplitterNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelSplitterNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelSplitterNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeChannelSplitterNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeChannelSplitterNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeChannelSplitterNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class ConcreteBaseAudioContextImpl extends RustOpaque
    implements ConcreteBaseAudioContext {
  // Not to be used by end users
  ConcreteBaseAudioContextImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ConcreteBaseAudioContextImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_ConcreteBaseAudioContext,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_ConcreteBaseAudioContext,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_ConcreteBaseAudioContextPtr,
  );

  /// Unset the callback to run when the state of the AudioContext has changed
  Future<void> clearOnstatechange() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextClearOnstatechange(
        that: this,
      );

  /// Creates a `AnalyserNode`
  Future<AnalyserNode> createAnalyser() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateAnalyser(
        that: this,
      );

  /// Create an `AudioParam`.
  ///
  /// Call this inside the `register` closure when setting up your `AudioNode`
  Future<(AudioParam, AudioParamId)> createAudioParam(
          {required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateAudioParam(
              that: this, opts: opts, dest: dest);

  /// Creates an `BiquadFilterNode` which implements a second order filter
  Future<BiquadFilterNode> createBiquadFilter() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateBiquadFilter(
        that: this,
      );

  /// Create an new "in-memory" `AudioBuffer` with the given number of channels,
  /// length (i.e. number of samples per channel) and sample rate.
  ///
  /// Note: In most cases you will want the sample rate to match the current
  /// audio context sample rate.
  Future<AudioBuffer> createBuffer(
          {required int numberOfChannels,
          required int length,
          required double sampleRate}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateBuffer(
              that: this,
              numberOfChannels: numberOfChannels,
              length: length,
              sampleRate: sampleRate);

  /// Creates an `AudioBufferSourceNode`
  Future<AudioBufferSourceNode> createBufferSource() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateBufferSource(
        that: this,
      );

  /// Creates a `ChannelMergerNode`
  Future<ChannelMergerNode> createChannelMerger(
          {required int numberOfInputs}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateChannelMerger(
              that: this, numberOfInputs: numberOfInputs);

  /// Creates a `ChannelSplitterNode`
  Future<ChannelSplitterNode> createChannelSplitter(
          {required int numberOfOutputs}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateChannelSplitter(
              that: this, numberOfOutputs: numberOfOutputs);

  /// Creates an `ConstantSourceNode`, a source representing a constant value
  Future<ConstantSourceNode> createConstantSource() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateConstantSource(
        that: this,
      );

  /// Creates an `ConvolverNode`, a processing node which applies linear convolution
  Future<ConvolverNode> createConvolver() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateConvolver(
        that: this,
      );

  /// Creates a `DelayNode`, delaying the audio signal
  Future<DelayNode> createDelay({required double maxDelayTime}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateDelay(
              that: this, maxDelayTime: maxDelayTime);

  /// Creates a `DynamicsCompressorNode`, compressing the audio signal
  Future<DynamicsCompressorNode> createDynamicsCompressor() =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressor(
        that: this,
      );

  /// Creates an `GainNode`, to control audio volume
  Future<GainNode> createGain() =>
      RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateGain(
        that: this,
      );

  /// Creates an `IirFilterNode`
  ///
  /// # Arguments
  ///
  /// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  /// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  Future<IirFilterNode> createIirFilter(
          {required List<double> feedforward,
          required List<double> feedback}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateIirFilter(
              that: this, feedforward: feedforward, feedback: feedback);

  /// Creates an `OscillatorNode`, a source representing a periodic waveform.
  Future<OscillatorNode> createOscillator() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateOscillator(
        that: this,
      );

  /// Creates a `PannerNode`
  Future<PannerNode> createPanner() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreatePanner(
        that: this,
      );

  /// Creates a periodic wave
  ///
  /// Please note that this constructor deviates slightly from the spec by requiring a single
  /// argument with the periodic wave options.
  Future<PeriodicWave> createPeriodicWave(
          {required PeriodicWaveOptions options}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreatePeriodicWave(
              that: this, options: options);

  /// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);
  ///
  /// # Panics
  ///
  /// This function panics if:
  /// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384
  /// - the number of input and output channels are both zero
  /// - either of the channel counts exceed [`crate::MAX_CHANNELS`]
  Future<ScriptProcessorNode> createScriptProcessor(
          {required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateScriptProcessor(
              that: this,
              bufferSize: bufferSize,
              numberOfInputChannels: numberOfInputChannels,
              numberOfOutputChannels: numberOfOutputChannels);

  /// Creates an `StereoPannerNode` to pan a stereo output
  Future<StereoPannerNode> createStereoPanner() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateStereoPanner(
        that: this,
      );

  /// Creates a `WaveShaperNode`
  Future<WaveShaperNode> createWaveShaper() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCreateWaveShaper(
        that: this,
      );

  /// This is the time in seconds of the sample frame immediately following the last sample-frame
  /// in the block of audio most recently processed by the context’s rendering graph.
  Future<double> currentTime() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextCurrentTime(
        that: this,
      );

  /// Returns an `AudioDestinationNode` representing the final destination of all audio in the
  /// context. It can be thought of as the audio-rendering device.
  Future<AudioDestinationNode> destination() => RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextDestination(
        that: this,
      );

  /// Returns the `AudioListener` which is used for 3D spatialization
  Future<AudioListener> listener() =>
      RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextListener(
        that: this,
      );

  /// Inform render thread that this node can act as a cycle breaker
  Future<void> markCycleBreaker({required AudioContextRegistration reg}) =>
      RustLib.instance.api
          .webAudioApiContextConcreteBaseAudioContextMarkCycleBreaker(
              that: this, reg: reg);

  /// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.
  Future<double> sampleRate() =>
      RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextSampleRate(
        that: this,
      );

  /// Returns state of current context
  Future<AudioContextState> state() =>
      RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextState(
        that: this,
      );
}

@sealed
class ConstantSourceNodeImpl extends RustOpaque implements ConstantSourceNode {
  // Not to be used by end users
  ConstantSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ConstantSourceNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ConstantSourceNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConstantSourceNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ConstantSourceNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeConstantSourceNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when the source node has stopped playing
  Future<void> clearOnended() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeClearOnended(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeConstantSourceNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeNumberOfOutputs(
        that: this,
      );

  AudioParam get offset => AudioParamProxyVariantConstantSourceNodeOffset(this);

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeRegistration(
        that: this,
      );

  Future<void> setOnEnded({required FutureOr<void> Function(Event) callback}) =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetOnEnded(
          that: this, callback: callback);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetOnProcessorError(
          that: this, callback: callback);

  Future<void> start() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeStart(
        that: this,
      );

  Future<void> startAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeConstantSourceNodeStartAt(that: this, when: when);

  Future<void> stop() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeStop(
        that: this,
      );

  Future<void> stopAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeConstantSourceNodeStopAt(that: this, when: when);
}

@sealed
class ConvolverNodeImpl extends RustOpaque implements ConvolverNode {
  // Not to be used by end users
  ConvolverNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ConvolverNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ConvolverNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeDisconnectOutput(that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeFrbOverrideConnect(that: this, dest: dest);

  /// Denotes if the response buffer will be scaled with an equal-power normalization
  Future<bool> normalize() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeNormalize(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeRegistration(
        that: this,
      );

  /// Set or update the impulse response buffer
  ///
  /// # Panics
  ///
  /// Panics when the sample rate of the provided AudioBuffer differs from the audio context
  /// sample rate.
  Future<void> setBuffer({required AudioBuffer buffer}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeSetBuffer(that: this, buffer: buffer);

  /// Update the `normalize` setting. This will only have an effect when `set_buffer` is called.
  Future<void> setNormalize({required bool value}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeSetNormalize(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class DelayNodeImpl extends RustOpaque implements DelayNode {
  // Not to be used by end users
  DelayNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  DelayNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_DelayNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_DelayNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_DelayNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeClearOnprocessorerror(
        that: this,
      );

  /// A-rate [`AudioParam`] representing the amount of delay (in seconds) to apply.
  AudioParam get delayTime => AudioParamProxyVariantDelayNodeDelayTime(this);

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeDelayNodeDisconnectOutput(that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeDelayNodeFrbOverrideConnect(that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeDelayNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class DummyStructImpl extends RustOpaque implements DummyStruct {
  // Not to be used by end users
  DummyStructImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  DummyStructImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_DummyStruct,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_DummyStruct,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_DummyStructPtr,
  );
}

@sealed
class DynamicsCompressorNodeImpl extends RustOpaque
    implements DynamicsCompressorNode {
  // Not to be used by end users
  DynamicsCompressorNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  DynamicsCompressorNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_DynamicsCompressorNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNodePtr,
  );

  AudioParam get attack =>
      AudioParamProxyVariantDynamicsCompressorNodeAttack(this);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() => RustLib.instance.api
          .webAudioApiNodeDynamicsCompressorNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeDynamicsCompressorNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeDynamicsCompressorNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeDynamicsCompressorNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeDynamicsCompressorNodeFrbOverrideConnect(
          that: this, dest: dest);

  AudioParam get knee => AudioParamProxyVariantDynamicsCompressorNodeKnee(this);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeNumberOfOutputs(
        that: this,
      );

  AudioParam get ratio =>
      AudioParamProxyVariantDynamicsCompressorNodeRatio(this);

  Future<double> reduction() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeReduction(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeRegistration(
        that: this,
      );

  AudioParam get release =>
      AudioParamProxyVariantDynamicsCompressorNodeRelease(this);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeDynamicsCompressorNodeSetOnProcessorError(
              that: this, callback: callback);

  AudioParam get threshold =>
      AudioParamProxyVariantDynamicsCompressorNodeThreshold(this);
}

@sealed
class EventImpl extends RustOpaque implements Event {
  // Not to be used by end users
  EventImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  EventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_Event,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_Event,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_EventPtr,
  );

  String get type => RustLib.instance.api.webAudioApiEventType(
        that: this,
      );
}

@sealed
class GainNodeImpl extends RustOpaque implements GainNode {
  // Not to be used by end users
  GainNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  GainNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_GainNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_GainNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_GainNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeGainNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeGainNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeGainNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeGainNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeGainNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeGainNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeGainNodeDisconnectOutput(that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeGainNodeFrbOverrideConnect(that: this, dest: dest);

  AudioParam get gain => AudioParamProxyVariantGainNodeGain(this);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeGainNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeGainNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeGainNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeGainNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class IirFilterNodeImpl extends RustOpaque implements IirFilterNode {
  // Not to be used by end users
  IirFilterNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  IirFilterNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_IirFilterNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeIirFilterNodeDisconnectOutput(that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeIirFilterNodeFrbOverrideConnect(that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class MediaElementAudioSourceNodeImpl extends RustOpaque
    implements MediaElementAudioSourceNode {
  // Not to be used by end users
  MediaElementAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaElementAudioSourceNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaElementAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceNodePtr,
  );

  Future<void> channelConfig() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeMediaElementAudioSourceNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class MediaElementImpl extends RustOpaque implements MediaElement {
  // Not to be used by end users
  MediaElementImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaElementImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_MediaElement,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaElement,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaElementPtr,
  );

  Future<double> currentTime() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementCurrentTime(
        that: this,
      );

  Future<bool> loop() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementLoop(
        that: this,
      );

  Future<void> pause() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementPause(
        that: this,
      );

  Future<bool> paused() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementPaused(
        that: this,
      );

  Future<void> play() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementPlay(
        that: this,
      );

  Future<double> playbackRate() =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementPlaybackRate(
        that: this,
      );

  Future<void> setCurrentTime({required double value}) =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementSetCurrentTime(
          that: this, value: value);

  Future<void> setLoop({required bool value}) => RustLib.instance.api
      .crateApiMediaElementMyMediaElementSetLoop(that: this, value: value);

  Future<void> setPlaybackRate({required double value}) =>
      RustLib.instance.api.crateApiMediaElementMyMediaElementSetPlaybackRate(
          that: this, value: value);
}

@sealed
class MediaRecorderImpl extends RustOpaque implements MediaRecorder {
  // Not to be used by end users
  MediaRecorderImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaRecorderImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_MediaRecorder,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaRecorder,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaRecorderPtr,
  );

  Future<void> clearOndataavailable() => RustLib.instance.api
          .webAudioApiMediaRecorderMediaRecorderClearOndataavailable(
        that: this,
      );

  Future<void> clearOnerror() =>
      RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderClearOnerror(
        that: this,
      );

  Future<void> clearOnstop() =>
      RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderClearOnstop(
        that: this,
      );

  /// Begin recording media
  ///
  /// # Panics
  ///
  /// Will panic when the recorder has already started
  Future<void> start() =>
      RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderStart(
        that: this,
      );

  Future<void> stop() =>
      RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderStop(
        that: this,
      );
}

@sealed
class MediaStreamAudioDestinationNodeImpl extends RustOpaque
    implements MediaStreamAudioDestinationNode {
  // Not to be used by end users
  MediaStreamAudioDestinationNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamAudioDestinationNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamAudioDestinationNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioDestinationNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioDestinationNodePtr,
  );

  Future<void> channelConfig() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorError(
              that: this, callback: callback);

  /// A [`MediaStream`] producing audio buffers with the same number of channels as the node
  /// itself
  Future<MediaStream> stream() => Future.value(
      MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream(this));
}

@sealed
class MediaStreamAudioSourceNodeImpl extends RustOpaque
    implements MediaStreamAudioSourceNode {
  // Not to be used by end users
  MediaStreamAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamAudioSourceNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceNodePtr,
  );

  Future<void> channelConfig() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class MediaStreamConstraintsImpl extends RustOpaque
    implements MediaStreamConstraints {
  // Not to be used by end users
  MediaStreamConstraintsImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamConstraintsImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_MediaStreamConstraints,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_MediaStreamConstraints,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_MediaStreamConstraintsPtr,
  );
}

@sealed
class MediaStreamImpl extends RustOpaque implements MediaStream {
  // Not to be used by end users
  MediaStreamImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_MediaStream,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaStream,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamPtr,
  );

  Future<List<MediaStreamTrack>> getTracks() => RustLib.instance.api
          .webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(
        that: this,
      );
}

@sealed
class MediaStreamTrackAudioSourceNodeImpl extends RustOpaque
    implements MediaStreamTrackAudioSourceNode {
  // Not to be used by end users
  MediaStreamTrackAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamTrackAudioSourceNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamTrackAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNodePtr,
  );

  Future<void> channelConfig() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class MediaStreamTrackImpl extends RustOpaque implements MediaStreamTrack {
  // Not to be used by end users
  MediaStreamTrackImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamTrackImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamTrack,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamTrack,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_MediaStreamTrackPtr,
  );

  Future<void> close() =>
      RustLib.instance.api.webAudioApiMediaStreamsMediaStreamTrackClose(
        that: this,
      );

  Future<MediaStreamTrackState> readyState() =>
      RustLib.instance.api.webAudioApiMediaStreamsMediaStreamTrackReadyState(
        that: this,
      );
}

@sealed
class OfflineAudioCompletionEventImpl extends RustOpaque
    implements OfflineAudioCompletionEvent {
  // Not to be used by end users
  OfflineAudioCompletionEventImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  OfflineAudioCompletionEventImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_OfflineAudioCompletionEvent,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_OfflineAudioCompletionEvent,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_OfflineAudioCompletionEventPtr,
  );

  Event get event => RustLib.instance.api
          .webAudioApiOfflineAudioCompletionEventAutoAccessorGetEvent(
        that: this,
      );

  AudioBuffer get renderedBuffer => RustLib.instance.api
          .webAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBuffer(
        that: this,
      );

  set event(Event event) => RustLib.instance.api
      .webAudioApiOfflineAudioCompletionEventAutoAccessorSetEvent(
          that: this, event: event);

  set renderedBuffer(AudioBuffer renderedBuffer) => RustLib.instance.api
      .webAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBuffer(
          that: this, renderedBuffer: renderedBuffer);
}

@sealed
class OfflineAudioContextImpl extends RustOpaque
    implements OfflineAudioContext {
  // Not to be used by end users
  OfflineAudioContextImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  OfflineAudioContextImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_OfflineAudioContext,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_OfflineAudioContext,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_OfflineAudioContextPtr,
  );

  /// Unset the callback to run when the rendering has completed
  Future<void> clearOncomplete() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextClearOncomplete(
        that: this,
      );

  /// Unset the callback to run when the state of the AudioContext has changed
  Future<void> clearOnstatechange() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextClearOnstatechange(
        that: this,
      );

  /// Creates a `AnalyserNode`
  Future<AnalyserNode> createAnalyser() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateAnalyser(
        that: this,
      );

  /// Create an `AudioParam`.
  ///
  /// Call this inside the `register` closure when setting up your `AudioNode`
  Future<(AudioParam, AudioParamId)> createAudioParam(
          {required AudioParamDescriptor opts,
          required AudioContextRegistration dest}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateAudioParam(
              that: this, opts: opts, dest: dest);

  /// Creates an `BiquadFilterNode` which implements a second order filter
  Future<BiquadFilterNode> createBiquadFilter() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateBiquadFilter(
        that: this,
      );

  /// Create an new "in-memory" `AudioBuffer` with the given number of channels,
  /// length (i.e. number of samples per channel) and sample rate.
  ///
  /// Note: In most cases you will want the sample rate to match the current
  /// audio context sample rate.
  Future<AudioBuffer> createBuffer(
          {required int numberOfChannels,
          required int length,
          required double sampleRate}) =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateBuffer(
          that: this,
          numberOfChannels: numberOfChannels,
          length: length,
          sampleRate: sampleRate);

  /// Creates an `AudioBufferSourceNode`
  Future<AudioBufferSourceNode> createBufferSource() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateBufferSource(
        that: this,
      );

  /// Creates a `ChannelMergerNode`
  Future<ChannelMergerNode> createChannelMerger(
          {required int numberOfInputs}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateChannelMerger(
              that: this, numberOfInputs: numberOfInputs);

  /// Creates a `ChannelSplitterNode`
  Future<ChannelSplitterNode> createChannelSplitter(
          {required int numberOfOutputs}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateChannelSplitter(
              that: this, numberOfOutputs: numberOfOutputs);

  /// Creates an `ConstantSourceNode`, a source representing a constant value
  Future<ConstantSourceNode> createConstantSource() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateConstantSource(
        that: this,
      );

  /// Creates an `ConvolverNode`, a processing node which applies linear convolution
  Future<ConvolverNode> createConvolver() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateConvolver(
        that: this,
      );

  /// Creates a `DelayNode`, delaying the audio signal
  Future<DelayNode> createDelay({required double maxDelayTime}) =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateDelay(
          that: this, maxDelayTime: maxDelayTime);

  /// Creates a `DynamicsCompressorNode`, compressing the audio signal
  Future<DynamicsCompressorNode> createDynamicsCompressor() =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateDynamicsCompressor(
        that: this,
      );

  /// Creates an `GainNode`, to control audio volume
  Future<GainNode> createGain() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateGain(
        that: this,
      );

  /// Creates an `IirFilterNode`
  ///
  /// # Arguments
  ///
  /// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  /// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.
  /// The maximum length of this array is 20
  Future<IirFilterNode> createIirFilter(
          {required List<double> feedforward,
          required List<double> feedback}) =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateIirFilter(
          that: this, feedforward: feedforward, feedback: feedback);

  /// Creates an `OscillatorNode`, a source representing a periodic waveform.
  Future<OscillatorNode> createOscillator() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateOscillator(
        that: this,
      );

  /// Creates a `PannerNode`
  Future<PannerNode> createPanner() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCreatePanner(
        that: this,
      );

  /// Creates a periodic wave
  ///
  /// Please note that this constructor deviates slightly from the spec by requiring a single
  /// argument with the periodic wave options.
  Future<PeriodicWave> createPeriodicWave(
          {required PeriodicWaveOptions options}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreatePeriodicWave(
              that: this, options: options);

  /// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);
  ///
  /// # Panics
  ///
  /// This function panics if:
  /// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384
  /// - the number of input and output channels are both zero
  /// - either of the channel counts exceed [`crate::MAX_CHANNELS`]
  Future<ScriptProcessorNode> createScriptProcessor(
          {required int bufferSize,
          required int numberOfInputChannels,
          required int numberOfOutputChannels}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateScriptProcessor(
              that: this,
              bufferSize: bufferSize,
              numberOfInputChannels: numberOfInputChannels,
              numberOfOutputChannels: numberOfOutputChannels);

  /// Creates an `StereoPannerNode` to pan a stereo output
  Future<StereoPannerNode> createStereoPanner() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateStereoPanner(
        that: this,
      );

  /// Creates a `WaveShaperNode`
  Future<WaveShaperNode> createWaveShaper() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextCreateWaveShaper(
        that: this,
      );

  /// This is the time in seconds of the sample frame immediately following the last sample-frame
  /// in the block of audio most recently processed by the context’s rendering graph.
  Future<double> currentTime() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextCurrentTime(
        that: this,
      );

  /// Returns an `AudioDestinationNode` representing the final destination of all audio in the
  /// context. It can be thought of as the audio-rendering device.
  Future<AudioDestinationNode> destination() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextDestination(
        that: this,
      );

  /// get the length of rendering audio buffer
  Future<int> length() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextLength(
        that: this,
      );

  /// Returns the `AudioListener` which is used for 3D spatialization
  Future<AudioListener> listener() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextListener(
        that: this,
      );

  /// Resumes the progression of the OfflineAudioContext's currentTime when it has been suspended
  ///
  /// # Panics
  ///
  /// Panics when the context is closed or rendering has not started
  Future<void> resume() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextResume(
        that: this,
      );

  /// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.
  Future<double> sampleRate() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextSampleRate(
        that: this,
      );

  Future<void> setOnComplete(
          {required FutureOr<void> Function(OfflineAudioCompletionEvent)
              callback}) =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextSetOnComplete(
          that: this, callback: callback);

  /// Given the current connections and scheduled changes, starts rendering audio.
  ///
  /// Rendering is purely CPU bound and contains no `await` points, so calling this method will
  /// block the executor until completion or until the context is suspended.
  ///
  /// This method will only adhere to scheduled suspensions via [`Self::suspend`] and will
  /// ignore those provided via [`Self::suspend_sync`].
  ///
  /// # Panics
  ///
  /// Panics if this method is called multiple times.
  Future<AudioBuffer> startRendering() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextStartRendering(
        that: this,
      );

  /// Given the current connections and scheduled changes, starts rendering audio.
  ///
  /// This function will block the current thread and returns the rendered `AudioBuffer`
  /// synchronously.
  ///
  /// This method will only adhere to scheduled suspensions via [`Self::suspend_sync`] and
  /// will ignore those provided via [`Self::suspend`].
  ///
  /// # Panics
  ///
  /// Panics if this method is called multiple times
  Future<AudioBuffer> startRenderingSync() => RustLib.instance.api
          .webAudioApiContextOfflineAudioContextStartRenderingSync(
        that: this,
      );

  /// Returns state of current context
  Future<AudioContextState> state() =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextState(
        that: this,
      );

  /// Schedules a suspension of the time progression in the audio context at the specified time
  /// and returns a promise
  ///
  /// The specified time is quantized and rounded up to the render quantum size.
  ///
  /// # Panics
  ///
  /// Panics if the quantized frame number
  ///
  /// - is negative or
  /// - is less than or equal to the current time or
  /// - is greater than or equal to the total render duration or
  /// - is scheduled by another suspend for the same time
  ///
  /// # Example usage
  ///
  /// ```rust
  /// use futures::{executor, join};
  /// use futures::FutureExt as _;
  /// use std::sync::Arc;
  ///
  /// use web_audio_api::context::BaseAudioContext;
  /// use web_audio_api::context::OfflineAudioContext;
  /// use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};
  ///
  /// let context = Arc::new(OfflineAudioContext::new(1, 512, 44_100.));
  /// let context_clone = Arc::clone(&context);
  ///
  /// let suspend_promise = context.suspend(128. / 44_100.).then(|_| async move {
  ///     let mut src = context_clone.create_constant_source();
  ///     src.connect(&context_clone.destination());
  ///     src.start();
  ///     context_clone.resume().await;
  /// });
  ///
  /// let render_promise = context.start_rendering();
  ///
  /// let buffer = executor::block_on(async move { join!(suspend_promise, render_promise).1 });
  /// assert_eq!(buffer.number_of_channels(), 1);
  /// assert_eq!(buffer.length(), 512);
  /// ```
  Future<void> suspend({required double suspendTime}) =>
      RustLib.instance.api.webAudioApiContextOfflineAudioContextSuspend(
          that: this, suspendTime: suspendTime);
}

@sealed
class OscillatorNodeImpl extends RustOpaque implements OscillatorNode {
  // Not to be used by end users
  OscillatorNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  OscillatorNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_OscillatorNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when the source node has stopped playing
  Future<void> clearOnended() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeClearOnended(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeClearOnprocessorerror(
        that: this,
      );

  /// A-rate [`AudioParam`] that defines a transposition according to the
  /// frequency, expressed in cents.
  ///
  /// see <https://en.wikipedia.org/wiki/Cent_(music)>
  ///
  /// The final frequency is calculated as follow: frequency * 2^(detune/1200)
  AudioParam get detune => AudioParamProxyVariantOscillatorNodeDetune(this);

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeOscillatorNodeFrbOverrideConnect(that: this, dest: dest);

  /// A-rate [`AudioParam`] that defines the fundamental frequency of the
  /// oscillator, expressed in Hz
  ///
  /// The final frequency is calculated as follow: frequency * 2^(detune/1200)
  AudioParam get frequency =>
      AudioParamProxyVariantOscillatorNodeFrequency(this);

  /// `OscillatorNode` is a source node. A source node is by definition with no input
  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeNumberOfInputs(
        that: this,
      );

  /// `OscillatorNode` is a mono source node.
  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeRegistration(
        that: this,
      );

  Future<void> setOnEnded({required FutureOr<void> Function(Event) callback}) =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeSetOnEnded(
          that: this, callback: callback);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeSetOnProcessorError(
          that: this, callback: callback);

  /// Sets a `PeriodicWave` which describes a waveform to be used by the oscillator.
  ///
  /// Calling this sets the oscillator type to `custom`, once set to `custom`
  /// the oscillator cannot be reverted back to a standard waveform.
  Future<void> setPeriodicWave({required PeriodicWave periodicWave}) =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeSetPeriodicWave(
          that: this, periodicWave: periodicWave);

  /// Set the oscillator type
  ///
  /// # Arguments
  ///
  /// * `type_` - oscillator type (sine, square, triangle, sawtooth)
  ///
  /// # Panics
  ///
  /// if `type_` is `OscillatorType::Custom`
  Future<void> setType({required OscillatorType type}) => RustLib.instance.api
      .webAudioApiNodeOscillatorNodeSetType(that: this, type: type);

  Future<void> start() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeStart(
        that: this,
      );

  Future<void> startAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeOscillatorNodeStartAt(that: this, when: when);

  Future<void> stop() => RustLib.instance.api.webAudioApiNodeOscillatorNodeStop(
        that: this,
      );

  Future<void> stopAt({required double when}) => RustLib.instance.api
      .webAudioApiNodeOscillatorNodeStopAt(that: this, when: when);

  /// Returns the oscillator type
  Future<OscillatorType> type() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeType(
        that: this,
      );
}

@sealed
class PannerNodeImpl extends RustOpaque implements PannerNode {
  // Not to be used by end users
  PannerNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  PannerNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_PannerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_PannerNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_PannerNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodePannerNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodePannerNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodePannerNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodePannerNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodePannerNodeClearOnprocessorerror(
        that: this,
      );

  Future<double> coneInnerAngle() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeInnerAngle(
        that: this,
      );

  Future<double> coneOuterAngle() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeOuterAngle(
        that: this,
      );

  Future<double> coneOuterGain() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeOuterGain(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodePannerNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiNodePannerNodeDisconnectOutput(that: this, output: output);

  Future<DistanceModelType> distanceModel() =>
      RustLib.instance.api.webAudioApiNodePannerNodeDistanceModel(
        that: this,
      );

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodePannerNodeFrbOverrideConnect(that: this, dest: dest);

  Future<double> maxDistance() =>
      RustLib.instance.api.webAudioApiNodePannerNodeMaxDistance(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodePannerNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodePannerNodeNumberOfOutputs(
        that: this,
      );

  AudioParam get orientationX =>
      AudioParamProxyVariantPannerNodeOrientationX(this);

  AudioParam get orientationY =>
      AudioParamProxyVariantPannerNodeOrientationY(this);

  AudioParam get orientationZ =>
      AudioParamProxyVariantPannerNodeOrientationZ(this);

  Future<PanningModelType> panningModel() =>
      RustLib.instance.api.webAudioApiNodePannerNodePanningModel(
        that: this,
      );

  AudioParam get positionX => AudioParamProxyVariantPannerNodePositionX(this);

  AudioParam get positionY => AudioParamProxyVariantPannerNodePositionY(this);

  AudioParam get positionZ => AudioParamProxyVariantPannerNodePositionZ(this);

  Future<double> refDistance() =>
      RustLib.instance.api.webAudioApiNodePannerNodeRefDistance(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodePannerNodeRegistration(
        that: this,
      );

  Future<double> rolloffFactor() =>
      RustLib.instance.api.webAudioApiNodePannerNodeRolloffFactor(
        that: this,
      );

  Future<void> setConeInnerAngle({required double value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetConeInnerAngle(that: this, value: value);

  Future<void> setConeOuterAngle({required double value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetConeOuterAngle(that: this, value: value);

  /// Set the coneOuterGain attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is not in the range [0, 1]
  Future<void> setConeOuterGain({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetConeOuterGain(that: this, value: value);

  Future<void> setDistanceModel({required DistanceModelType value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetDistanceModel(that: this, value: value);

  /// Set the maxDistance attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setMaxDistance({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetMaxDistance(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodePannerNodeSetOnProcessorError(
          that: this, callback: callback);

  Future<void> setOrientation(
          {required double x, required double y, required double z}) =>
      RustLib.instance.api.webAudioApiNodePannerNodeSetOrientation(
          that: this, x: x, y: y, z: z);

  Future<void> setPanningModel({required PanningModelType value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetPanningModel(that: this, value: value);

  Future<void> setPosition(
          {required double x, required double y, required double z}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetPosition(that: this, x: x, y: y, z: z);

  /// Set the refDistance attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setRefDistance({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetRefDistance(that: this, value: value);

  /// Set the rolloffFactor attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setRolloffFactor({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetRolloffFactor(that: this, value: value);
}

@sealed
class PeriodicWaveImpl extends RustOpaque implements PeriodicWave {
  // Not to be used by end users
  PeriodicWaveImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  PeriodicWaveImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_PeriodicWave,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_PeriodicWave,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_PeriodicWavePtr,
  );
}

@sealed
class ScriptProcessorNodeImpl extends RustOpaque
    implements ScriptProcessorNode {
  // Not to be used by end users
  ScriptProcessorNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ScriptProcessorNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_ScriptProcessorNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_ScriptProcessorNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ScriptProcessorNodePtr,
  );

  Future<int> bufferSize() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeBufferSize(
        that: this,
      );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() => RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when the AudioProcessingEvent is dispatched
  Future<void> clearOnaudioprocess() => RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeClearOnaudioprocess(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() => RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<void> setOnaudioprocess(
          {required FutureOr<void> Function(AudioProcessingEvent) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeFrbOverrideSetOnaudioprocess(
              that: this, callback: callback);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeSetOnProcessorError(
              that: this, callback: callback);
}

@sealed
class StereoPannerNodeImpl extends RustOpaque implements StereoPannerNode {
  // Not to be used by end users
  StereoPannerNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  StereoPannerNodeImpl.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_StereoPannerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_StereoPannerNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_StereoPannerNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeFrbOverrideConnect(
          that: this, dest: dest);

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeNumberOfOutputs(
        that: this,
      );

  /// Returns the pan audio parameter
  AudioParam get pan => AudioParamProxyVariantStereoPannerNodePan(this);

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeRegistration(
        that: this,
      );

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeSetOnProcessorError(
          that: this, callback: callback);
}

@sealed
class WaveShaperNodeImpl extends RustOpaque implements WaveShaperNode {
  // Not to be used by end users
  WaveShaperNodeImpl.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  WaveShaperNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_WaveShaperNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNodePtr,
  );

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeClearOnprocessorerror(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeDisconnectOutput(
          that: this, output: output);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiNodeWaveShaperNodeFrbOverrideConnect(that: this, dest: dest);

  Future<Float32List?> curve() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeFrbOverrideCurve(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeNumberOfOutputs(
        that: this,
      );

  /// Returns the `oversample` faactor of this node
  Future<OverSampleType> oversample() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeOversample(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeRegistration(
        that: this,
      );

  /// Set the distortion `curve` of this node
  ///
  /// # Arguments
  ///
  /// * `curve` - the desired distortion `curve`
  ///
  /// # Panics
  ///
  /// Panics if a curve has already been given to the source (though `new` or through
  /// `set_curve`)
  Future<void> setCurve({required List<double> curve}) => RustLib.instance.api
      .webAudioApiNodeWaveShaperNodeSetCurve(that: this, curve: curve);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetOnProcessorError(
          that: this, callback: callback);

  /// set the `oversample` factor of this node
  ///
  /// # Arguments
  ///
  /// * `oversample` - the desired `OversampleType` variant
  Future<void> setOversample({required OverSampleType oversample}) =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetOversample(
          that: this, oversample: oversample);
}

class AudioParamProxyVariantAudioBufferSourceNodeDetune
    with SimpleDisposable
    implements AudioParam {
  final AudioBufferSourceNode _upstream;

  AudioParamProxyVariantAudioBufferSourceNodeDetune(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioBufferSourceNodePlaybackRate
    with SimpleDisposable
    implements AudioParam {
  final AudioBufferSourceNode _upstream;

  AudioParamProxyVariantAudioBufferSourceNodePlaybackRate(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerForwardX
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerForwardX(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerForwardY
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerForwardY(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerForwardZ
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerForwardZ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerPositionX
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerPositionX(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerPositionY
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerPositionY(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerPositionZ
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerPositionZ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerUpX
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerUpX(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerUpY
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerUpY(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantAudioListenerUpZ
    with SimpleDisposable
    implements AudioParam {
  final AudioListener _upstream;

  AudioParamProxyVariantAudioListenerUpZ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantBiquadFilterNodeDetune
    with SimpleDisposable
    implements AudioParam {
  final BiquadFilterNode _upstream;

  AudioParamProxyVariantBiquadFilterNodeDetune(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantBiquadFilterNodeFrequency
    with SimpleDisposable
    implements AudioParam {
  final BiquadFilterNode _upstream;

  AudioParamProxyVariantBiquadFilterNodeFrequency(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantBiquadFilterNodeGain
    with SimpleDisposable
    implements AudioParam {
  final BiquadFilterNode _upstream;

  AudioParamProxyVariantBiquadFilterNodeGain(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantBiquadFilterNodeQ
    with SimpleDisposable
    implements AudioParam {
  final BiquadFilterNode _upstream;

  AudioParamProxyVariantBiquadFilterNodeQ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantConstantSourceNodeOffset
    with SimpleDisposable
    implements AudioParam {
  final ConstantSourceNode _upstream;

  AudioParamProxyVariantConstantSourceNodeOffset(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDelayNodeDelayTime
    with SimpleDisposable
    implements AudioParam {
  final DelayNode _upstream;

  AudioParamProxyVariantDelayNodeDelayTime(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDynamicsCompressorNodeAttack
    with SimpleDisposable
    implements AudioParam {
  final DynamicsCompressorNode _upstream;

  AudioParamProxyVariantDynamicsCompressorNodeAttack(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDynamicsCompressorNodeKnee
    with SimpleDisposable
    implements AudioParam {
  final DynamicsCompressorNode _upstream;

  AudioParamProxyVariantDynamicsCompressorNodeKnee(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDynamicsCompressorNodeRatio
    with SimpleDisposable
    implements AudioParam {
  final DynamicsCompressorNode _upstream;

  AudioParamProxyVariantDynamicsCompressorNodeRatio(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDynamicsCompressorNodeRelease
    with SimpleDisposable
    implements AudioParam {
  final DynamicsCompressorNode _upstream;

  AudioParamProxyVariantDynamicsCompressorNodeRelease(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantDynamicsCompressorNodeThreshold
    with SimpleDisposable
    implements AudioParam {
  final DynamicsCompressorNode _upstream;

  AudioParamProxyVariantDynamicsCompressorNodeThreshold(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantGainNodeGain
    with SimpleDisposable
    implements AudioParam {
  final GainNode _upstream;

  AudioParamProxyVariantGainNodeGain(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantOscillatorNodeDetune
    with SimpleDisposable
    implements AudioParam {
  final OscillatorNode _upstream;

  AudioParamProxyVariantOscillatorNodeDetune(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantOscillatorNodeFrequency
    with SimpleDisposable
    implements AudioParam {
  final OscillatorNode _upstream;

  AudioParamProxyVariantOscillatorNodeFrequency(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodeOrientationX
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodeOrientationX(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodeOrientationY
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodeOrientationY(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodeOrientationZ
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodeOrientationZ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodePositionX
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodePositionX(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodePositionY
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodePositionY(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantPannerNodePositionZ
    with SimpleDisposable
    implements AudioParam {
  final PannerNode _upstream;

  AudioParamProxyVariantPannerNodePositionZ(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class AudioParamProxyVariantStereoPannerNodePan
    with SimpleDisposable
    implements AudioParam {
  final StereoPannerNode _upstream;

  AudioParamProxyVariantStereoPannerNodePan(this._upstream);

  /// Current value of the automation rate of the AudioParam
  Future<AutomationRate> automationRate() =>
      RustLib.instance.api.webAudioApiAudioParamAutomationRate(
        that: this,
      );

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time` and the automation value that would have happened at
  /// that time is then propagated for all future time.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelAndHoldAtTime({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(
          that: this, cancelTime: cancelTime);

  /// Cancels all scheduled parameter changes with times greater than or equal
  /// to `cancel_time`.
  ///
  /// # Panics
  ///
  /// Will panic if `cancel_time` is negative
  Future<void> cancelScheduledValues({required double cancelTime}) =>
      RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(
          that: this, cancelTime: cancelTime);

  Future<void> channelConfig() =>
      RustLib.instance.api.webAudioApiAudioParamChannelConfig(
        that: this,
      );

  /// Represents an integer used to determine how many channels are used when up-mixing and
  /// down-mixing connections to any inputs to the node.
  Future<int> channelCount() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCount(
        that: this,
      );

  /// Represents an enumerated value describing the way channels must be matched between the
  /// node's inputs and outputs.
  Future<ChannelCountMode> channelCountMode() =>
      RustLib.instance.api.webAudioApiAudioParamChannelCountMode(
        that: this,
      );

  /// Represents an enumerated value describing the meaning of the channels. This interpretation
  /// will define how audio up-mixing and down-mixing will happen.
  Future<ChannelInterpretation> channelInterpretation() =>
      RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(
        that: this,
      );

  /// Unset the callback to run when an unhandled exception occurs in the audio processor.
  Future<void> clearOnprocessorerror() =>
      RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(
        that: this,
      );

  Future<double> defaultValue() =>
      RustLib.instance.api.webAudioApiAudioParamDefaultValue(
        that: this,
      );

  /// Disconnects all outgoing connections from the AudioNode.
  Future<void> disconnect() =>
      RustLib.instance.api.webAudioApiAudioParamDisconnect(
        that: this,
      );

  /// Disconnects all outgoing connections at the given output port from the AudioNode.
  ///
  /// # Panics
  ///
  /// This function will panic when
  /// - if the output port is out of bounds for this node
  Future<void> disconnectOutput({required int output}) => RustLib.instance.api
      .webAudioApiAudioParamDisconnectOutput(that: this, output: output);

  /// Schedules an exponential continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` is zero
  /// - `end_time` is negative
  Future<void> exponentialRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<void> connect({required AudioNode dest}) => RustLib.instance.api
      .webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);

  /// Schedules a linear continuous change in parameter value from the
  /// previous scheduled parameter value to the given value.
  ///
  /// # Panics
  ///
  /// Will panic if `end_time` is negative
  Future<void> linearRampToValueAtTime(
          {required double value, required double endTime}) =>
      RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(
          that: this, value: value, endTime: endTime);

  Future<double> maxValue() =>
      RustLib.instance.api.webAudioApiAudioParamMaxValue(
        that: this,
      );

  Future<double> minValue() =>
      RustLib.instance.api.webAudioApiAudioParamMinValue(
        that: this,
      );

  Future<int> numberOfInputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(
        that: this,
      );

  Future<int> numberOfOutputs() =>
      RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(
        that: this,
      );

  Future<void> registration() =>
      RustLib.instance.api.webAudioApiAudioParamRegistration(
        that: this,
      );

  /// Update the current value of the automation rate of the AudioParam
  ///
  /// # Panics
  ///
  /// Some nodes have automation rate constraints and may panic when updating the value.
  Future<void> setAutomationRate({required AutomationRate value}) =>
      RustLib.instance.api
          .webAudioApiAudioParamSetAutomationRate(that: this, value: value);

  Future<void> setOnProcessorError(
          {required FutureOr<void> Function(String) callback}) =>
      RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(
          that: this, callback: callback);

  /// Start exponentially approaching the target value at the given time with
  /// a rate having the given time constant.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `start_time` is negative
  /// - `time_constant` is negative
  Future<void> setTargetAtTime(
          {required double value,
          required double startTime,
          required double timeConstant}) =>
      RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(
          that: this,
          value: value,
          startTime: startTime,
          timeConstant: timeConstant);

  /// Set the value of the `AudioParam`.
  ///
  /// Is equivalent to calling the `set_value_at_time` method with the current
  /// AudioContext's currentTime
  set value(double value) => RustLib.instance.api
      .webAudioApiAudioParamSetValue(that: this, value: value);

  /// Schedules a parameter value change at the given time.
  ///
  /// # Panics
  ///
  /// Will panic if `start_time` is negative
  Future<void> setValueAtTime(
          {required double value, required double startTime}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(
          that: this, value: value, startTime: startTime);

  /// Sets an array of arbitrary parameter values starting at the given time
  /// for the given duration.
  ///
  /// # Panics
  ///
  /// Will panic if:
  /// - `value` length is less than 2
  /// - `start_time` is negative
  /// - `duration` is negative or equal to zero
  Future<void> setValueCurveAtTime(
          {required List<double> values,
          required double startTime,
          required double duration}) =>
      RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(
          that: this, values: values, startTime: startTime, duration: duration);

  /// Retrieve the current value of the `AudioParam`.
  double get value => RustLib.instance.api.webAudioApiAudioParamValue(
        that: this,
      );
}

class MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream
    with SimpleDisposable
    implements MediaStream {
  final MediaStreamAudioDestinationNode _upstream;

  MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream(this._upstream);

  Future<List<MediaStreamTrack>> getTracks() => RustLib.instance.api
          .webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(
        that: this,
      );
}
